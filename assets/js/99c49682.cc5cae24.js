"use strict";(self.webpackChunkvac_dev=self.webpackChunkvac_dev||[]).push([[6807],{10319:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"rln-v3","metadata":{"permalink":"/rlog/rln-v3","source":"@site/rlog/2024-05-13-rln-v3.mdx","title":"RLN-v3: Towards a Flexible and Cost-Efficient Implementation","description":"Improving on the previous version of RLN by allowing dynamic epoch sizes.","date":"2024-05-13T12:00:00.000Z","formattedDate":"May 13, 2024","tags":[],"readingTime":6.31,"hasTruncateMarker":true,"authors":[{"name":"Aaryamann","twitter":"p1ge0nh8er","github":"rymnc","key":"p1ge0nh8er"}],"frontMatter":{"title":"RLN-v3: Towards a Flexible and Cost-Efficient Implementation","date":"2024-05-13T12:00:00.000Z","authors":"p1ge0nh8er","published":true,"slug":"rln-v3","categories":"research","toc_min_heading_level":2,"toc_max_heading_level":4},"nextItem":{"title":"Verifying RLN Proofs in Light Clients with Subtrees","permalink":"/rlog/rln-light-verifiers"}},"content":"Improving on the previous version of RLN by allowing dynamic epoch sizes.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nRecommended previous reading: [Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku](https://vac.dev/rlog/rln-anonymous-dos-prevention).\\n\\nThe premise of RLN-v3 is to have a variable message rate per variable epoch,\\nwhich can be explained in the following way:\\n\\n- **RLN-v1:** \u201cAlice can send 1 message per global epoch\u201d\\n\\n  Practically, this is `1 msg/second`\\n\\n- **RLN-v2:** \u201cAlice can send `x` messages per global epoch\u201d\\n\\n  Practically, this is `x msg/second`\\n\\n- **RLN-v3:** \u201cAlice can send `x` messages within a time interval `y` chosen by herself.\\n  The funds she has to pay are affected by both the number of messages and the chosen time interval.\\n  Other participants can choose different time intervals fitting their specific needs.\\n\\n  Practically, this is `x msg/y seconds`\\n\\nRLN-v3 allows higher flexibility and ease of payment/stake for users who have more predictable usage patterns and therefore,\\nmore predictable bandwidth usage on a p2p network (Waku, etc.).\\n\\nFor example:\\n\\n- An AMM that broadcasts bids, asks, and fills over Waku may require a lot of throughput in the smallest epoch possible and hence may register an RLN-v3 membership of `10000 msg/1 second`.\\n  They could do this with RLN-v2, too.\\n- Alice, a casual user of a messaging app built on Waku, who messages maybe 3-4 people infrequently during the day, may register an RLN-v3 membership of `100 msg/hour`,\\n  which would not be possible in RLN-v2 considering the `global epoch` was set to `1 second`.\\n  With RLN-v2, Alice would have to register with a membership of `1 msg/sec`,\\n  which would translate to `3600 msg/hour`. This is much higher than her usage and would\\n  result in her overpaying to stake into the membership set.\\n- A sync service built over Waku,\\n  whose spec defines that it MUST broadcast a set of public keys every hour,\\n  may register an RLN-v3 membership of `1 msg/hour`,\\n  cutting down the costs to enter the membership set earlier.\\n\\n## Theory\\n\\n### Modification to leaves set in the membership Merkle tree\\n\\nTo ensure that a user\u2019s epoch size (`user_epoch_limit`) is included within their membership we must modify the user\u2019s commitment/leaf in the tree to contain it.\\nA user\u2019s commitment/leaf in the tree is referred to as a `rate_commitment`,\\nwhich was previously derived from their public key (`identity_commitment`)\\nand their variable message rate (`user_message_limit`).\\n\\nIn **RLN-v2:**\\n\\n$$\\nrate\\\\_commitment = poseidon([identity\\\\_commitment, user\\\\_message\\\\_limit])\\n$$\\n\\nIn **RLN-v3:**\\n\\n$$\\nrate\\\\_commitment = poseidon([identity\\\\_commitment, user\\\\_message\\\\_limit, user\\\\_epoch\\\\_limit])\\n$$\\n\\n### Modification to circuit inputs\\n\\nTo detect double signaling,\\nwe make use of a circuit output `nullifier`,\\nwhich remains the same if a user generates a proof with the same `message_id` and `external_nullifier`,\\nwhere the `external_nullifier` and `nullifier` are defined as:\\n\\n$$\\nexternal\\\\_nullifier = poseidon([epoch, rln\\\\_identifier]) \\\\\\\\\\nnullifier = poseidon([identity\\\\_secret, external\\\\_nullifier, message\\\\_id])\\n$$\\n\\nWhere:\\n\\n- `epoch` is defined as the Unix epoch timestamp with seconds precision.\\n- `rln_identifier` uniquely identifies an application for which a user submits a proof.\\n- `identity_secret` is the private key of the user.\\n- `message_id` is the sequence number of the user\u2019s message within `user_message_limit` in an epoch.\\n\\nIn RLN-v2, the global epoch was 1 second,\\nhence we did not need to perform any assertions to the epoch\u2019s value inside the circuit,\\nand the validation of the epoch was handled off-circuit (i.e., too old, too large, bad values, etc.).\\n\\nIn RLN-v3, we propose that the `epoch` that is passed into the circuit\\nmust be a valid multiple of `user_epoch_limit`\\nsince the user may pass in values of the `epoch` which do not directly correlate with the `user_epoch_limit`.\\n\\nFor example:\\n\\n- A user with `user_epoch_limit` of 120\\n  passes in an epoch of `237`\\n  generates `user_message_limit` proofs with it,\\n  can increment the epoch by `1`,\\n  and generate `user_message_limit` proofs with it,\\n  thereby allowing them to bypass the message per epoch restriction.\\n\\nOne could say that we could perform this validation outside of the circuit,\\nbut we maintain the `user_epoch_limit` as a private input to the circuit so that the user is not deanonymized by the anonymity set connected to that `user_epoch_limit`.\\nSince `user_epoch_limit` is kept private,\\nthe verifier does not have access to that value and cannot perform validation on it.\\n\\nIf we ensure that the `epoch` is a multiple of `user_epoch_limit`,\\nwe have the following scenarios:\\n\\n- A user with `user_epoch_limit` of 120\\n  passes in an epoch of `237`.\\n  Proof generation fails since the epoch is not a multiple of `user_epoch_limit`.\\n- A user with `user_epoch_limit` of 120\\n  passes in an epoch of `240` and\\n  can generate `user_message_limit` proofs without being slashed.\\n\\nSince we perform operations on the `epoch`, we must include it as a circuit input (previously, it was removed from the circuit inputs to RLN-v2).\\n\\nTherefore, the new circuit inputs are as follows:\\n\\n```c\\n// unchanged\\nprivate identity_secret\\nprivate user_message_limit\\nprivate message_id\\nprivate pathElements[]\\nprivate pathIndices[]\\npublic x // messageHash\\n\\n// new/changed\\nprivate user_epoch_limit\\nprivate user_epoch_quotient // epoch/user_epoch_limit to assert within circuit\\npublic epoch\\npublic rln_identifier\\n```\\n\\nThe circuit outputs remain the same.\\n\\n### Additional circuit constraints\\n\\n1. Since we accept the `epoch`, `user_epoch_quotient`, and `user_epoch_limit`,\\n   we must ensure that the relation between these 3 values is preserved. I.e.:\\n\\n   $$\\n   epoch == user\\\\_epoch\\\\_limit * user\\\\_epoch\\\\_quotient\\n   $$\\n\\n2. To ensure no overflows/underflows occur in the above multiplication,\\n   we must constrain the inputs of `epoch`, `user_epoch_quotient`, and `user_epoch_limit`.\\n   We have assumed `3600` to be the maximum valid size of the `user_epoch_quotient`.\\n\\n$$\\nsize(epoch) \\\\leq 64\\\\ bits \\\\\\\\\\nsize(user\\\\_epoch\\\\_limit) \\\\leq 12\\\\ bits \\\\\\\\\\nuser\\\\_epoch\\\\_limit \\\\leq 3600 \\\\\\\\\\nuser\\\\_epoch\\\\_limit \\\\leq epoch \\\\\\\\\\nuser\\\\_epoch\\\\_quotient < user\\\\_epoch\\\\_limit\\n$$\\n\\n### Modifications to external epoch validation (Waku, etc.)\\n\\nFor receivers of an RLN-v3 proof\\nto detect if a message is too old, we must use the higher bound of the `user_epoch_limit`, which has been set to `3600`.\\nThe **trade-off** here is that we allow hour-old messages to propagate within the network.\\n\\n### Modifications to double signaling detection scheme (Waku, etc.)\\n\\nFor verifiers of RLN-v1/v2 proofs,\\na log of nullifiers seen in the last epoch is maintained,\\nand if there is a match with a pre-existing nullifier,\\ndouble signaling has been detected and the verifier MAY proceed to slash the spamming user.\\n\\nWith the RLN-v3 scheme,\\nwe need to increase the size of the nullifier log used,\\nwhich previously cleared itself every second to the higher bound of the `user_epoch_limit`, which is `3600`.\\nNow, the RLN proof verifier must clear the nullifier log every `3600` seconds to satisfactorily detect double signaling.\\n\\n## The implementation\\n\\nAn implementation of the RLN-v3 scheme in [gnark](https://docs.gnark.consensys.io/) can be found [here](https://github.com/vacp2p/gnark-rln/blob/9b05eddc89901a06d8f41b093ce8ce12fd0bb4e0/rln/rln.go).\\n\\n## Comments on performance\\n\\n- Hardware: Macbook Air M2, 16GB RAM\\n- Circuit: [RLN-v3](https://github.com/vacp2p/gnark-rln/blob/9b05eddc89901a06d8f41b093ce8ce12fd0bb4e0/rln/rln.go)\\n- Proving system: [`Groth16`](https://eprint.iacr.org/2016/260.pdf)\\n- Framework: [`gnark`](https://docs.gnark.consensys.io/)\\n- Elliptic curve: [`bn254`](https://eprint.iacr.org/2013/879.pdf) (aka bn128) (not to be confused with the 254-bit Weierstrass curve)\\n- Finite field: Prime-order subgroup of the group of points on the `bn254` curve\\n- Default Merkle tree height: `20`\\n- Hashing algorithm: [`Poseidon`](https://eprint.iacr.org/2019/458.pdf)\\n- Merkle tree: [`Sparse Indexed Merkle Tree`](https://github.com/rate-limiting-nullifier/pmtree)\\n\\n### Proving\\n\\nThe proving time for the RLN-v3 circuit is `90ms` for a single proof.\\n\\n### Verification\\n\\nThe verification time for the RLN-v3 circuit is `1.7ms` for a single proof.\\n\\n## Conclusion\\n\\nThe RLN-v3 scheme introduces a new epoch-based message rate-limiting scheme to the RLN protocol.\\nIt enhances the user\'s flexibility in setting their message limits and cost-optimizes their stake.\\n\\n## Future work\\n\\n- Implementing the RLN-v3 scheme in [Zerokit](https://github.com/vacp2p/zerokit)\\n- Implementing the RLN-v3 scheme in [Waku](https://github.com/waku-org/nwaku)\\n- Formal security analysis of the RLN-v3 scheme\\n\\n## References\\n\\n- [Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku](https://vac.dev/rlog/rln-anonymous-dos-prevention)\\n- [RLN Circuits](https://github.com/rate-limiting-nullifier/circom-rln)\\n- [Groth16](https://eprint.iacr.org/2016/260.pdf)\\n- [Gnark](https://docs.gnark.consensys.io/)\\n- [Poseidon Hash](https://eprint.iacr.org/2019/458.pdf)\\n- [Zerokit](https://github.com/vacp2p/zerokit)\\n- [RLN-v1 RFC](https://rfc.vac.dev/spec/32/)\\n- [RLN-v2 RFC](https://rfc.vac.dev/spec/58/)\\n- [Waku](https://waku.org)"},{"id":"rln-light-verifiers","metadata":{"permalink":"/rlog/rln-light-verifiers","source":"@site/rlog/2024-05-03-rln-light-verifiers.mdx","title":"Verifying RLN Proofs in Light Clients with Subtrees","description":"How resource-restricted devices can verify RLN proofs fast and efficiently.","date":"2024-05-03T12:00:00.000Z","formattedDate":"May 3, 2024","tags":[],"readingTime":4.81,"hasTruncateMarker":true,"authors":[{"name":"Aaryamann","twitter":"p1ge0nh8er","github":"rymnc","key":"p1ge0nh8er"}],"frontMatter":{"title":"Verifying RLN Proofs in Light Clients with Subtrees","date":"2024-05-03T12:00:00.000Z","authors":"p1ge0nh8er","published":true,"slug":"rln-light-verifiers","categories":"research","toc_min_heading_level":2,"toc_max_heading_level":4},"prevItem":{"title":"RLN-v3: Towards a Flexible and Cost-Efficient Implementation","permalink":"/rlog/rln-v3"},"nextItem":{"title":"Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku","permalink":"/rlog/rln-anonymous-dos-prevention"}},"content":"How resource-restricted devices can verify RLN proofs fast and efficiently.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nRecommended previous reading: [Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku](https://vac.dev/rlog/rln-anonymous-dos-prevention).\\n\\nThis post expands upon ideas described in the previous post,\\nfocusing on how resource-restricted devices can verify RLN proofs fast and efficiently.\\n\\nPreviously, it was required to fetch all the memberships from the smart contract,\\nconstruct the merkle tree locally,\\nand derive the merkle root,\\nwhich is subsequently used to verify RLN proofs.\\n\\nThis process is not feasible for resource-restricted devices since it involves a lot of RPC calls, computation and fault tolerance.\\nOne cannot expect a mobile phone to fetch all the memberships from the smart contract and construct the merkle tree locally.\\n\\n## Constraints and requirements\\n\\nAn alternative solution to the one proposed in this post is to construct the merkle tree on-chain,\\nand have the root accessible with a single RPC call.\\nHowever, this approach increases gas costs for inserting new memberships and _may_ not be feasible until it is optimized further with batching mechanisms, etc.\\n\\nThe other methods have been explored in more depth [here](https://hackmd.io/@rymnc/rln-tree-storages).\\n\\nFollowing are the requirements and constraints for the solution proposed in this post:\\n\\n1. Cheap membership insertions.\\n2. As few RPC calls as possible to reduce startup time.\\n3. Merkle root of the tree is available on-chain.\\n4. No centralized services to sequence membership insertions.\\n5. Map inserted commitments to the block in which they were inserted.\\n\\n## Metrics on sync time for a tree with 2,653 leaves\\n\\nThe following metrics are based on the current implementation of RLN in the Waku gen0 network.\\n\\n### Test bench\\n\\n- Hardware: Macbook Air M2, 16GB RAM\\n- Network: 120 Megabits/sec\\n- Nwaku commit: [e61e4ff](https://github.com/waku-org/nwaku/tree/e61e4ff90a235657a7dc4248f5be41b6e031e98c)\\n- RLN membership set contract: [0xF471d71E9b1455bBF4b85d475afb9BB0954A29c4](https://sepolia.etherscan.io/address/0xF471d71E9b1455bBF4b85d475afb9BB0954A29c4#code)\\n- Deployed block number: 4,230,716\\n- RLN Membership set depth: 20\\n- Hash function: PoseidonT3 (which is a gas guzzler)\\n- Max size of the membership set: 2^20 = 1,048,576 leaves\\n\\n### Metrics\\n\\n- Time to sync the whole tree: 4 minutes\\n- RPC calls: 702\\n- Number of leaves: 2,653\\n\\nOne can argue that the time to sync the tree at the current state is not _that_ bad.\\nHowever, the number of RPC calls is a concern,\\nwhich scales linearly with the number of blocks since the contract was deployed\\nThis is because the implementation fetches all events from the contract,\\nchunking 2,000 blocks at a time.\\nThis is done to avoid hitting the block limit of 10,000 events per call,\\nwhich is a limitation of popular RPC providers.\\n\\n## Proposed solution\\n\\nFrom a theoretical perspective,\\none could construct the merkle tree on-chain,\\nin a view call, in-memory.\\nHowever, this is not feasible due to the gas costs associated with it.\\n\\nTo compute the root of a Merkle tree with $2^{20}$ leaves it costs approximately 2 billion gas.\\nWith Infura and Alchemy capping the gas limit to 350M and 550M gas respectively,\\nit is not possible to compute the root of the tree in a single call.\\n\\nAcknowledging that [Polygon Miden](https://polygon.technology/blog/polygon-miden-state-model) and [Penumbra](https://penumbra.zone/blog/tiered-commitment-tree/) both make use of a tiered commitment tree,\\nwe propose a similar approach for RLN.\\n\\nA tiered commitment tree is a tree which is sharded into multiple smaller subtrees,\\neach of which is a tree in itself.\\nThis allows scaling in terms of the number of leaves,\\nas well as reducing state bloat by just storing the root of a subtree when it is full instead of all its leaves.\\n\\nHere, the question arises:\\nWhat is the maximum number of leaves in a subtree with which the root can be computed in a single call?\\n\\nIt costs approximately 217M gas to compute the root of a Merkle tree with $2^{10}$ leaves.\\n\\nThis is a feasible number for a single call,\\nand hence we propose a tiered commitment tree with a maximum of $2^{10}$ leaves in a subtree and the number of subtrees is $2^{10}$.\\nTherefore, the maximum number of leaves in the tree is $2^{20}$ (the same as the current implementation).\\n\\n![img](/img/light-rln-verifiers.png)\\n\\n### Insertion\\n\\nWhen a commitment is inserted into the tree it is first inserted into the first subtree.\\nWhen the first subtree is full the next insertions go into the second subtree and so on.\\n\\n### Syncing\\n\\nWhen syncing the tree,\\none only needs to fetch the roots of the subtrees.\\nThe root of the full tree can be computed in-memory or on-chain.\\n\\nThis allows us to derive the following relation:\\n\\n$$\\nnumber\\\\_of\\\\_rpc\\\\_calls = number\\\\_of\\\\_filled\\\\_subtrees + 1\\n$$\\n\\nThis is a significant improvement over the current implementation,\\nwhich requires fetching all the memberships from the smart contract.\\n\\n### Gas costs\\n\\nThe gas costs for inserting a commitment into the tree are the same as the current implementation except it consists of an extra SSTORE operation to store the `shardIndex` of the commitment.\\n\\n### Events\\n\\nThe events emitted by the contract are the same as the current implementation,\\nappending the `shardIndex` of the commitment.\\n\\n### Proof of concept\\n\\nA proof of concept implementation of the tiered commitment tree is available [here](https://github.com/vacp2p/rln-contract/pull/37),\\nand is deployed on Sepolia at [0xE7987c70B54Ff32f0D5CBbAA8c8Fc1cAf632b9A5](https://sepolia.etherscan.io/address/0xE7987c70B54Ff32f0D5CBbAA8c8Fc1cAf632b9A5).\\n\\nIt is compatible with the current implementation of the RLN verifier.\\n\\n## Future work\\n\\n1. Optimize the gas costs of the tiered commitment tree.\\n2. Explore using different number of leaves under a given node in the tree (currently set to 2).\\n\\n## Conclusion\\n\\nThe tiered commitment tree is a promising approach to reduce the number of RPC calls required to sync the tree and reduce the gas costs associated with computing the root of the tree.\\nConsequently, it allows for a more scalable and efficient RLN verifier.\\n\\n## References\\n\\n- [RLN Circuits](https://github.com/rate-limiting-nullifier/circom-rln)\\n- [Zerokit](https://github.com/vacp2p/zerokit)\\n- [RLN-V1 RFC](https://rfc.vac.dev/spec/32/)\\n- [RLN-V2 RFC](https://rfc.vac.dev/spec/58/)\\n- [RLN Implementers guide](https://hackmd.io/7cBCMU5hS5OYv8PTaW2wAQ?view)\\n- [Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku](https://vac.dev/rlog/rln-anonymous-dos-prevention)"},{"id":"rln-anonymous-dos-prevention","metadata":{"permalink":"/rlog/rln-anonymous-dos-prevention","source":"@site/rlog/2023-11-07-rln-relay.mdx","title":"Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku","description":"Rate Limiting Nullifiers in practice, applied to an anonymous p2p network, like Waku.","date":"2023-11-07T12:00:00.000Z","formattedDate":"November 7, 2023","tags":[],"readingTime":6.77,"hasTruncateMarker":true,"authors":[{"name":"Aaryamann","twitter":"p1ge0nh8er","github":"rymnc","key":"p1ge0nh8er"}],"frontMatter":{"title":"Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku","date":"2023-11-07T12:00:00.000Z","authors":"p1ge0nh8er","published":true,"slug":"rln-anonymous-dos-prevention","categories":"research","toc_min_heading_level":2,"toc_max_heading_level":4},"prevItem":{"title":"Verifying RLN Proofs in Light Clients with Subtrees","permalink":"/rlog/rln-light-verifiers"},"nextItem":{"title":"GossipSub Improvements: Evolution of Overlay Design and Message Dissemination in Unstructured P2P Networks","permalink":"/rlog/GossipSub Improvements"}},"content":"Rate Limiting Nullifiers in practice, applied to an anonymous p2p network, like Waku.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nRate Limiting Nullifier (RLN) is a zero-knowledge gadget that allows users to prove 2 pieces of information,\\n1. They belong to a permissioned membership set\\n2. Their rate of signaling abides by a fixed number that has been previously declared\\n\\nThe \\"membership set\\" introduced above, is in the form of a sparse, indexed merkle tree.\\nThis membership set can be maintained on-chain, off-chain or as a hybrid depending on the network\'s storage costs.\\nWaku makes use of a hybrid membership set, \\nwhere insertions are tracked in a smart contract.\\nIn addition, each Waku node maintains a local copy of the tree, \\nwhich is updated upon each insertion.\\n\\nUsers register themselves with a hash of a locally generated secret, \\nwhich is then inserted into the tree at the next available index.\\nAfter having registered, users can prove their membership by proving their knowledge of the pre-image of the respective leaf in the tree.\\nThe leaf hashes are also referred to as commitments of the respective users.\\nThe actual proof is done by a [Merkle Inclusion Proof](https://ethereum.org/en/developers/tutorials/merkle-proofs-for-offline-data-integrity/), which is a type of ZK proof.\\n\\nThe circuit ensures that the user\'s secret does indeed hash to a leaf in the tree,\\nand that the provided Merkle proof is valid.\\n\\nAfter a User generates this Merkle proof, \\nthey can transmit it to other users, \\nwho can verify the proof.\\nIncluding a message\'s hash within the proof generation, \\nadditionally guarantees integrity of that message.\\n\\nA malicious user could generate multiple proofs per epoch.\\nthey generate multiple proofs per epoch.\\nHowever, when multiple proofs are generated per epoch, \\nthe malicious user\'s secret is exposed, which strongly disincentivizes this attack.\\nThis mechanism is further described in [malicious User secret interpolation mechanism](#malicious-user-secret-interpolation-mechanism)\\n\\nNote: This blog post describes rln-v1, which excludes the range check in favor of a global rate limit for all users,\\nwhich is once per time window. This version is currently in use in waku-rln-relay.\\n\\n## RLN Protocol parameters\\n\\nGiven below is the set of cryptographic primitives, \\nand constants that are used in the RLN protocol. \\n\\n1. Proving System: [`groth16`](https://eprint.iacr.org/2016/260.pdf)\\n2. Elliptic Curve: [`bn254`](https://eprint.iacr.org/2013/879.pdf) (aka bn128) (not to be confused with the 254 bit Weierstrass curve)\\n3. Finite Field: Prime-order subgroup of the group of points on the `bn254` curve\\n4. Default Merkle Tree Height: `20`\\n5. Hashing algorithm: [`Poseidon`](https://eprint.iacr.org/2019/458.pdf)\\n6. Merkle Tree: [`Sparse Indexed Merkle Tree`](https://github.com/rate-limiting-nullifier/pmtree)\\n7. Messages per epoch: `1`\\n8. Epoch duration: `10 seconds`\\n\\n## Malicious User secret interpolation mechanism\\n\\n> note: all the parameters mentioned below are elements in the finite field mentioned above.\\n\\nThe private inputs to the circuit are as follows: -\\n```\\nidentitySecret: the randomly generated secret of the user\\nidentityPathIndex: the index of the commitment derived from the secret\\npathElements: elements included in the path to the index of the commitment\\n```\\n\\nFollowing are the public inputs to the circuit -\\n```\\nx: hash of the signal to the finite field\\nrlnIdentifier: application-specific identifier which this proof is being generated for\\nepoch: the timestamp which this proof is being generated for\\n```\\n\\nThe outputs of the circuit are as follows: -\\n```\\ny: result of Shamir\'s secret sharing calculation\\nroot: root of the Merkle tree obtained after applying the inclusion proof\\nnullifier: uniquely identifies a message, derived from rlnIdentifier, epoch, and the user\'s secret\\n```\\n\\nWith the above data in mind, following is the circuit pseudocode -\\n\\n```\\nidentityCommitment = Poseidon([identitySecret])\\nroot = MerkleInclusionProof(identityCommitment, identityPathIndex, pathElements)\\nexternalNullifier = Poseidon([epoch, rlnIdentifier])\\na1 = Poseidon([identitySecret, externalNullifier])\\ny = identitySecret + a1 * x\\nnullifier = Poseidon([a1])\\n```\\n\\nTo interpolate the secret of a user who has sent multiple signals during the same epoch to the same rln-based application, we may make use of the following formula -\\n\\n$$a_1 = {(y_1 - y_2) \\\\over (x_1 - x_2)}$$\\n\\nwhere $x_1$, $y_1$ and $x_2$, $y_2$ are shares from different messages\\n\\nsubsequently, we may use one pair of the shares, $x_1$ and $y_1$ to obtain the `identitySecret`\\n\\n$$identitySecret = y_1 - a_1 * x$$\\n\\nThis enables RLN to be used for rate limiting with a *global* limit. For arbitrary limits,\\nplease refer to an article written by @curryrasul, [rln-v2](https://mirror.xyz/privacy-scaling-explorations.eth/iCLmH1JVb7fDqp6Mms2NR001m2_n5OOSHsLF2QrxDnQ).\\n\\n\\n## Waku\'s problem with DoS\\n\\nIn a decentralized, privacy focused messaging system like [Waku](https://waku.org),\\nDenial of Service (DoS) vulnerabilities are very common, and must be addressed to promote network scale and optimal bandwidth utilization.\\n\\n### DoS prevention with user metadata\\n\\nThere are a couple of ways a user can be rate-limited, either -\\n1. IP Logging\\n2. KYC Logging\\n\\nBoth IP and KYC logging prevent systems from being truly anonymous, and hence, cannot be used as a valid DoS prevention mechanism for Waku.\\n\\nRLN can be used as an alternative, which provides the best of both worlds, i.e a permissioned membership set, as well as anonymous signaling.\\nHowever, we are bound by k-anonymity rules of the membership set.\\n\\n[Waku-RLN-Relay](https://rfc.vac.dev/spec/17/) is a [libp2p](https://libp2p.io) pubsub validator that verifies if a proof attached to a given message is valid.\\nIn case the proof is valid, the message is relayed.\\n\\n## Performance analysis\\n\\n> Test bench specs: AMD EPYC 7502P 32-Core, 4x32GB DDR4 Reg.ECC Memory \\n\\nThis simulation was conducted by @alrevuelta, and is described in more detail [here](https://github.com/waku-org/research/issues/23).\\n\\nThe simulation included 100 waku nodes running in parallel.\\n\\nProof generation times - \\n![img](/img/rln-relay-2023-update//proof_generation_time.png)\\n\\nProof verification times -\\n![img](/img/rln-relay-2023-update/proof_verification_time.png)\\n\\nA spammer node publishes 3000 msg/epoch, which is detected by all connected nodes, and subsequently disconnect to prevent further spam -\\n![img](/img/rln-relay-2023-update/spam_prevention_in_action.png)\\n\\n\\n## Security analysis\\n\\n[Barbulescu and Duquesne](https://doi.org/10.1007/s00145-018-9280-5)\\nconclude that that the `bn254` curve has only 100 bits of security.\\nSince the bn254 curve has a small embedding degree,\\nit is vulnerable to the [MOV attack](https://en.wikipedia.org/wiki/MOV_attack).\\nHowever, the MOV attack is only applicable to pairings,\\nand not to the elliptic curve itself.\\nIt is acceptable to use the bn254 curve for RLN,\\nsince the circuit does not make use of pairings.\\n\\n[An analysis](https://github.com/vacp2p/research/issues/155) on the number of rounds in the Poseidon hash function was done,\\nwhich concluded that the hashing rounds should *not* be reduced, \\n\\nThe [smart contracts](https://github.com/vacp2p/rln-contract) have *not* been audited, and are not recommended for real world deployments *yet*.\\n\\n\\n## Storage analysis\\n\\n$$\\ncommitment\\\\_size = 32\\\\ bytes \\\\\\\\\\ntree\\\\_height =20 \\\\\\\\\\ntotal\\\\_leaves = 2^{20} \\\\\\\\ \\nmax\\\\_tree\\\\_size = total\\\\_leaves * commitment\\\\_size \\\\\\\\\\nmax\\\\_tree\\\\_size = 2^{20} * 32 = 33,554,432 \\\\\\\\\\n\u2234max\\\\_tree\\\\_size = 33.55\\\\ megabytes\\n$$\\nThe storage overhead introduced by RLN is minimal.\\nRLN only requires 34 megabytes of storage, which poses no problem on most end-user hardware, with the exception of IoT/microcontrollers.\\nStill, we are working on further optimizations  allowing proof generation without having to store the full tree.\\n\\n## The bare minimum requirements to run RLN\\n\\nWith proof generation time in sub-second latency, along with low storage overhead for the tree,\\nit is possible for end users to generate and verify RLN proofs on a modern smartphone.\\n\\nFollowing is a demo provided by @rramos that demonstrates\\n[waku-rln-relay used in react native](https://drive.google.com/file/d/1ITLYrDOQrHQX2_3Q6O5EqKPYJN8Ye2gF/view?usp=sharing).\\n\\n> Warning: The react native sdk will be deprecated soon, and the above demo should serve as a PoC for RLN on mobiles\\n\\n## RLN usage guide\\n\\n[Zerokit](https://github.com/vacp2p/zerokit) implements api\'s that allow users to handle operations to the tree, \\nas well as generate/verify RLN proofs.\\n\\nOur main implementation of RLN can be accessed via this Rust [crate](https://crates.io/crates/rln),\\nwhich is documented [here](https://docs.rs/rln/0.4.1/rln/public/struct.RLN.html).\\nIt can used in other langugages via the FFI API, which is documented [here](https://docs.rs/rln/0.4.1/rln/ffi/index.html).\\nThe usage of RLN in Waku is detailed in our [RLN Implementers guide](https://hackmd.io/7cBCMU5hS5OYv8PTaW2wAQ?view),\\nwhich provides step-by-step instructions on how to run Waku-RLN-Relay.\\n\\nFollowing is a diagram that will help understand the dependency tree -\\n\\n![rln-dep-tree](/img/rln-relay-2023-update/rln_dep_tree.jpg)\\n\\n## Future work\\n\\n- Optimizations to zerokit for proof generation time.\\n- Incrementing tree depth from 20 to 32, to allow more memberships.\\n- Optimizations to the smart contract.\\n- An ability to signal validity of a message in different time windows.\\n- Usage of proving systems other than Groth16.\\n\\n## References\\n\\n* [RLN Circuits](https://github.com/rate-limiting-nullifier/circom-rln)\\n* [Zerokit](https://github.com/vacp2p/zerokit)\\n* [RLN-V1 RFC](https://rfc.vac.dev/spec/32/)\\n* [RLN-V2 RFC](https://rfc.vac.dev/spec/58/)\\n* [RLN Implementers guide](https://hackmd.io/7cBCMU5hS5OYv8PTaW2wAQ?view)\\n* [groth16](https://eprint.iacr.org/2016/260.pdf)\\n* [bn254](https://eprint.iacr.org/2013/879.pdf)\\n* [Poseidon Hash](https://eprint.iacr.org/2019/458.pdf)\\n* [Sparse Indexed Merkle Tree](https://github.com/rate-limiting-nullifier/pmtree)\\n* [Updating key size estimations for pairings](https://doi.org/10.1007/s00145-018-9280-5)"},{"id":"GossipSub Improvements","metadata":{"permalink":"/rlog/GossipSub Improvements","source":"@site/rlog/2023-09-27-gossipimprovements.mdx","title":"GossipSub Improvements: Evolution of Overlay Design and Message Dissemination in Unstructured P2P Networks","description":"GossipSub Improvements: Evolution of Overlay Design and Message Dissemination in Unstructured P2P Networks","date":"2023-11-06T12:00:00.000Z","formattedDate":"November 6, 2023","tags":[],"readingTime":13.815,"hasTruncateMarker":true,"authors":[{"name":"Umar Farooq","github":"ufarooqstatus","key":"farooq"}],"frontMatter":{"title":"GossipSub Improvements: Evolution of Overlay Design and Message Dissemination in Unstructured P2P Networks","date":"2023-11-06T12:00:00.000Z","authors":"farooq","published":true,"slug":"GossipSub Improvements","categories":"research","toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"Strengthening Anonymous DoS Prevention with Rate Limiting Nullifiers in Waku","permalink":"/rlog/rln-anonymous-dos-prevention"},"nextItem":{"title":"Nescience - A zkVM leveraging hiding properties","permalink":"/rlog/Nescience-A-zkVM-leveraging-hiding-properties"}},"content":"GossipSub Improvements: Evolution of Overlay Design and Message Dissemination in Unstructured P2P Networks \\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\n## Motivitation\\r\\nWe have been recently working on analyzing and improving the performance of the GossipSub protocol for large messages, \\r\\nas in the case of Ethereum Improvement Proposal [EIP-4844](https://eips.ethereum.org/EIPS/eip-4844).\\r\\nThis work led to a comprehensive study of unstructured P2P networks. \\r\\nThe intention was to identify the best practices that can serve as guidelines for performance improvement and scalability of P2P networks.\\r\\n\\r\\n## Introduction\\r\\n\\r\\nNodes in an unstructured p2p network form self-organizing overlay(s) on top of the IP infrastructure to facilitate different services like information dissemination,\\r\\nquery propagation, file sharing, etc. The overlay(s) can be as optimal as a tree-like structure or as enforcing as a fully connected mesh. \\r\\n\\r\\nDue to peer autonomy and a trustless computing environment, some peers may deviate from the expected operation or even leave the network.\\r\\nAt the same time, the underlying IP layer is unreliable. \\r\\n\\r\\nTherefore, tree-like overlays are not best suited for reliable information propagation.\\r\\nMoreover, tree-based solutions usually result in significantly higher message dissemination latency due to suboptimal branches. \\r\\n\\r\\nFlooding-based solutions, on the other hand, result in maximum resilience against adversaries and achieve minimal message dissemination latency because the message propagates through all (including the optimal) paths. \\r\\nRedundant transmissions help maintain the integrity and security of the network in the presence of adversaries and high node failure but significantly increase network-wide bandwidth utilization, cramming the bottleneck links. \\r\\n\\r\\nAn efficient alternative is to lower the number of redundant transmissions by D-regular broadcasting, where a peer will likely receive (or relay) a message from up to $D$ random peers.\\r\\nPublishing through a D-regular overlay triggers approximately $N \\\\times D$ transmissions.\\r\\nReducing $D$ reduces the redundant transmissions but compromises reachability and latency. \\r\\nSharing metadata through a K-regular overlay (where $K > D$) allows nodes to pull missing messages. \\r\\n\\r\\nGossipSub [[1](https://arxiv.org/pdf/2007.02754.pdf)] benefits from full-message (D-regular) and metadata-only (k-regular) overlays.\\r\\nAlternatively, a metadata-only overlay can be used, requiring a pull-based operation that significantly minimizes bandwidth utilization at the cost of increased latency. \\r\\n\\r\\nStriking the right balance between parameters like $D, K$, pull-based operation, etc., can yield application-specific performance tuning, but scalability remains a problem.\\r\\n\\r\\nAt the same time, many other aspects can significantly contribute to the network\'s performance and scalability.\\r\\nOne option is to realize peers\' suitability and continuously changing capabilities while forming overlays. \\r\\n\\r\\nFor instance, a low-bandwidth link near a publisher can significantly demean the entire network\'s performance.\\r\\nReshuffling of peering links according to the changing network conditions can lead to superior performance. \\r\\n\\r\\nLaying off additional responsibilities to more capable nodes (super nodes) can alleviate peer cramming, but it makes the network susceptible to adversaries/peer churn.\\r\\nGrouping multiple super nodes to form virtual node(s) can solve this problem. \\r\\n\\r\\n\\r\\nSimilarly, flat (single-tier) overlays cannot address the routing needs in large (geographically dispersed) networks.\\r\\n\\r\\nHierarchical (Multi-tier) overlays with different intra/inter-overlay routing solutions can better address these needs.\\r\\nMoreover, using message aggregation schemes for grouping multiple messages can save bandwidth and provide better resilience against adversaries/peer churn.\\r\\n\\r\\n\\r\\nThis article\'s primary objective is to investigate the possible choices that can empower an unstructured P2P network to achieve superior performance for the broadest set of applications. \\r\\nWe look into different constraints imposed by application-specific needs (performance goals) and investigate various choices that can augment the network\'s performance. \\r\\nWe explore overlay designs/freshness, peer selection approaches, message-relaying mechanisms, and resilience against adversaries/peer churn. \\r\\nWe consider GossipSub a baseline protocol to explore various possibilities and decisively commit to the ones demonstrating superior performance.\\r\\nWe also discuss the current state and, where applicable, propose a strategic plan for embedding new features to the GossipSub protocol. \\r\\n\\r\\n\\r\\n## GOAL1: Low Latency Operation\\r\\nDifferent applications, like blockchain, streaming, etc., impose strict time bounds on network-wide message dissemination latency. \\r\\nA message delivered after the imposed time bounds is considered as dropped. \\r\\nAn early message delivery in applications like live streaming can further enhance the viewing quality.\\r\\n\\r\\nThe properties and nature of the overlay network topology significantly impact the performance of services and applications executed on top of them. \\r\\nStudying and devising mechanisms for better overlay design and message dissemination is paramount to achieving superior performance.\\r\\n\\r\\nInterestingly, shortest-path message delivery trees have many limitations: \\r\\n\\r\\n1) Changing network dynamics requires a quicker and continuous readjustment of the multicast tree. \\r\\n2) The presence of resource-constrained (bandwidth/compute, etc.) nodes in the overlay can result in congestion. \\r\\n3) Node failure can result in partitions, making many segments unreachable. \\r\\n4) Assuring a shortest-path tree-like structure requires a detailed view of the underlying (and continuously changing) network topology. \\r\\n\\r\\n\\r\\nSolutions involve creating multiple random trees to add redundancy [[2](https://ieeexplore.ieee.org/abstract/document/6267905)].\\r\\nAlternatives involve building an overlay mesh and forwarding messages through the multicast delivery tree (eager push). \\r\\n\\r\\nMetadata is shared through the overlay links so that the nodes can ask for missing messages (lazy push or pull-based operation) through the overlay links. \\r\\nNew nodes are added from the overlay on node failure, but it requires non-faulty node selection.\\r\\n\\r\\nGossipSub uses eager push (through overlay mesh) and lazy push (through IWANT messages). \\r\\n\\r\\nThe mesh degree $D_{Low} \\\\leq D \\\\leq D_{High}$ is crucial in deciding message dissemination latency. \\r\\nA smaller value for $D$ results in higher latency due to increased rounds, whereas a higher $D$ reduces latency on the cost of increased bandwidth. \\r\\nAt the same time, keeping $D$ independent of the growing network size ($N$) may increase network-wide message dissemination latency.\\r\\nAdjusting $D$ with $N$ maintains similar latency on the cost of increased workload for peers. \\r\\nAuthors in [[3](https://infoscience.epfl.ch/record/83478/files/EugGueKerMas04IEEEComp.pdf)] suggest only a logarithmic increase in $D$ to maintain a manageable workload for peers.\\r\\nIn [[4](https://inria.hal.science/tel-02375909/document)], it is reported that the average mesh degree should not exceed $D_{avg} = \\\\ln(N) + C$ for an optimal operation, \\r\\nwhere $C$ is a small constant.\\r\\n\\r\\nMoreover, quicker shuffling of peers results in better performance in the presence of resource-constrained nodes or node failure [[4](https://inria.hal.science/tel-02375909/document)].\\r\\n\\r\\n## GOAL2: Considering Heterogeneity In Overlay Design\\r\\nRandom peering connections in P2P overlays represent a stochastic process. It is inherently difficult to precisely model the performance of such systems. \\r\\nMost of the research on P2P networks provides simulation results assuming nodes with similar capabilities. \\r\\nThe aspect of dissimilar capabilities and resource-constrained nodes is less explored.\\r\\n\\r\\nIt is discussed in GOAL1 that overlay mesh results in better performance if  $D_{avg}$ does not exceed $\\\\ln(N) + C$. \\r\\nEnforcing all the nodes to have approximately $\\\\ln(N) + C$ peers makes resource-rich nodes under-utilized, while resource-constrained nodes are overloaded. \\r\\nAt the same time, connecting high-bandwidth nodes through a low-bandwidth node undermines the network\'s performance.\\r\\nIdeally, the workload on any node should not exceed its available resources.\\r\\nA better solution involves a two-phased operation:\\r\\n\\r\\n\\r\\n1. Every node computes its available bandwidth and selects a node degree $D$ proportional to its available bandwidth [[4](https://inria.hal.science/tel-02375909/document)].\\r\\n    Different bandwidth estimation approaches are suggested in literature [[5](https://ieeexplore.ieee.org/abstract/document/1224454),[6](https://ieeexplore.ieee.org/abstract/document/1248658)]. \\r\\n    Simple bandwidth estimation approaches like variable packet size probing [[6](https://ieeexplore.ieee.org/abstract/document/1248658)] yield similar results with less complexity.\\r\\n    It is also worth mentioning that many nodes may want to allocate only a capped share of their bandwidth to the network. \\r\\n    Lowering $D$ according to the available bandwidth can still prove helpful. \\r\\n    Additionally, bandwidth preservation at the transport layer through approaches like \xb5TP can be useful.\\r\\n    To further conform to the suggested mesh-degree average $D_{avg}$, every node tries achieving this average within its neighborhood, resulting in an overall similar $D_{avg}$.\\r\\n\\r\\n2. From the available local view, every node tries connecting peers with the lowest latency until $D$ connections are made.\\r\\n    We suggest referring to the peering solution discussed in GOAL5 to avoid network partitioning.\\r\\n\\r\\nThe current GossipSub design considers homogeneous peers, and every node tries maintaining $D_{Low} \\\\leq D \\\\leq D_{High}$ connections. \\r\\n\\r\\n\\r\\n## GOAL3: Bandwidth Optimization\\r\\nRedundant message transmissions are essential for handling adversaries/node failure. However, these transmissions result in traffic bursts, cramming many overlay links. \\r\\nThis not only adds to the network-wide message dissemination latency but a significant share of the network\'s bandwidth is wasted on (usually) unnecessary transmissions. \\r\\nIt is essential to explore solutions that can minimize the number of redundant transmissions while assuring resilience against node failures. \\r\\n\\r\\nMany efforts have been made to minimize the impact of redundant transmissions. \\r\\nThese solutions include multicast delivery trees, metadata sharing to enable pull-based operation, in-network information caching, etc. [[7](https://dl.acm.org/doi/abs/10.1145/945445.945473),[8](https://link.springer.com/chapter/10.1007/11558989_12)]. \\r\\nGossipSub employs a hybrid of eager push (message dissemination through the overlay) and lazy push (a pull-based operation by the nodes requiring information through IWANT messages). \\r\\n\\r\\nA better alternative to simple redundant transmission is to use message aggregation [[9](https://ieeexplore.ieee.org/abstract/document/8737576),[10](https://dl.acm.org/doi/abs/10.1145/1993636.1993676),[11](https://ieeexplore.ieee.org/abstract/document/4276446)] for the GossipSub protocol. \\r\\nAs a result, redundant message transmissions can serve as a critical advantage of the GossipSub protocol. \\r\\nSuppose that we have three equal-length messages $x1, x2, x3$. Assuming an XOR coding function,\\r\\nwe know two trivial properties: $x1 \\\\oplus x2 \\\\oplus x2 = x1$ and $\\\\vert x1 \\\\vert = \\\\vert x1 \\\\oplus x2 \\\\oplus x2 \\\\vert$. \\r\\n\\r\\nThis implies that instead of sending messages individually, we can encode and transmit composite message(s) to the network. \\r\\nThe receiver can reconstruct the original message from encoded segments. \\r\\nAs a result, fewer transmissions are sufficient for sending more messages to the network. \\r\\n\\r\\nHowever, sharing linear combinations of messages requires organizing messages in intervals, \\r\\nand devising techniques to identify all messages belonging to each interval.\\r\\nIn addition, combining messages from different publishers requires more complex arrangements, \\r\\ninvolving embedding publisher/message IDs, delayed forwarding (to accommodate more messages), and mechanisms to ensure the decoding of messages at all peers.\\r\\nCareful application-specific need analysis can help decide the benefits against the added complexity. \\r\\n\\r\\n## GOAL4: Handling Large Messages\\r\\nMany applications require transferring large messages for their successful operation. For instance, database/blockchain transactions [[12](https://eips.ethereum.org/EIPS/eip-4844)]. \\r\\nThis introduces two challenges: \\r\\n\\r\\n1) Redundant large message transmissions result in severe network congestion. \\r\\n2) Message transmissions follow a store/forward process at all peers, which is inefficient in the case of large messages. \\r\\n\\r\\nThe above-mentioned challenges result in a noticeable increase in message dissemination latency and bandwidth wastage. \\r\\nMost of the work done for handling large messages involves curtailing redundant transmissions using multicast delivery trees,\\r\\nreducing the number of fanout nodes, employing in-network message caching, pull-based operation, etc.\\r\\n\\r\\nApproaches like message aggregation also prove helpful in minimizing bandwidth wastage.\\r\\n\\r\\nOur recent work on GossipSub improvements (still a work in progress) suggests the following solutions to deal with large message transmissions: \\r\\n\\r\\n1. Using IDontWant message proposal [[13](https://github.com/libp2p/specs/pull/413)] and staggered sending. \\r\\n\\r\\n    IDontWant message helps curtail redundant transmissions by letting other peers know we have already received the message.\\r\\n    Staggered sending enables relaying the message to a short subset of peers in each round.\\r\\n    We argue that simultaneously relaying a message to all peers hampers the effectiveness of the IDontWant message.\\r\\n    Therefore, using the IDontWant message with staggered sending can yield better results by allowing timely reception and processing of IDontWant messages.\\r\\n\\r\\n2. Message transmissions follow a store/forward process at all peers that is inefficient in the case of large messages.\\r\\n    We can parallelize message transmission by partitioning large messages into smaller fragments, letting intermediate peers relay these fragments as soon as they receive them.\\r\\n\\r\\n\\r\\n## GOAL5: Scalability\\r\\nP2P networks are inherently scalable because every incoming node brings in bandwidth and compute resources.\\r\\nIn other words, we can keep adding nodes to the network as long as every incoming node brings at-least $R \\\\times D$ bandwidth, \\r\\nwhere $R$ is average data arrival rate. \\r\\nIt is worth mentioning that network-wide message dissemination requires at-least $\\\\lceil \\\\log_D (N) \\\\rceil$ hops. \\r\\nTherefore, increasing network size increases message dissemination latency, assuming D is independent of the network size.\\r\\n\\r\\nAdditionally, problems like peer churn, adversaries, heterogeneity, distributed operation, etc., significantly hamper the network\'s performance.\\r\\nMost efforts for bringing scalability to the P2P systems have focused on curtailing redundant transmissions and flat overlay adjustments.\\r\\nHierarchical overlay designs, on the other hand, are less explored.\\r\\n\\r\\nPlacing a logical structure in unstructured P2P systems can help scale P2P networks. \\r\\n\\r\\nOne possible solution is to use a hierarchical overlay inspired by the approaches [[14](https://link.springer.com/article/10.1007/s12083-016-0460-5),[15](https://link.springer.com/chapter/10.1007/978-3-030-19223-5_16),[16](https://ieeexplore.ieee.org/abstract/document/9826458)]. \\r\\nAn abstract operation of such overlay design is provided below:\\r\\n\\r\\n1. Clustering nodes based on locality, assuming that such peers will have relatively lower intra-cluster latency and higher bandwidth. \\r\\n    For this purpose, every node tries connecting peers with the lowest latency until $D$ connections are made or the cluster limit is reached.\\r\\n\\r\\n2. A small subset of nodes having the highest bandwidth and compute resources is selected from each cluster. \\r\\n    These super nodes form a fully connected mesh and jointly act as a virtual node, \\r\\n    mitigating the problem of peer churn among super nodes.\\r\\n    \\r\\n3. Virtual nodes form a fully connected mesh to construct a hierarchical overlay. \\r\\n    Each virtual node is essentially a collection of super nodes; \\r\\n    a link to any of the constituent super nodes represents a link to the virtual node.\\r\\n\\r\\n4. One possible idea is to use GossipSub for intra-cluster message dissemination and FloodSub for inter-cluster message dissemination.\\r\\n\\r\\n## Summary\\r\\nOverlay acts as a virtual backbone for a P2P network. A flat overlay is more straightforward and allows effortless readjustment to application needs. \\r\\nOn the other hand, a hierarchical overlay can bring scalability at the cost of increased complexity. \\r\\nRegardless of the overlay design, a continuous readjustment to appropriate peering links is essential for superior performance. \\r\\nAt the same time, bandwidth preservation (through message aggregation, caching at strategic locations, metadata sharing, pull-based operation, etc.) can help minimize latency.\\r\\nHowever, problems like peer churn and in-network adversaries can be best alleviated through balanced redundant coverage, and frequent reshuffling of the peering links.\\r\\n\\r\\n# References\\r\\n\\r\\n* [1] D. Vyzovitis, Y. Napora, D. McCormick, D. Dias, and Y. Psaras, \u201cGossipsub: Attack-resilient message propagation in the filecoin and eth2. 0 networks,\u201d arXiv preprint arXiv:2007.02754, 2020. Retrieved from https://arxiv.org/pdf/2007.02754.pdf\\r\\n* [2] M. Matos, V. Schiavoni, P. Felber, R. Oliveira, and E. Riviere, \u201cBrisa: Combining efficiency and reliability in epidemic data dissemination,\u201d in 2012 IEEE 26th International Parallel and Distributed Processing Symposium. IEEE, 2012, pp. 983\u2013994. Retrieved from https://ieeexplore.ieee.org/abstract/document/6267905\\r\\n* [3] P. T. Eugster, R. Guerraoui, A. M. Kermarrec, and L. Massouli, \u201cEpidemic information dissemination in distributed systems,\u201d IEEE Computer, vol. 37, no. 5, 2004.  Retrieved from https://infoscience.epfl.ch/record/83478/files/EugGueKerMas04IEEEComp.pdf\\r\\n* [4] D. Frey, \u201cEpidemic protocols: From large scale to big data,\u201d Ph.D. dissertation, Universite De Rennes 1, 2019. Retrieved from https://inria.hal.science/tel-02375909/document\\r\\n* [5] M. Jain and C. Dovrolis, \u201cEnd-to-end available bandwidth: measurement methodology, dynamics, and relation with tcp throughput,\u201d IEEE/ACM Transactions on networking, vol. 11, no. 4, pp. 537\u2013549, 2003. Retrieved from https://ieeexplore.ieee.org/abstract/document/1224454\\r\\n* [6] R. Prasad, C. Dovrolis, M. Murray, and K. Claffy, \u201cBandwidth estimation: metrics, measurement techniques, and tools,\u201d IEEE network, vol. 17, no. 6, pp. 27\u201335, 2003. Retrieved from https://ieeexplore.ieee.org/abstract/document/1248658\\r\\n* [7] D. Kostic, A. Rodriguez, J. Albrecht, and A. Vahdat, \u201cBullet: High bandwidth data dissemination using an overlay mesh,\u201d in Proceedings of the nineteenth ACM symposium on Operating systems principles, 2003, pp. 282\u2013297. Retrieved from https://dl.acm.org/doi/abs/10.1145/945445.945473\\r\\n* [8] V. Pai, K. Kumar, K. Tamilmani, V. Sambamurthy, and A. E. Mohr, \u201cChainsaw: Eliminating trees from overlay multicast,\u201d in Peer-to-Peer Systems IV: 4th International Workshop, IPTPS 2005, Ithaca, NY, USA, February 24-25, 2005. Revised Selected Papers 4. Springer, 2005, pp. 127\u2013140. Retrieved from https://link.springer.com/chapter/10.1007/11558989_12\\r\\n* [9] Y.-D. Bromberg, Q. Dufour, and D. Frey, \u201cMultisource rumor spreading with network coding,\u201d in IEEE INFOCOM 2019-IEEE Conference on Computer Communications. IEEE, 2019, pp. 2359\u20132367. Retrieved from https://ieeexplore.ieee.org/abstract/document/8737576\\r\\n* [10] B. Haeupler, \u201cAnalyzing network coding gossip made easy,\u201d in Proceedings of the forty-third annual ACM symposium on Theory of computing, 2011, pp. 293\u2013302. Retrieved from https://dl.acm.org/doi/abs/10.1145/1993636.1993676\\r\\n* [11] S. Yu and Z. Li, \u201cMassive data delivery in unstructured peer-to-peer networks with network coding,\u201d in 6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007). IEEE, 2007, pp. 592\u2013597. Retrieved from https://ieeexplore.ieee.org/abstract/document/4276446\\r\\n* [12] V. Buterin, D. Feist, D. Loerakker, G. Kadianakis, M. Garnett, M. Taiwo, and A. Dietrichs, \u201cEip-4844: Shard blob transactions scale data-availability of ethereum in a simple, forwards-compatible manner,\u201d 2022. Retrieved from https://eips.ethereum.org/EIPS/eip-4844\\r\\n* [13] A. Manning, \u201cGossipsub extension for epidemic meshes (v1.2.0),\u201d 2022. Retrieved from https://github.com/libp2p/specs/pull/413\\r\\n* [14] Z. Duan, C. Tian, M. Zhou, X. Wang, N. Zhang, H. Du, and L. Wang, \u201cTwo-layer hybrid peer-to-peer networks,\u201d Peer-to-Peer Networking and Applications, vol. 10, pp. 1304\u20131322, 2017. Retrieved from https://link.springer.com/article/10.1007/s12083-016-0460-5\\r\\n* [15] W. Hao, J. Zeng, X. Dai, J. Xiao, Q. Hua, H. Chen, K.-C. Li, and H. Jin, \u201cBlockp2p: Enabling fast blockchain broadcast with scalable peer-to-peer network topology,\u201d in Green, Pervasive, and Cloud Computing: 14th International Conference, GPC 2019, Uberlandia, Brazil, May 26\u201328, 2019, Proceedings 14. Springer, 2019, pp. 223\u2013237. Retrieved from https://link.springer.com/chapter/10.1007/978-3-030-19223-5_16\\r\\n* [16] H. Qiu, T. Ji, S. Zhao, X. Chen, J. Qi, H. Cui, and S. Wang, \u201cA geography-based p2p overlay network for fast and robust blockchain systems,\u201d IEEE Transactions on Services Computing, 2022. Retrieved from https://ieeexplore.ieee.org/abstract/document/9826458"},{"id":"Nescience-A-zkVM-leveraging-hiding-properties","metadata":{"permalink":"/rlog/Nescience-A-zkVM-leveraging-hiding-properties","source":"@site/rlog/2023-08-28-Nescience.mdx","title":"Nescience - A zkVM leveraging hiding properties","description":"Nescience, a privacy-first blockchain zkVM.","date":"2023-08-28T12:00:00.000Z","formattedDate":"August 28, 2023","tags":[],"readingTime":31.34,"hasTruncateMarker":true,"authors":[{"name":"Moudy","github":"moudyellaz","key":"moudy"}],"frontMatter":{"title":"Nescience - A zkVM leveraging hiding properties","date":"2023-08-28T12:00:00.000Z","authors":"moudy","published":true,"slug":"Nescience-A-zkVM-leveraging-hiding-properties","categories":"research","toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"GossipSub Improvements: Evolution of Overlay Design and Message Dissemination in Unstructured P2P Networks","permalink":"/rlog/GossipSub Improvements"},"nextItem":{"title":"Device Pairing in Js-waku and Go-waku","permalink":"/rlog/device-pairing-in-js-waku-and-go-waku"}},"content":"Nescience, a privacy-first blockchain zkVM. \\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nNescience is a privacy-first blockchain project that aims to enable private transactions and provide a general-purpose execution environment for classical applications. \\nThe goals include creating a state separation architecture for public/private computation, \\ndesigning a versatile virtual machine based on mainstream instruction sets, \\ncreating proofs for private state updates, implementing a kernel-based architecture for correct execution of private functions, \\nand implementing core DeFi protocols such as AMMs and staking from a privacy perspective. \\n\\nIt intends to create a user experience that is similar to public blockchains, but with additional privacy features that users can leverage at will. \\nTo achieve this goal, Nescience will implement a versatile virtual machine that can be used to implement existing blockchain applications, \\nwhile also enabling the development of privacy-centric protocols such as private staking and private DEXs.\\n\\nTo ensure minimal trust assumptions and prevent information leakage, Nescience proposes a proof system that allows users to create proofs for private state updates, \\nwhile the verification of the proofs and the execution of the public functions inside the virtual machine can be delegated to an external incentivised prover. \\n\\nIt also aims to implement a seamless interaction between public and private state, enabling composability between contracts, and private and public functions. \\nFinally, Nescience intends to implement permissive licensing, which means that the source code will be open-source, \\nand developers will be able to use and modify the code without any restriction.\\n\\nOur primary objective is the construction of the Zero-Knowledge Virtual Machine (zkVM). This document serves as a detailed exploration of the multifaceted challenges, \\npotential solutions, and alternatives that lay ahead. Each step is a testament to our commitment to thoroughness; \\nwe systematically test various possibilities and decisively commit to the one that demonstrates paramount performance and utility. \\nFor instance, as we progress towards achieving Goal 2, we are undertaking a rigorous benchmarking of the Nova proof system against its contemporaries. \\nShould Nova showcase superior performance metrics, we stand ready to integrate it as our proof system of choice. Through such meticulous approaches, \\nwe not only reinforce the foundation of our project but also ensure its scalability and robustness in the ever-evolving landscape of blockchain technology.\\n\\n\\n## Goal 1: Create a State Separation Architecture\\n\\nThe initial goal revolves around crafting a distinctive architecture that segregates public and private computations, \\nemploying an account-based framework for the public state and a UTXO-based structure for the private state. \\n\\nThe UTXO model [[1]( https://bitcoin.org/bitcoin.pdf),[2](https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/)], notably utilized in Bitcoin, generates new UTXOs to serve future transactions, \\nwhile the account-based paradigm assigns balances to accounts that transactions can modify. \\nAlthough the UTXO model bolsters privacy by concealing comprehensive balances, \\nthe pursuit of a dual architecture mandates a meticulous synchronization of these state models, \\nensuring that private transactions remain inconspicuous in the wider public network state. \\n\\nThis task is further complicated by the divergent transaction processing methods intrinsic to each model, \\nnecessitating a thoughtful and innovative approach to harmonize their functionality. \\nTo seamlessly bring together the dual architecture, harmonizing the account-based model for public state with the UTXO-based model for private state, \\na comprehensive strategy is essential.\\n\\nThe concept of blending an account-based structure with a UTXO-based model for differentiating between public and private states is intriguing. \\nIt seeks to leverage the strengths of both models: the simplicity and directness of the account-based model with the privacy enhancements of the UTXO model.\\n\\nHere\'s a breakdown and a potential strategy for harmonizing these models:\\n\\n### <ins> Rationale Behind the Dual Architecture: </ins>\\n\\n* **Account-Based Model:** This model is intuitive and easy to work with. Every participant has an account, \\nand transactions directly modify the balances of these accounts. It\'s conducive for smart contracts and a broad range of applications.\\n\\n* **UTXO-Based Model:** This model treats every transaction as a new output, which can then be used as an input for future transactions. \\nBy not explicitly associating transaction outputs with user identities, it offers a degree of privacy.\\n\\n### <ins> Harmonizing the Two Systems: </ins>\\n\\n1. Translation Layer\\n\\n    * Role: Interface between UTXO and account-based states.\\n\\n    * _UTXO-to-Account Adapter:_  When UTXOs are spent, the adapter can translate these into the corresponding account balance modifications. \\n    This could involve creating a temporary \'pseudo-account\' that mirrors the \\n    UTXO\'s attributes.\\n\\n    * _Account-to-UTXO Adapter:_ When an account wishes to make a private transaction, \\n    it would initiate a process converting a part of its balance to a UTXO, facilitating a privacy transaction.\\n\\n2. Unified Identity Management\\n\\n    * Role: Maintain a unified identity (or address) system that works across both state models, \\n    allowing users to easily manage their public and private states without requiring separate identities.\\n\\n    * _Deterministic Wallets:_ Use Hierarchical Deterministic (HD) wallets [[3](https://medium.com/mycrypto/the-journey-from-mnemonic-phrase-to-address-6c5e86e11e14),[4](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki)], enabling users to generate multiple addresses (both UTXO and account-based) from a single seed. \\n     This ensures privacy while keeping management centralized for the user.\\n\\n\\n3. State Commitments\\n\\n    * Role: Use cryptographic commitments to commit to the state of both models. This can help in efficiently validating cross-model transactions.\\n   \\n    * _Verkle Trees:_ Verkle Trees combine Vector Commitment and the KZG polynomial commitment scheme to produce a structure that\'s efficient in terms of both proofs and verification.\\n    Verkle proofs are considerably small in size (less data to store and transmit), where Transaction and state verifications can be faster due to the smaller proof sizes and computational efficiencies.\\n\\n    * _Mimblewimble-style Aggregation_ [[5](https://github.com/mimblewimble/grin/blob/master/doc/intro.md)]: For UTXOs, techniques similar to those used in Mimblewimble can be used to aggregate transactions, keeping the state compact and enhancing privacy.\\n\\n\\n4. Batch Processing & Anonymity Sets\\n\\n    * Role: Group several UTXO-based private transactions into a single public account-based transaction. \\n    This can provide a level of obfuscation and can make synchronization between the two models more efficient.\\n\\n    * _CoinJoin Technique_ [[6](https://en.bitcoin.it/wiki/CoinJoin)]: As seen in Bitcoin, multiple users can combine their UTXO transactions into one, enhancing privacy.\\n\\n    * _Tornado Cash Principle_ [[7](https://github.com/tornadocash/tornado-classic-ui)]: For account-based systems wanting to achieve privacy, methods like those used in Tornado Cash can be implemented, \\n    providing zk-SNARKs-based private transactions.\\n\\n5. Event Hooks & Smart Contracts\\n\\n    * Role: Implement event-driven mechanisms that trigger specific actions in one model based on events in the other. \\n    For instance, a private transaction (UTXO-based) can trigger a corresponding public notification or event in the account-based model.\\n\\n    * _Conditional Execution:_ Smart contracts could be set to execute based on events in the UTXO system. For instance, \\n    a smart contract might release funds (account-based) once a specific UTXO is spent.\\n\\n    * _Privacy Smart Contracts:_ Using zk-SNARKs or zk-STARKs to bring privacy to the smart contract layer, \\n    allowing for private logic execution.\\n\\n\\n### <ins> Challenges and Solutions </ins>\\n\\n1. Synchronization Overhead\\n\\n    * Challenge: Combining two distinct transaction models creates an inherent synchronization challenge.\\n\\n    * State Channels: By allowing transactions to be conducted off-chain between participants, state channels can alleviate synchronization stresses. \\n    Only the final state needs to be settled on-chain, drastically reducing the amount of data and frequency of updates required.\\n\\n    * Sidechains: These act as auxiliary chains to the main blockchain. Transactions can be processed on the sidechain and then periodically synced with the main chain. \\n    This structure helps reduce the immediate load on the primary system.\\n\\n    * Checkpointing: Introduce periodic checkpoints where the two systems\' states are verified and harmonized. \\n    This can ensure consistency without constant synchronization.\\n\\n2. Double Spending\\n\\n    * Challenge: With two models operating in tandem, there\'s an increased risk of double-spending attacks.\\n\\n    * Multi-Signature Transactions: Implementing transactions that require signatures from both systems can prevent unauthorized movements.\\n\\n    * Cross-Verification Mechanisms: Before finalizing a transaction, it undergoes verification in both UTXO and account-based systems. \\n    If discrepancies arise, the transaction can be halted.\\n\\n    * Timestamping: By attaching a timestamp to each transaction, it\'s possible to order them sequentially, making it easier to spot and prevent double spending.\\n\\n3. Complexity in User Experience\\n\\n    * Challenge: The dual model, while powerful, is inherently complex.\\n\\n    * Abstracted User Interfaces: Design UIs that handle the complexity behind the scenes, \\n    allowing users to make transactions without needing to understand the nuances of the dual model.\\n\\n    * Guided Tutorials: Offer onboarding tutorials to acquaint users with the system\'s features, \\n    especially emphasizing when and why they might choose one transaction type over the other.\\n\\n    * Feedback Systems: Implement systems where users can provide feedback on any complexities or challenges they encounter. \\n    This real-time feedback can be invaluable for iterative design improvements.\\n\\n4. Security\\n\\n    * Challenge: Merging two systems can introduce unforeseen vulnerabilities.\\n\\n    * Threat Modeling: Regularly conduct threat modeling exercises to anticipate potential attack vectors, \\n    especially those that might exploit the interaction between the two systems.\\n\\n    * Layered Security Protocols: Beyond regular audits, introduce multiple layers of security checks. \\n    Each layer can act as a fail-safe if a potential threat bypasses another.\\n\\n    * Decentralized Watchtowers: These are third-party services that monitor the network for malicious activities. \\n    If any suspicious activity is detected, they can take corrective measures or raise alerts.\\n\\n5. Gas & Fee Management:\\n\\n    * Challenge: A dual model can lead to convoluted fee structures.\\n\\n    * Dynamic Fee Adjustment: Implement algorithms that adjust fees based on network congestion and transaction type. \\n    This can ensure fairness and prevent network abuse.\\n\\n    * Fee Estimation Tools: Provide tools that can estimate fees before a transaction is initiated. \\n    This helps users understand potential costs upfront.\\n\\n    * Unified Gas Stations: Design platforms where users can purchase or allocate gas for both transaction types simultaneously, \\n    simplifying the gas acquisition process.\\n\\n\\nBy addressing these challenges head-on with a detailed and systematic approach, it\'s possible to unlock the full potential of a dual-architecture system, \\ncombining the strengths of both UTXO and account-based models without their standalone limitations.\\n\\n\\n| Aspect                 \\t| Details                                                                                                                                                                                                                                                                                                                                                                                                        \\t|\\n|------------------------\\t|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\t|\\n| **Harmony**            \\t| - **Advanced VM Development:** Design tailored for private smart contracts. - **Leverage Established Architectures:** Use WASM or RISC-V to harness their versatile and encompassing nature suitable for zero-knowledge applications. - **Support for UTXO & Account-Based Models:** Enhance adaptability across various blockchain structures.                                                                \\t|\\n| **Challenges**         \\t| - **Adaptation Concerns:** WASM and RISC-V weren\'t designed with zero-knowledge proofs as a primary focus, posing integration challenges. - **Complexities with Newer Systems:** Systems like (Super)Nova, STARKs, and Sangria are relatively nascent, adding another layer of intricacy to the integration. - **Optimization Concerns:** Ensuring that these systems are optimized for zero-knowledge proofs. \\t|\\n| **Proposed Solutions** \\t| - **Integration of Nova:** Consider Nova\'s proof system for its potential alignment with project goals. - **Comprehensive Testing:** Rigorously test and benchmark against alternatives like Halo2, Plonky, and Starky to validate choices. - **Poseidon Recursion Technique:** To conduct exhaustive performance tests, providing insights into each system\'s efficiency and scalability.                     \\t|\\n\\n\\n## Goal 2: Virtual Machine Creation\\n\\nThe second goal entails the creation of an advanced virtual machine by leveraging established mainstream instruction sets like WASM or RISC-V. \\nAlternatively, the objective involves pioneering a new, specialized instruction set meticulously optimized for Zero-Knowledge applications.\\n\\nThis initiative seeks to foster a versatile and efficient environment for executing computations within the privacy-focused context of the project. \\nBoth WASM and RISC-V exhibit adaptability to both UTXO and account-based models due to their encompassing nature as general-purpose instruction set architectures.\\n\\n _WASM_, operating as a low-level virtual machine, possesses the capacity to execute code derived from a myriad of high-level programming languages, \\n and boasts seamless integration across diverse blockchain platforms. \\n \\n Meanwhile, _RISC-V_ emerges as a versatile option, accommodating both models, and can be seamlessly integrated with secure enclaves like SGX or TEE, \\n elevating the levels of security and privacy. However, it is crucial to acknowledge that employing WASM or RISC-V might present challenges, \\n given their original design without specific emphasis on optimizing for Zero-Knowledge Proofs (ZKPs). \\n \\n Further complexity arises with the consideration of more potent proof systems like (Super)Nova, STARKs, and Sangria, which, \\n while potentially addressing optimization concerns, necessitate extensive research and testing due to their relatively nascent status within the field. \\n This accentuates the need for a judicious balance between established options and innovative solutions in pursuit of an architecture harmoniously amalgamating privacy, security, and performance.\\n\\nThe ambition to build a powerful virtual machine tailored to zero-knowledge (ZK) applications is both commendable and intricate. \\nThe combination of two renowned instruction sets, WASM and RISC-V, in tandem with ZK, is an innovation that could redefine privacy standards in blockchain. \\nLet\'s dissect the challenges and possibilities inherent in this goal:\\n\\n1. Established Mainstream Instruction Sets - WASM and RISC-V\\n\\n    * Strengths:\\n\\n        * _WASM_: Rooted in its ability to execute diverse high-level language codes, its potential for cross-chain compatibility makes it a formidable contender. \\n        Serving as a low-level virtual machine, its role in the blockchain realm is analogous to that of the Java Virtual Machine in the traditional computing landscape.\\n\\n        * _RISC-V_: This open-standard instruction set architecture has made waves due to its customizable nature. \\n        Its adaptability to both UTXO and account-based structures coupled with its compatibility with trusted execution environments like SGX and TEE augments its appeal, \\n        especially in domains that prioritize security and privacy.\\n\\n    * Challenges: Neither WASM nor RISC-V was primarily designed with ZKPs in mind. While they offer flexibility, \\n    they might lack the necessary optimizations for ZK-centric tasks. Adjustments to these architectures might demand intensive R&D efforts.\\n\\n\\n\\n2. Pioneering a New, Specialized Instruction Set\\n\\n    * Strengths: A bespoke instruction set can be meticulously designed from the ground up with ZK in focus, \\n    potentially offering unmatched performance and optimizations tailored to the project\'s requirements.\\n    \\n    * Challenges: Crafting a new instruction set is a monumental task requiring vast resources, including expertise, time, and capital.\\n     It would also need to garner community trust and support over time.\\n\\n\\n\\n3. Contemporary Proof Systems - (Super)Nova, STARKs, Sangria\\n\\n    * Strengths: These cutting-edge systems, being relatively new, might offer breakthrough cryptographic efficiencies that older systems lack: designed with modern challenges in mind, \\n    they could potentially bridge the gap where WASM and RISC-V might falter in terms of ZKP optimization.\\n\\n    * Challenges: Their nascent nature implies a dearth of exhaustive testing, peer reviews, and potentially limited community support. \\n    The unknowns associated with these systems could introduce unforeseen vulnerabilities or complexities. \\n    While they could offer optimizations that address challenges presented by WASM and RISC-V, their young status demands rigorous vetting and testing.\\n\\n\\n<center>\\n\\n|                    | Mainstream (WASM, RISC-V) | ZK-optimized (New Instruction Set) |\\n|:------------------:|:-------------------------:|:----------------------------------:|\\n|  Existing Tooling  |            YES            |                 NO                 |\\n| Blockchain-focused |             NO            |                 YES                |\\n|     Performant     |          DEPENDS          |                 YES                |\\n\\n</center>\\n\\n### <ins> Optimization Concerns for WASM and RISC-V: </ins>\\n\\n* _Cryptography Libraries_: ZKP applications rely heavily on specific cryptographic primitives. Neither WASM nor RISC-V natively supports all of these primitives. \\nThus, a comprehensive library of cryptographic functions, optimized for these platforms, needs to be developed.\\n\\n* _Parallel Execution_: Given the heavy computational demands of ZKPs, leveraging parallel processing capabilities can optimize the time taken. \\nBoth WASM and RISC-V would need modifications to handle parallel execution of ZKP processes efficiently.\\n\\n* _Memory Management_: ZKP computations can sometimes require significant amounts of memory, especially during the proof generation phase. \\nFine-tuned memory management mechanisms are essential to prevent bottlenecks.\\n\\n\\n### <ins> Emerging ZKP Optimized Systems Considerations: </ins>\\n\\n* _Proof Size_: Different systems generate proofs of varying sizes. A smaller proof size is preferable for blockchain applications to save on storage and bandwidth. \\nThe trade-offs between proof size, computational efficiency, and security need to be balanced.\\n\\n* _Universality_: Some systems can support any computational statement (universal), while others might be tailored to specific tasks. \\nA universal system can be more versatile for diverse applications on the blockchain.\\n\\n* _Setup Requirements_: Certain ZKP systems, like zk-SNARKs, require a trusted setup, which can be a security concern. \\nAlternatives like zk-STARKs don\'t have this requirement but come with other trade-offs.\\n\\n\\n### <ins> Strategies for Integration: </ins>\\n\\n* _Iterative Development_: Given the complexities, an iterative development approach can be beneficial. \\nStart with a basic integration of WASM or RISC-V for general tasks and gradually introduce specialized ZKP functionalities.\\n\\n* _Benchmarking_: Establish benchmark tests specifically for ZKP operations. This will provide continuous feedback on the performance of the system as modifications are made, ensuring optimization.\\n\\n* _External Audits & Research_: Regular checks from cryptographic experts and collaboration with academic researchers can help in staying updated and ensuring secure implementations.\\n\\n\\n## Goal 3: Proofs Creation and Verification\\n\\nThe process of generating proofs for private state updates is vested in the hands of the user, aligning with our commitment to minimizing trust assumptions and enhancing privacy. \\nConcurrently, the responsibility of verifying these proofs and executing public functions within the virtual machine can be effectively delegated to an external prover, \\na role that is incentivized to operate with utmost honesty and integrity. This intricate balance seeks to safeguard against information leakage, \\npreserving the confidentiality of private transactions. Integral to this mechanism is the establishment of a robust incentivization framework.\\n\\nTo ensure the prover\u2019s steadfast commitment to performing tasks with honesty, we should introduce a mechanism that facilitates both rewards for sincere behavior and penalties for any deviation from the expected standards. \\nThis two-pronged approach serves as a compelling deterrent against dishonest behavior and fosters an environment of accountability. \\nIn addition to incentivization, a crucial consideration is the economic aspect of verification and execution. \\nThe verification process has been intentionally designed to be more cost-effective than execution. \\n\\nThis strategic approach prevents potential malicious actors from exploiting the system by flooding it with spurious proofs, a scenario that could arise when the costs align favorably. \\nBy maintaining a cost balance that favors verification, we bolster the system\u2019s resilience against fraudulent activities while ensuring its efficiency. \\nIn sum, our multifaceted approach endeavors to strike an intricate equilibrium between user-initiated proof creation, external verification, and incentivization. \\nThis delicate interplay of mechanisms ensures a level of trustworthiness that hinges on transparency, accountability, and economic viability.\\n\\nAs a result, we are poised to cultivate an ecosystem where users\u2019 privacy is preserved, incentives are aligned, \\nand the overall integrity of the system is fortified against potential adversarial actions. To achieve the goals of user-initiated proof creation, \\nexternal verification, incentivization, and cost-effective verification over execution, several options and mechanisms can be employed:\\n\\n1. **User-Initiated Proof Creation:** Users are entrusted with the generation of proofs for private state updates, thus ensuring greater privacy and reducing trust dependencies.\\n\\n    * Challenges:\\n\\n        * Maintaining the quality and integrity of the proofs generated by users.\\n\\n         * Ensuring that users have the tools and knowledge to produce valid proofs.\\n\\n    * Solutions:\\n\\n        * Offer extensive documentation, tutorials, and user-friendly tools to streamline the proof-generation process.\\n\\n        * Implement checks at the verifier\'s end to ensure the quality of proofs.\\n\\n\\n2. **External Verification by Provers:** An external prover verifies the proofs and executes public functions within the virtual machine.\\n\\n    * Challenges:\\n\\n        * Ensuring that the external prover acts honestly.\\n\\n        * Avoiding centralized points of failure.\\n    \\n    * Solutions:\\n\\n        * Adopt a decentralized verification approach, with multiple provers cross-verifying each other\u2019s work.\\n\\n        * Use reputation systems to rank provers based on their past performances, creating a trust hierarchy.\\n\\n3. ** Incentivization Framework:** A system that rewards honesty and penalizes dishonest actions, ensuring provers\' commitment to the task.\\n\\n    * Challenges:\\n\\n        * Determining the right balance of rewards and penalties.\\n\\n        * Ensuring that the system cannot be gamed for undue advantage.\\n\\n    * Solutions[^1]: \\n\\n        * Implement a dynamic reward system that adjusts based on network metrics and provers\' performance.\\n\\n        * Use a staking mechanism where provers need to lock up a certain amount of assets. \\n        Honest behavior earns rewards, while dishonest behavior could lead to loss of staked assets.\\n\\n4. **Economic Viability through Cost Dynamics:** Making verification more cost-effective than execution to deter spamming and malicious attacks.\\n\\n    * Challenges: \\n\\n        * Setting the right cost metrics for both verification and execution.\\n\\n        * Ensuring that genuine users aren\u2019t priced out of the system.\\n\\n    * Solutions:\\n\\n        * Use a dynamic pricing model, adjusting costs in real-time based on network demand.\\n\\n        * Implement gas-like mechanisms to differentiate operation costs and ensure fairness.\\n\\n5. **  Maintaining Trustworthiness:** Create a system that\'s transparent, holds all actors accountable, and is economically sound.\\n\\n    * Challenges: \\n\\n        * Keeping the balance where users feel their privacy is intact, while provers feel incentivized.\\n\\n        * Ensuring the system remains resilient against adversarial attacks.\\n\\n    * Solutions:\\n\\n        * Implement layered checks and balances.\\n\\n        * Foster community involvement, allowing them to participate in decision-making, potentially through a decentralized autonomous organization (DAO).\\n\\nEach of these options can be combined or customized to suit the specific requirements of your project, striking a balance between user incentives, \\ncost dynamics, and verification integrity. A thoughtful combination of these mechanisms ensures that the system remains robust, resilient, \\nand conducive to the objectives of user-initiated proof creation, incentivized verification, and cost- effective validation.\\n\\n<center>\\n\\n| Aspect                        \\t| Details                                                                                                                                                                                                                      \\t|\\n|-------------------------------\\t|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\t|\\n| **Design Principle**          \\t| - **User Responsibility:** Generating proofs for private state updates. - **External Prover:** Delegated the task of verifying proofs and executing public VM functions.                                                     \\t|\\n| **Trust & Privacy**           \\t| - **Minimized Trust Assumptions:** Place proof generation in users\' hands. - **Enhanced Privacy:** Ensure confidentiality of private transactions and prevent information leakage.                                           \\t|\\n| **Incentivization Framework** \\t| - **Rewards:** Compensate honest behavior. - **Penalties:** Deter and penalize dishonest behavior.                                                                                                                           \\t|\\n| **Economic Considerations**   \\t| - **Verification vs. Execution:** Make verification more cost-effective than execution to prevent spurious proofs flooding. - **Cost Balance:** Strengthen resilience against fraudulent activities and maintain efficiency. \\t|\\n| **Outcome**                   \\t| An ecosystem where: - Users\' privacy is paramount. - Incentives are appropriately aligned. - The system is robust against adversarial actions.                                                                               \\t|\\n\\n</center>\\n\\n[^1]: Incentive Mechanisms:\\n    * Token Rewards: Design a token-based reward system where honest provers are compensated with tokens for their verification services. \\n    This incentivizes participation and encourages integrity.\\n   \\n    * Staking and Slashing: Introduce a staking mechanism where provers deposit tokens as collateral. \\n    Dishonest behavior results in slashing (partial or complete loss) of the staked tokens, while honest actions are rewarded.\\n   \\n    * Proof of Work/Proof of Stake: Implement a proof-of-work or proof-of- stake consensus mechanism for verification, \\n    aligning incentives with the blockchain\u2019s broader consensus mechanism.\\n\\n\\n## Goal 4: Kernel-based Architecture Implementation\\n\\nThis goal centers on the establishment of a kernel-based architecture, akin to the model observed in ZEXE, to facilitate the attestation of accurate private function executions. \\nThis innovative approach employs recursion to construct a call stack, which is then validated through iterative recursive computations. \\nAt its core, this technique harnesses a recursive Succinct Non-Interactive Argument of Knowledge (SNARK) mechanism, where each function call\u2019s proof accumulates within the call stack.\\n\\nThe subsequent verification of this stack\u2019s authenticity leverages recursive SNARK validation. \\nWhile this method offers robust verification of private function executions, it\u2019s essential to acknowledge its associated intricacies.\\n\\nThe generation of SNARK proofs necessitates a substantial computational effort, which, in turn, may lead to elevated gas fees for users. \\nMoreover, the iterative recursive computations could potentially exhibit computational expansion as the depth of recursion increases. \\nThis calls for a meticulous balance between the benefits of recursive verification and the resource implications it may entail.\\n\\nIn essence, Goal 4 embodies a pursuit of enhanced verification accuracy through a kernel-based architecture. \\nBy weaving recursion and iterative recursive computations into the fabric of our system, we aim to establish a mechanism that accentuates the trustworthiness of private function executions, \\nwhile conscientiously navigating the computational demands that ensue.\\n\\nTo accomplish the goal of implementing a kernel-based architecture for recursive verification of private function executions, \\nseveral strategic steps and considerations can be undertaken: recursion handling and depth management.\\n\\n<ins> Recursion Handling </ins>\\n\\n* _Call Stack Management:_ \\n\\n    * Implement a data structure to manage the call stack, recording each recursive function call\u2019s details, parameters, and state.\\n\\n* _Proof Accumulation: _\\n\\n    * Design a mechanism to accumulate proof data for each function call within the call stack. \\n    This includes cryptographic commitments, intermediate results, and cryptographic challenges.\\n\\n    * Ensure that the accumulated proof data remains secure and tamper-resistant throughout the recursion process.\\n\\n* _Intermediary SNARK Proofs:_\\n\\n    * Develop an intermediary SNARK proof for each function call\u2019s correctness within the call stack. \\n    This proof should demonstrate that the function executed correctly and produced expected outputs.\\n\\n    * Ensure that the intermediary SNARK proof for each recursive call can be aggregated and verified together, maintaining the integrity of the entire call stack.\\n\\n<ins> Depth management </ins>\\n\\n* _Depth Limitation:_\\n\\n    * Define a threshold for the maximum allowable recursion depth based on the system\u2019s computational capacity, gas limitations, and performance considerations.\\n\\n    * Implement a mechanism to prevent further recursion beyond the defined depth limit, safeguarding against excessive computational growth.\\n\\n* _Graceful Degradation:_\\n\\n    * Design a strategy for graceful degradation when the recursion depth approaches or reaches the defined limit. \\n    This may involve transitioning to alternative execution modes or optimization techniques.\\n\\n    * Communicate the degradation strategy to users and ensure that the system gracefully handles scenarios where recursion must be curtailed.\\n\\n* _Resource Monitoring:_\\n\\n    * Develop tools to monitor resource consumption (such as gas usage and computational time) as recursion progresses. \\n    Provide real-time feedback to users about the cost and impact of recursive execution.\\n\\n* _Dynamic Depth Adjustment:_\\n\\n    * Consider implementing adaptive depth management that dynamically adjusts the recursion depth based on network conditions, transaction fees, and available resources.\\n\\n    * Utilize algorithms to assess the optimal recursion depth for efficient execution while adhering to gas cost constraints.\\n\\n* _Fallback Mechanisms:_\\n\\n    * Create fallback mechanisms that activate if the recursion depth limit is reached or if the system encounters resource constraints. \\n    These mechanisms could involve alternative verification methods or delayed execution.\\n\\n* _User Notifications:_\\n\\n    * Notify users when the recursion depth limit is approaching, enabling them to make informed decisions about the complexity of their transactions and potential resource usage.\\n\\n\\nGoal 4 underscores the project\'s ambition to integrate the merits of a kernel-based architecture with recursive verifications to bolster the reliability of private function executions. \\nWhile the approach promises robust outcomes, it\'s pivotal to maneuver through its intricacies with astute strategies, ensuring computational efficiency and economic viability. \\nBy striking this balance, the architecture can realize its full potential in ensuring trustworthy and efficient private function executions.\\n\\n\\n## Goal 5: Seamless Interaction Design\\n\\nGoal 5 revolves around the meticulous design of a seamless interaction between public and private states within the blockchain ecosystem. \\nThis objective envisions achieving not only composability between contracts but also the harmonious integration of private and public functions.\\n\\nA notable challenge in this endeavor lies in the intricate interplay between public and private states, \\nwherein the potential linkage of a private transaction to a public one raises concerns about unintended information leakage.\\n\\nThe essence of this goal entails crafting an architecture that facilitates the dynamic interaction of different states while ensuring that the privacy and confidentiality of private transactions remain unbreached. \\nThis involves the formulation of mechanisms that enable secure composability between contracts, guaranteeing the integrity of interactions across different layers of functionality.\\n\\nA key focus of this goal is to surmount the challenge of information leakage by implementing robust safeguards. \\nThe solution involves devising strategies to mitigate the risk of revealing private transaction details when connected to corresponding public actions. \\nBy creating a nuanced framework that com- partmentalizes private and public interactions, the architecture aims to uphold privacy while facilitating seamless interoperability.\\n\\nGoal 5 encapsulates a multifaceted undertaking, calling for the creation of an intricate yet transparent framework that empowers users to confidently engage in both public and private functions, \\nwithout compromising the confidentiality of private transactions. The successful realization of this vision hinges on a delicate blend of architectural ingenuity, cryptographic sophistication, and user-centric design.\\n\\nTo achieve seamless interaction between public and private states, composability, and privacy preservation, a combination of solutions and approaches can be employed. \\nIn the table below, a comprehensive list of solutions that address these objectives:\\n\\n<center>\\n\\n|           **Solution Category**           \\t|                                                                                     **Description**                                                                                    \\t|\\n|:-----------------------------------------:\\t|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:\\t|\\n| **Layer 2 Solutions**                     \\t| Employ zk-Rollups, Optimistic Rollups, and state channels to handle private interactions off-chain and settle them on-chain periodically. Boost scalability and cut transaction costs. \\t|\\n| **Intermediary Smart Contracts**          \\t|                            Craft smart contracts as intermediaries for secure public-private interactions. Use these to manage data exchange confidentially.                           \\t|\\n| **Decentralized Identity & Pseudonymity** \\t|                                  Implement decentralized identity systems for pseudonymous interactions. Validate identity using cryptographic proofs.                                 \\t|\\n| **Confidential Sidechains & Cross-Chain** \\t|                                 Set up confidential sidechains and employ cross-chain protocols to ensure private and composability across blockchains.                                \\t|\\n| **Temporal Data Structures**              \\t|                               Create chronological data structures for secure interactions. Utilize cryptographic methods for data integrity and privacy.                              \\t|\\n| **Homomorphic Encryption & MPC**          \\t|                                     Apply homomorphic encryption and MPC for computations on encrypted data and interactions between state layers.                                     \\t|\\n| **Commit-Reveal Schemes**                 \\t|                                     Introduce commit-reveal mechanisms for private transactions, revealing data only post necessary public actions.                                    \\t|\\n| **Auditability & Verifiability**          \\t|                                Use on-chain tools for auditing and verifying interactions. Utilize cryptographic commitments for third-party validation.                               \\t|\\n| **Data Fragmentation & Sharding**         \\t|                               Fragment data across shards for private interactions and curtailed data exposure. Bridge shards securely with cryptography.                              \\t|\\n| **Ring Signatures & CoinJoin**            \\t|                                  Incorporate ring signatures and CoinJoin protocols to mask transaction details and mix transactions collaboratively.                                  \\t|\\n\\n</center>\\n\\n## Goal 6: Integration of DeFi Protocols with a Privacy-Preserving Framework\\n\\nThe primary aim of Goal 6 is to weave key DeFi protocols, such as AMMs and staking, into a user-centric environment that accentuates privacy. \\nThis endeavor comes with inherent challenges, especially considering the heterogeneity of existing DeFi protocols, predominantly built on Ethereum. \\nThese variations in programming languages and VMs exacerbate the quest for interoperability. Furthermore, the success and functionality of DeFi protocols is closely tied to liquidity, \\nwhich in turn is influenced by user engagement and the amount of funds locked into the system.\\n\\n## <ins> Strategic Roadmap for Goal 6 </ins>\\n\\n1. _** Pioneering Privacy-Centric DeFi Models: **_ Initiate the development of AMMs and staking solutions that are inherently protective of users\' transactional privacy and identity.\\n\\n2. _** Specialized Smart Contracts with Privacy: **_ Architect distinct smart contracts infused with privacy elements, setting the stage for secure user interactions within this new, confidential DeFi landscape.\\n\\n3. _** Optimized User Interfaces: **_ Craft interfaces that resonate with user needs, simplifying the journey through the private DeFi space without compromising on security.\\n\\n4. _** Tackling Interoperability: **_ \\n\\n    * Deploy advanced bridge technologies and middleware tools to foster efficient data exchanges and guarantee operational harmony across a spectrum of programming paradigms and virtual environments.\\n    \\n    * Design and enforce universal communication guidelines that bridge the privacy-centric DeFi entities with the larger DeFi world seamlessly.\\n\\n\\n5. _** Enhancing and Sustaining Liquidity: **_\\n\\n    * Unveil innovative liquidity stimuli and yield farming incentives, compelling users to infuse liquidity into the private DeFi space.\\n    \\n    * Incorporate adaptive liquidity frameworks that continually adjust based on the evolving market demands, ensuring consistent liquidity.\\n\\n    * Forge robust alliances with other DeFi stalwarts, jointly maximizing liquidity stores and honing sustainable token distribution strategies.\\n\\n\\n6. _** Amplifying Community Engagement:**_ Design and roll out enticing incentive schemes to rally users behind privacy-focused AMMs and staking systems, \\nthereby nurturing a vibrant, privacy-advocating DeFi community.\\n\\n\\nThrough the integration of these approaches, we aim to achieve Goal 6, providing users with a privacy-focused platform for engaging effortlessly in core DeFi functions such as AMMs and staking, \\nall while effectively overcoming the obstacles related to interoperability and liquidity concerns.\\n\\n\\n## Summary of the Architecture\\n\\nIn our quest to optimize privacy, we\'re proposing a Zero-Knowledge Virtual Machine (Zkvm) that harnesses the power of Zero-Knowledge Proofs (ZKPs).\\nThese proofs ensure that while private state data remains undisclosed, public state transitions can still be carried out and subsequently verified by third parties. \\nThis blend of public and private state is envisaged to be achieved through a state tree representing the public state, while the encrypted state leaves stand for the private state. \\nEach user\'s private state indicates validity through the absence of a corresponding nullifier.\\nA nullifier is a unique cryptographic value generated in privacy-preserving blockchain transactions to prevent double-spending, \\nensuring that each private transaction is spent only once without revealing its details.\\n\\nPrivate functions\' execution mandates users to offer a proof underscoring the accurate execution of all encapsulated private calls. \\nFor validating a singular private function call, we\'re leaning into the kernel-based model inspired by the ZEXE protocol. \\nDefined as kernel circuits, these functions validate the correct execution of each private function call. \\nDue to their recursive circuit structure, a succession of private function calls can be executed by calculating proofs in an iterative manner. \\nExecution-relevant data, like private and public call stacks and additions to the state tree, are incorporated as public inputs.\\n\\nOur method integrates the verification keys for these functions within a merkle tree. Here\'s the innovation: a user\'s ZKP showcases the existence of the verification key in this tree, yet keeps the executed function concealed. \\nThe unique function identifier can be presented as the verification key, with all contracts merkleized for hiding functionalities.\\n\\nWe suggest a nuanced shift from the ZEXE protocol\'s identity function, which crafts an identity for smart contracts delineating its behavior, access timeframes, and other functionalities. \\nInstead of the ZEXE protocol\'s structure, our approach pivots to a method anchored in the \\nsecurity of a secret combined with the uniqueness from hashing with the contract address. \\nThe underlying rationale is straightforward: the sender, equipped with a unique nonce and salt for the transaction, hashes the secret, payload, nonce, and salt. \\nThis result is then hashed with the contract address for the final value. The hash function\'s unidirectional nature ensures that the input cannot be deduced easily from its output. \\nA specific concern, however, is the potential repetition of secret and payload values across transactions, which could jeopardize privacy. \\nYet, by embedding the function\'s hash within the hash of the contract address, users can validate a specific function\'s execution without divulging the function, navigating this limitation.\\n\\nAlternative routes do exist: We could employ signature schemes like ECDSA, focusing on uniqueness and authenticity, albeit at the cost of complex key management. \\nFully Homomorphic Encryption (FHE) offers another pathway, enabling function execution on encrypted data, or Multi-Party Computation (MPC) which guarantees non-disclosure of function or inputs. \\nYet, integrating ZKPs with either FHE or MPC presents a challenge. Combining cryptographic functions like SHA-3 and BLAKE2 can also bolster security and uniqueness. \\nIt\'s imperative to entertain these alternatives, especially when hashing might not serve large input/output functions effectively or might fall short in guaranteeing uniqueness.\\n\\n## Current State\\n\\nOur aim is to revolutionize the privacy and security paradigms through Nescience.\\nAs we strive to set milestones and achieve groundbreaking advancements, \\nour current focus narrows onto the realization of Goal 2 and Goal 3.\\n\\nOur endeavors to build a powerful virtual machine tailored for Zero-Knowledge applications have led us down the path of rigorous exploration and testing. \\nWe believe that integrating the right proof system is pivotal to our project\'s success, which brings us to Nova [[8](https://eprint.iacr.org/2021/370)].\\nIn our project journey, we have opted to integrate the Nova proof system, recognizing its potential alignment with our overarching goals. \\nHowever, as part of our meticulous approach to innovation and optimization, we acknowledge the need to thoroughly examine Nova\u2019s performance capabilities, \\nparticularly due to its status as a pioneering and relatively unexplored proof system.\\n\\nThis critical evaluation entails a comprehensive process of benchmarking and comparative analysis [[9]](https://github.com/vacp2p/zk-explorations), \\npitting Nova against other prominent proof systems in the field, including Halo2 [[10](https://electriccoin.co/blog/explaining-halo-2/)], \\nPlonky2 [[11](https://polygon.technology/blog/introducing-plonky2)], and Starky [[12](https://eprint.iacr.org/2021/582)]. \\nThis ongoing and methodical initiative is designed to ensure a fair and impartial assessment, enabling us to draw meaningful conclusions about Nova\u2019s strengths and limitations in relation to its counterparts. \\nBy leveraging the Poseidon recursion technique, we are poised to conduct an exhaustive performance test that delves into intricate details. \\nThrough this testing framework, we aim to discern whether Nova possesses the potential to outshine its contemporaries in terms of efficiency, scalability, and overall performance. \\nThe outcome of this rigorous evaluation will be pivotal in shaping our strategic decisions moving forward. \\nArmed with a comprehensive understanding of Nova\u2019s performance metrics vis-\xe0-vis other proof systems, \\nwe can confidently chart a course that maximizes the benefits of our project\u2019s optimization efforts.\\n\\nMoreover, as we ambitiously pursue the establishment of a robust mechanism for proof creation and verification, our focus remains resolute on preserving user privacy, \\nincentivizing honest behaviour, and ensuring the cost-effective verification of transactions. \\nAt the heart of this endeavor is our drive to empower users by allowing them the autonomy of generating proofs for private state updates, \\nthereby reducing dependencies and enhancing privacy.\\nWe would like to actively work on providing comprehensive documentation, user-friendly tools, \\nand tutorials to aid users in this intricate process.\\n\\nParallelly, we\'re looking into decentralized verification processes, harnessing the strength of multiple external provers that cross-verify each other\'s work. \\nOur commitment is further cemented by our efforts to introduce a dynamic reward system that adjusts based on network metrics and prover performance. \\nThis intricate balance, while challenging, aims to fortify our system against potential adversarial actions, aligning incentives, and preserving the overall integrity of the project.\\n\\n\\n# References\\n\\n[1] Nakamoto, S. (2008). Bitcoin: A Peer-to-Peer Electronic Cash System. Retrieved from https://bitcoin.org/bitcoin.pdf\\n\\n[2] Sanchez, F. (2021). Cardano\u2019s Extended UTXO accounting model. Retrived from https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/\\n\\n[3] Morgan, D. (2020). HD Wallets Explained: From High Level to Nuts and Bolts. Retrieved from https://medium.com/mycrypto/the-journey-from-mnemonic-phrase-to-address-6c5e86e11e14\\n\\n[4] Wuille, P. (012). Bitcoin Improvement Proposal (BIP) 44. Retrieved from https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki\\n\\n[5] Jedusor, T. (2020). Introduction to Mimblewimble and Grin. Retrieved from https://github.com/mimblewimble/grin/blob/master/doc/intro.md\\n\\n[6]  Bitcoin\'s official wiki overview of the CoinJoin method. Retrieved from https://en.bitcoin.it/wiki/CoinJoin\\n\\n[7] TornadoCash official Github page. Retrieved from https://github.com/tornadocash/tornado-classic-ui\\n\\n[8] Kothapalli, A., Setty, S., Tzialla, I. (2021). Nova: Recursive Zero-Knowledge Arguments from Folding Schemes. Retrieved from https://eprint.iacr.org/2021/370\\n\\n[9] ZKvm Github page. Retrieved from https://github.com/vacp2p/zk-explorations\\n\\n[10] Electric Coin Company (2020). Explaining Halo 2. Retrieved from https://electriccoin.co/blog/explaining-halo-2/\\n\\n[11] Polygon Labs (2022). Introducing Plonky2. Retrieved from https://polygon.technology/blog/introducing-plonky2\\n\\n[12] StarkWare (2021). ethSTARK Documentation. Retrieved from https://eprint.iacr.org/2021/582"},{"id":"device-pairing-in-js-waku-and-go-waku","metadata":{"permalink":"/rlog/device-pairing-in-js-waku-and-go-waku","source":"@site/rlog/2023-04-24-device-pairing-in-js-waku-and-go-waku.mdx","title":"Device Pairing in Js-waku and Go-waku","description":"Device pairing and secure message exchange using Waku and noise protocol.","date":"2023-04-24T12:00:00.000Z","formattedDate":"April 24, 2023","tags":[],"readingTime":4.09,"hasTruncateMarker":true,"authors":[{"name":"Richard","twitter":"richardramos_me","github":"richard-ramos","website":"https://richard-ramos.github.io/","key":"rramos"}],"frontMatter":{"layout":"post","name":"Device Pairing in Js-waku and Go-waku","title":"Device Pairing in Js-waku and Go-waku","date":"2023-04-24T12:00:00.000Z","authors":"rramos","published":true,"slug":"device-pairing-in-js-waku-and-go-waku","categories":"platform"},"prevItem":{"title":"Nescience - A zkVM leveraging hiding properties","permalink":"/rlog/Nescience-A-zkVM-leveraging-hiding-properties"},"nextItem":{"title":"The Future of Waku Network: Scaling, Incentivization, and Heterogeneity","permalink":"/rlog/future-of-waku-network"}},"content":"Device pairing and secure message exchange using Waku and noise protocol.\\n\\n\x3c!--truncate--\x3e\\n\\nAs the world becomes increasingly connected through the internet, the need for secure and reliable communication becomes paramount. In [this article](https://vac.dev/wakuv2-noise) it is described how the Noise protocol can be used as a key-exchange mechanism for Waku.\\n\\nRecently, this feature was introduced in [js-waku](https://github.com/waku-org/js-noise) and [go-waku](https://github.com/waku-org/go-waku), providing a simple API for developers to implement secure communication protocols using the Noise Protocol framework. These open-source libraries provide a solid foundation for building secure and decentralized applications that prioritize data privacy and security.\\n\\nThis functionality is designed to be simple and easy to use, even for developers who are not experts in cryptography. The library offers a clear and concise API that abstracts away the complexity of the Noise Protocol framework and provides an straightforward interface for developers to use. Using this, developers can effortlessly implement secure communication protocols on top of their JavaScript and Go applications, without having to worry about the low-level details of cryptography.\\n\\nOne of the key benefits of using Noise is that it provides end-to-end encryption, which means that the communication between two parties is encrypted from start to finish. This is essential for ensuring the security and privacy of sensitive information\\n\\n### Device Pairing\\n\\nIn today\'s digital world, device pairing has become an integral part of our lives. Whether it\'s connecting our smartphones with other computers or web applications, the need for secure device pairing has become more crucial than ever. With the increasing threat of cyber-attacks and data breaches, it\'s essential to implement secure protocols for device pairing to ensure data privacy and prevent unauthorized access.\\n\\nTo demonstrate how device pairing can be achieved using Waku and Noise, we have examples available at https://examples.waku.org/noise-js/. You can try pairing different devices, such as mobile and desktop, via a web application. This can be done by scanning a QR code or opening a URL that contains the necessary data for a secure handshake.\\n\\nThe process works as follows:\\n\\nActors:\\n\\n- Alice the initiator\\n- Bob the responder\\n\\n1. The first step in achieving secure device pairing using Noise and Waku is for Bob generate the pairing information which could be transmitted out-of-band. For this, Bob opens https://examples.waku.org/noise-js/ and a QR code is generated, containing the data required to do the handshake. This pairing QR code is timeboxed, meaning that after 2 minutes, it will become invalid and a new QR code must be generated\\n2. Alice scans the QR code using a mobile phone. This will open the app with the QR code parameters initiating the handshake process which is described in [43/WAKU2-DEVICE-PAIRING](https://rfc.vac.dev/spec/43/#protocol-flow). These messages are exchanged between two devices over Waku to establish a secure connection. The handshake messages consist of three main parts: the initiator\'s message, the responder\'s message, and the final message, which are exchanged to establish a secure connection. While using js-noise, the developer is abstracted of this process, since the messaging happens automatically depending on the actions performed by the actors in the pairing process.\\n3. Both Alice and Bob will be asked to verify each other\'s identity. This is done by confirming if an 8-digits authorization code match in both devices. If both actors confirm that the authorization code is valid, the handshake concludes succesfully\\n4. Alice and Bob receive a set of shared keys that can be used to start exchanging encrypted messages. The shared secret keys generated during the handshake process are used to encrypt and decrypt messages sent between the devices. This ensures that the messages exchanged between the devices are secure and cannot be intercepted or modified by an attacker.\\n\\nThe above example demonstrates device pairing using js-waku. Additionally, You can also try building and experimenting with other noise implementations like nwaku, or go-waku, with an example available at https://github.com/waku-org/go-waku/tree/master/examples/noise in which the same flow described before is done with Bob (the receiver) using go-waku instead of js-waku.\\n\\n### Conclusion\\n\\nWith its easy to use API built on top of the Noise Protocol framework and the LibP2P networking stack, if you are a developer looking to implement secure messaging in their applications that are both decentralized and censorship resistant, Waku is definitely an excellent choice worth checking out!\\n\\nWaku is also Open source with a MIT and APACHEv2 licenses, which means that developers are encouraged to contribute code, report bugs, and suggest improvements to make it even better.\\n\\nDon\'t hesitate to try the live example at https://examples.waku.org/noise-js and build your own webapp using https://github.com/waku-org/js-noise, https://github.com/waku-org/js-waku and https://github.com/waku-org/go-waku. This will give you a hands-on experience of implementing secure communication protocols using the Noise Protocol framework in a practical setting. Happy coding!\\n\\n### References\\n\\n- [Noise handshakes as key-exchange mechanism for Waku](https://vac.dev/wakuv2-noise)\\n- [Noise Protocols for Waku Payload Encryption](https://rfc.vac.dev/spec/35/)\\n- [Session Management for Waku Noise](https://rfc.vac.dev/spec/37/)\\n- [Device pairing and secure transfers with Noise](https://rfc.vac.dev/spec/43/)\\n- [go-waku Noise\'s example](https://github.com/waku-org/go-waku/tree/master/examples/noise)\\n- [js-waku Noise\'s example](https://github.com/waku-org/js-waku-examples/tree/master/examples/noise-js)\\n- [js-noise](https://github.com/waku-org/js-noise/)\\n- [go-noise](https://github.com/waku-org/js-noise/)"},{"id":"future-of-waku-network","metadata":{"permalink":"/rlog/future-of-waku-network","source":"@site/rlog/2023-04-03-waku-as-a-network.mdx","title":"The Future of Waku Network: Scaling, Incentivization, and Heterogeneity","description":"Learn how the Waku Network is evolving through scaling, incentivization, and diverse ecosystem development and what the future might look like.","date":"2023-04-03T00:00:00.000Z","formattedDate":"April 3, 2023","tags":[],"readingTime":5.745,"hasTruncateMarker":true,"authors":[{"name":"Franck","twitter":"fryorcraken","github":"fryorcraken","key":"franck"}],"frontMatter":{"layout":"post","name":"The Future of Waku Network: Scaling, Incentivization, and Heterogeneity","title":"The Future of Waku Network: Scaling, Incentivization, and Heterogeneity","date":"2023-04-03T00:00:00.000Z","authors":"franck","published":true,"slug":"future-of-waku-network","categories":"platform, operator, network","image":"/img/black-waku-logo-with-name.png","discuss":"https://forum.vac.dev/t/discussion-the-future-of-waku-network-scaling-incentivization-and-heterogeneity/173","hide_table_of_contents":false},"prevItem":{"title":"Device Pairing in Js-waku and Go-waku","permalink":"/rlog/device-pairing-in-js-waku-and-go-waku"},"nextItem":{"title":"Waku for All Decentralized Applications and Infrastructures","permalink":"/rlog/waku-for-all"}},"content":"Learn how the Waku Network is evolving through scaling, incentivization, and diverse ecosystem development and what the future might look like.\\n\\n\x3c!--truncate--\x3e\\n\\nWaku is preparing for production with a focus on the Status Communities use case. In this blog post, we will provide an\\noverview of recent discussions and research outputs, aiming to give you a better understanding of how the Waku network\\nmay look like in terms of scaling and incentivization.\\n\\n## DOS Mitigation for Status Communities\\n\\nWaku is actively exploring DOS mitigation mechanisms suitable for Status Communities. While RLN\\n(Rate Limiting Nullifiers) remains the go-to DOS protection solution due to its privacy-preserving and\\ncensorship-resistant properties, there is still more work to be done. We are excited to collaborate with PSE\\n(Privacy & Scaling Explorations) in this endeavor. Learn more about their latest progress in this [tweet](https://twitter.com/CPerezz19/status/1640373940634939394?s=20).\\n\\n## A Heterogeneous Waku Network\\n\\nAs we noted in a previous [forum post](https://forum.vac.dev/t/waku-payment-models/166/3), Waku\'s protocol\\nincentivization model needs to be flexible to accommodate various business models. Flexibility ensures that projects\\ncan choose how they want to use Waku based on their specific needs.\\n\\n### Reversing the Incentivization Question\\n\\nTraditionally, the question of incentivization revolves around how to incentivize operators to run nodes. We\'d like to\\nreframe the question and instead ask, \\"How do we pay for the infrastructure?\\"\\n\\nWaku does not intend to offer a free lunch.\\nEthereum\'s infrastructure is supported by transaction fees and inflation, with validators receiving rewards from both sources.\\nHowever, this model does not suit a communication network like Waku.\\nUsers and platforms would not want to pay for every single message they send. Additionally, Waku aims to support instant\\nephemeral messages that do not require consensus or long-term storage.\\n\\nProjects that use Waku to enable user interactions, whether for chat messages, gaming, private DeFi, notifications, or\\ninter-wallet communication, may have different value extraction models. Some users might provide services for the\\nproject and expect to receive value by running nodes, while others may pay for the product or run infrastructure to\\ncontribute back. Waku aims to support each of these use cases, which means there will be various ways to \\"pay for the\\ninfrastructure.\\"\\n\\nIn [his talk](https://vac.dev/building-privacy-protecting-infrastructure), Oskar addressed two strategies: RLN and service credentials.\\n\\n### RLN and Service Credentials\\n\\nRLN enables DOS protection across the network in a privacy-preserving and permission-less manner: stake in a contract,\\nand you can send messages.\\n\\nService credentials establish a customer-provider relationship. Users might pay to have messages they are interested in\\nstored and served by a provider. Alternatively, a community owner could pay a service provider to host their community.\\n\\nProviders could offer trial or limited free services to Waku users, similar to Slack or Discord. Once a trial is expired or outgrown,\\na community owner could pay for more storage or bandwidth, similar to Slack\'s model.\\nAlternatively, individual users could contribute financially, akin to Discord\'s Server Boost, or by sharing their own\\nresources with their community.\\n\\nWe anticipate witnessing various scenarios across the spectrum: from users sharing resources to users paying for access to the network and everything in between.\\n\\n## Waku Network: Ethereum or Cosmos?\\n\\nAnother perspective is to consider whether the Waku network will resemble Ethereum or Cosmos.\\n\\nFor those not familiar with the difference between both, in a very concise manner:\\n\\n- Ethereum is a set of protocols and software that are designed to operate on one common network and infrastructure\\n- Cosmos is a set of protocols and software (SDKs) designed to be deployed in separate yet interoperable networks and infrastructures by third parties\\n\\nWe want Waku to be decentralized to provide censorship resistance and privacy-preserving communication.\\nIf each application has to deploy its own network, we will not achieve this goal.\\nTherefore, we aim Waku to be not only an open source set of protocols, but also a shared infrastructure that anyone can leverage to build applications on top, with some guarantees in terms of decentralization and anonymity.\\nThis approach is closer in spirit to Ethereum than Cosmos.\\nDo note that, similarly to Ethereum, anyone is free to take Waku software and protocols and deploy their own network.\\n\\nYet, because of the difference in the fee model, the Waku Network is unlikely to be as unified as Ethereum\'s.\\nWe currently assume that there will be separate gossipsub networks with different funding models.\\nSince there is no consensus on Waku, each individual operator can decide which network to support, enabling Waku to maintain its permission-less property.\\n\\nMost likely, the Waku network will be heterogeneous, and node operators will choose the incentivization model they prefer.\\n\\n## Scalability and Discovery Protocols\\n\\nTo enable scalability, the flow of messages in the Waku network will be divided in shards,\\nso that not every node has to forward every message of the whole network.\\nDiscovery protocols will facilitate users connecting to the right nodes to receive the messages they are interested in.\\n\\nDifferent shards could be subject to a variety of rate limiting techniques (globally, targeted to that shard or something in-between).\\n\\nMarketplace protocols may also be developed to help operators understand how they can best support the network and where\\ntheir resources are most needed. However, we are still far from establishing or even assert that such a marketplace will be needed.\\n\\n## Open Problems\\n\\nSplitting traffic between shards reduces bandwidth consumption for every Waku Relay node.\\nThis improvement increases the likelihood that users with home connections can participate and contribute to the gossipsub network without encountering issues.\\n\\nHowever, it does not cap traffic.\\nThere are still open problems regarding how to guarantee that someone can use Waku with lower Internet bandwidth or run critical services, such as a validation node, on the same connection.\\n\\nWe have several ongoing initiatives:\\n\\n- Analyzing the Status Community protocol to confirm efficient usage of Waku [[4]](https://github.com/vacp2p/research/issues/177)\\n- Simulating the Waku Network to measure actual bandwidth usage [[5]](https://github.com/waku-org/pm/issues/2)\\n- Segregating chat messages from control and media messages [[6]](https://rfc.vac.dev/spec/57/#control-message-shards)\\n\\nThe final solution will likely be a combination of protocols that reduce bandwidth usage or mitigate the risk of DOS attacks, providing flexibility for users and platforms to enable the best experience.\\n\\n## The Evolving Waku Network\\n\\nThe definition of the \\"Waku Network\\" will likely change over time. In the near future, it will transition from a single\\ngossipsub network to a sharded set of networks unified by a common discovery layer. This change will promote scalability\\nand allow various payment models to coexist within the Waku ecosystem.\\n\\nIn conclusion, the future of Waku Network entails growth, incentivization, and heterogeneity while steadfastly\\nmaintaining its core principles. As Waku continues to evolve, we expect it to accommodate a diverse range of use cases\\nand business models, all while preserving privacy, resisting censorship, avoiding surveillance, and remaining accessible\\nto devices with limited resources.\\n\\n## References\\n\\n1. [51/WAKU2-RELAY-SHARDING](https://rfc.vac.dev/spec/51/)\\n2. [57/STATUS-Simple-Scaling](https://rfc.vac.dev/spec/57/)\\n3. [58/RLN-V2](https://rfc.vac.dev/spec/58/)\\n4. [Scaling Status Communities: Potential Problems](https://github.com/vacp2p/research/issues/177)\\n5. [Waku Network Testing](https://github.com/waku-org/pm/issues/2)\\n6. [51/WAKU2-RELAY-SHARDING: Control Message Shards](https://rfc.vac.dev/spec/57/#control-message-shards)"},{"id":"waku-for-all","metadata":{"permalink":"/rlog/waku-for-all","source":"@site/rlog/2022-11-08-waku-for-all-decentralize-applications.mdx","title":"Waku for All Decentralized Applications and Infrastructures","description":"Waku is an open communication protocol and network. Decentralized apps and infrastructure can use Waku for their","date":"2022-11-08T00:00:00.000Z","formattedDate":"November 8, 2022","tags":[],"readingTime":6.145,"hasTruncateMarker":true,"authors":[{"name":"Franck","twitter":"fryorcraken","github":"fryorcraken","key":"franck"}],"frontMatter":{"layout":"post","name":"Waku for All Decentralized Applications and Infrastructures","title":"Waku for All Decentralized Applications and Infrastructures","date":"2022-11-08T00:00:00.000Z","authors":"franck","published":true,"slug":"waku-for-all","categories":"waku, dapp, infrastructure, public good, platform, operator","image":"/img/black-waku-logo-with-name.png","discuss":"https://forum.vac.dev/t/discussion-waku-for-all-decentralized-applications-and-infrastructures/163"},"prevItem":{"title":"The Future of Waku Network: Scaling, Incentivization, and Heterogeneity","permalink":"/rlog/future-of-waku-network"},"nextItem":{"title":"Building Privacy-Protecting Infrastructure","permalink":"/rlog/building-privacy-protecting-infrastructure"}},"content":"Waku is an open communication protocol and network. Decentralized apps and infrastructure can use Waku for their\\ncommunication needs. It is designed to enable dApps and decentralized infrastructure projects to have secure, private,\\nscalable communication. Waku is available in several languages and platforms, from Web to mobile to desktop to cloud.\\nInitially, We pushed Waku adoption to the Web ecosystem, we learned that Waku is usable in a variety of complex applications\\nand infrastructure projects. We have prioritized our effort to make Waku usable on various platforms and environments.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nWe have built Waku to be the communication layer for Web3. Waku is a collection of protocols to chose from for your\\nmessaging needs. It enables secure, censorship-resistant, privacy-preserving, spam-protected communication for its user.\\nIt is designed to run on any device, from mobile to the cloud.\\n\\nWaku is available on many systems and environments and used by several applications and SDKs for decentralized communications.\\n\\nThis involved research efforts in various domains: conversational security, protocol incentivization, zero-knowledge,\\netc.\\n\\nWaku uses novel technologies. Hence, we knew that early dogfooding of Waku was necessary. Even if research\\nwas still _in progress_ [[1]](#references). Thus, as soon as Waku protocols and software were usable, we started to push\\nfor the adoption of Waku. This started back in 2021.\\n\\nWaku is the communication component of the Web3 trifecta. This trifecta was Ethereum (contracts), Swarm\\n(storage) and Whisper (communication). Hence, it made sense to first target dApps which already uses one of the pillars:\\nEthereum.\\n\\nAs most dApps are web apps, we started the development of [js-waku for the browser](https://vac.dev/presenting-js-waku).\\n\\nOnce ready, we reached out to dApps to integrate Waku, added [prizes to hackathons](https://twitter.com/waku_org/status/1451400128791605254?s=20&t=Zhc0BEz6RVLkE_SeE6UyFA)\\nand gave [talks](https://docs.wakuconnect.dev/docs/presentations/).\\n\\nWe also assumed we would see patterns in the usage of Waku, that we would facilitate with the help of\\n[SDKs](https://github.com/status-im/wakuconnect-vote-poll-sdk).\\n\\nFinally, we created several web apps:\\n[examples](https://docs.wakuconnect.dev/docs/examples/)\\nand [PoCs](https://github.com/status-iM/gnosis-safe-waku).\\n\\nBy discussing with Waku users and watching it being used, we learned a few facts:\\n\\n1. The potential use cases for Waku are varied and many:\\n\\n- Wallet &lt;&gt; dApp communication: [WalletConnect](https://medium.com/walletconnect/walletconnect-v2-0-protocol-whats-new-3243fa80d312), [XMTP](https://xmtp.org/docs/dev-concepts/architectural-overview/)\\n- Off-chain (and private) marketplace:\\n  [RAILGUN](https://twitter.com/RAILGUN_Project/status/1556780629848727552?s=20&t=NEKQJiJAfg5WJqvuF-Ym_Q) &\\n  [Decentralized Uber](https://twitter.com/TheBojda/status/1455557282318721026)\\n- Signature exchange for a multi-sign wallet: [Gnosis Safe x Waku](https://github.com/status-im/gnosis-safe-waku)\\n- Off-chain Game moves/actions: [Super Card Game (EthOnline 2021)](https://showcase.ethglobal.com/ethonline2021/super-card-game)\\n- Decentralized Pastebin: [Debin](https://debin.io/)\\n\\n2. Many projects are interested in having an embedded chat in their dApp,\\n3. There are complex applications that need Waku as a solution. Taking RAILGUN as an example:\\n\\n- Web wallet\\n- \\\\+ React Native mobile wallet\\n- \\\\+ NodeJS node/backend.\\n\\n(1) means that it is not that easy to create SDKs for common use cases.\\n\\n(2) was a clear candidate for an SDK. Yet, building a chat app is a complex task. Hence, the Status app team tackled\\nthis in the form of [Status Web](https://github.com/status-im/status-web/).\\n\\nFinally, (3) was the most important lesson. We learned that multi-tier applications need Waku for decentralized and\\ncensorship-resistant communications. For these projects, js-waku is simply not enough. They need Waku to work in their\\nGolang backend, Unity desktop game and React Native mobile app.\\n\\nWe understood that we should see the whole Waku software suite\\n([js-waku](https://github.com/waku-org/js-waku),\\n[nwaku](https://github.com/status-im/nwaku),\\n[go-waku](https://github.com/status-im/go-waku),\\n[waku-react-native](https://github.com/waku-org/waku-react-native),\\n[etc](https://github.com/waku-org)) as an asset for its success.\\nThat we should not limit outreach, marketing, documentation efforts to the web, but target all platforms.\\n\\nFrom a market perspective, we identified several actors:\\n\\n- platforms: Projects that uses Waku to handle communication,\\n- operators: Operators run Waku nodes and are incentivized to do so,\\n- developers: Developers are usually part of a platforms or solo hackers learning Web3,\\n- contributors: Developers and researchers with interests in decentralization, privacy, censorship-resistance,\\n  zero-knowledge, etc.\\n\\n## Waku for All Decentralized Applications and Infrastructures\\n\\nIn 2022, we shifted our focus to make the various Waku implementations **usable and used**.\\n\\nWe made Waku [multi-plaform](https://github.com/status-im/go-waku/tree/master/examples).\\n\\nWe shifted Waku positioning to leverage all Waku implementations and better serve the user\'s needs:\\n\\n- Running a node for your projects and want to use Waku? Use [nwaku](https://github.com/status-im/nwaku).\\n- Going mobile? Use [Waku React Native](https://github.com/status-im/waku-react-native).\\n- C++ Desktop Game? Use [go-waku\'s C-Bindings](https://github.com/status-im/go-waku/tree/master/examples/c-bindings).\\n- Web app? Use [js-waku](https://github.com/status-im/js-waku).\\n\\nWe are consolidating the documentation for all implementations on a single website ([work in progress](https://github.com/waku-org/waku.org/issues/15))\\nto improve developer experience.\\n\\nThis year, we also started the _operator outreach_ effort to push for users to run their own Waku nodes. We have\\nrecently concluded our [first operator trial run](https://github.com/status-im/nwaku/issues/828).\\n[Nwaku](https://vac.dev/introducing-nwaku)\'s documentation, stability and performance has improved. It is now easier to\\nrun your [own Waku node](https://github.com/status-im/nwaku/tree/master/docs/operators).\\n\\nToday, operator wannabes most likely run their own nodes to support or use the Waku network.\\nWe are [dogfooding](https://twitter.com/oskarth/status/1582027828295790593?s=20&t=DPEP6fXK6KWbBjV5EBCBMA)\\n[Waku RLN](https://github.com/status-im/nwaku/issues/827), our novel economic spam protection protocol,\\nand looking at [incentivizing the Waku Store protocol](https://github.com/vacp2p/research/issues/99).\\nThis way, we are adding reasons to run your own Waku node.\\n\\nFor those who were following us in 2021, know that we are retiring the _Waku Connect_ branding in favour of the _Waku_\\nbranding.\\n\\n## Waku for Your Project\\n\\nAs discussed, Waku is now available on various platforms. The question remains: How can Waku benefit **your** project?\\n\\nHere are a couple of use cases we recently investigated:\\n\\n## Layer-2 Decentralization\\n\\nMost ([[2] [3]](#references) roll-ups use a centralized sequencer or equivalent. Running several sequencers is not as straightforward as running several execution nodes.\\nWaku can help:\\n\\n- Provide a neutral marketplace for a mempool: If sequencers compete for L2 tx fees, they may not be incentivized to\\n  share transactions with other sequencers. Waku nodes can act as a neutral network to enable all sequences to access\\n  transactions.\\n- Enable censorship-resistant wallet&lt;&gt;L2 communication,\\n- Provide rate limiting mechanism for spam protection: Using [RLN](https://rfc.vac.dev/spec/32/) to prevent DDOS.\\n\\n## Device pairing and communication\\n\\nWith [Waku Device Pairing](https://rfc.vac.dev/spec/43/), a user can setup a secure encrypted communication channel\\nbetween their devices. As this channel would operate over Waku, it would be censorship-resistant and privacy preserving.\\nThese two devices could be:\\n\\n- Ethereum node and mobile phone to access a remote admin panel,\\n- Alice\'s phone and Bob\'s phone for any kind of secure communication,\\n- Mobile wallet and desktop/browser dApp for transaction and signature exchange.\\n\\nCheck [js-waku#950](https://github.com/waku-org/js-waku/issues/950) for the latest update on this.\\n\\n## Get Involved\\n\\nDeveloper? Grab any of the Waku implementations and integrate it in your app: https://waku.org/platform.\\n\\nResearcher? See https://vac.dev/contribute to participate in Waku research.\\n\\nTech-savvy? Try to run your own node: https://waku.org/operator.\\n\\nOtherwise, play around with the various [web examples](https://github.com/waku-org/js-waku-examples#readme).\\n\\nIf you want to help, we are [hiring](https://jobs.status.im/)!\\n\\n## Moving Forward\\n\\nWhat you can expect next:\\n\\n- [Scalability and performance studies](https://forum.vac.dev/t/waku-v2-scalability-studies/142/9) and improvement across Waku software,\\n- [New websites](https://github.com/waku-org/waku.org/issues/15) to easily find documentation about Waku and its implementations,\\n- New Waku protocols implemented in all code bases and cross client PoCs\\n  ([noise](https://rfc.vac.dev/spec/35/), [noise-sessions](https://rfc.vac.dev/spec/37/),\\n  [waku-rln-relay](https://rfc.vac.dev/spec/17/), etc),\\n- Easier to [run your own waku node](https://github.com/status-im/nwaku/issues/828), more operator trials,\\n- Dogfooding and Improvement of existing protocols (e.g. [Waku Filter](https://github.com/vacp2p/rfc/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc++12%2FWAKU2-FILTER)),\\n- Continue our focus Waku portability: Browser,\\n  [Raspberry Pi Zero](https://twitter.com/richardramos_me/status/1574405469912932355?s=20&t=DPEP6fXK6KWbBjV5EBCBMA) and other restricted-resource environments,\\n- More communication & marketing effort around Waku and the Waku developer community.\\n\\n---\\n\\n## References\\n\\n- \\\\[1\\\\] Waku is modular; it is a suite of protocols; hence some Waku protocols may be mature, while\\n  new protocols are still being designed. Which means that research continues to be _ongoing_ while\\n  Waku is already used in production.\\n- [[2]](https://community.optimism.io/docs/how-optimism-works/#block-production) The Optimism Foundation runs the only block produce on the Optimism network.\\n- [[3]](https://l2beat.com/) Top 10 L2s are documented has having a centralized operator."},{"id":"building-privacy-protecting-infrastructure","metadata":{"permalink":"/rlog/building-privacy-protecting-infrastructure","source":"@site/rlog/2022-11-04-building-privacy-protecting-infrastructure.mdx","title":"Building Privacy-Protecting Infrastructure","description":"What is privacy-protecting infrastructure? Why do we need it and how we can build it? We\'ll look at Waku, the communication layer for Web3. We\'ll see how it uses ZKPs to incentivize and protect the Waku network. We\'ll also look at Zerokit, a library that makes it easier to use ZKPs in different environments. After reading this, I hope you\'ll better understand the importance of privacy-protecting infrastructure and how we can build it.","date":"2022-11-04T12:00:00.000Z","formattedDate":"November 4, 2022","tags":[],"readingTime":18.595,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"Building Privacy-Protecting Infrastructure","title":"Building Privacy-Protecting Infrastructure","date":"2022-11-04T12:00:00.000Z","authors":"oskarth","published":true,"slug":"building-privacy-protecting-infrastructure","categories":"research","image":"/img/building_private_infra_intro.png","discuss":"https://forum.vac.dev/t/discussion-building-privacy-protecting-infrastructure/161"},"prevItem":{"title":"Waku for All Decentralized Applications and Infrastructures","permalink":"/rlog/waku-for-all"},"nextItem":{"title":"Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay","permalink":"/rlog/wakuv2-relay-anon"}},"content":"What is privacy-protecting infrastructure? Why do we need it and how we can build it? We\'ll look at Waku, the communication layer for Web3. We\'ll see how it uses ZKPs to incentivize and protect the Waku network. We\'ll also look at Zerokit, a library that makes it easier to use ZKPs in different environments. After reading this, I hope you\'ll better understand the importance of privacy-protecting infrastructure and how we can build it.\\n\\n\x3c!--truncate--\x3e\\n\\n_This write-up is based on a talk given at DevCon 6 in Bogota, a video can be found [here](https://www.youtube.com/watch?v=CW1DYJifdhs)_\\n\\n### Intro\\n\\nIn this write-up, we are going to talk about building privacy-protecting\\ninfrastructure. What is it, why do we need it and how can we build it?\\n\\nWe\'ll look at Waku, the communication layer for Web3. We\'ll look at how we are\\nusing Zero Knowledge (ZK) technology to incentivize and protect the Waku\\nnetwork. We\'ll also look at Zerokit, a library we are writing to make ZKP easier\\nto use in different environments.\\n\\nAt the end of this write-up, I hope you\'ll come away with an understanding of\\nthe importance of privacy-protecting infrastructure and how we can build it.\\n\\n### About\\n\\nFirst, briefly about Vac. We build public good protocols for the decentralized\\nweb, with a focus on privacy and communication. We do applied research based on\\nwhich we build protocols, libraries and publications. We are also the custodians\\nof protocols that reflect a set of principles.\\n\\n![Principles](/img/building_private_infra_principles.png)\\n\\nIt has its origins in the [Status app](https://status.im/) and trying to improve\\nthe underlying protocols and infrastructure. We build [Waku](https://waku.org/),\\namong other things.\\n\\n### Why build privacy-protecting infrastructure?\\n\\nPrivacy is the power to selectively reveal yourself. It is a requirement for\\nfreedom and self-determination.\\n\\nJust like you need decentralization in order to get censorship-resistance, you\\nneed privacy to enable freedom of expression.\\n\\nTo build applications that are decentralized and privacy-protecting, you need\\nthe base layer, the infrastructure itself, to have those properties.\\n\\nWe see this a lot. It is easier to make trade-offs at the application layer than\\ndoing them at the base layer. You can build custodial solutions on top of a\\ndecentralized and non-custodial network where participants control their own\\nkeys, but you can\'t do the opposite.\\n\\nIf you think about it, buildings can be seen as a form of privacy-protecting\\ninfrastructure. It is completely normal and obvious in many ways, but when it\\ncomes to the digital realm our mental models and way of speaking about it hasn\'t\\ncaught up yet for most people.\\n\\nI\'m not going too much more into the need for privacy or what happens when you\\ndon\'t have it, but suffice to say it is an important property for any open\\nsociety.\\n\\nWhen we have conversations, true peer-to-peer offline conversations, we can talk\\nprivately. If we use cash to buy things we can do commerce privately.\\n\\nOn the Internet, great as it is, there are a lot of forces that makes this\\nnatural state of things not the default. Big Tech has turned users into a\\ncommodity, a product, and monetized user\'s attention for advertising. To\\noptimize for your attention they need to surveil your habits and activities, and\\nhence breach your privacy. As opposed to more old-fashioned models, where\\nsomeone is buying a useful service from a company and the incentives are more\\naligned.\\n\\nWe need to build credibly neutral infrastructure that protects your privacy at\\nthe base layer, in order to truly enable applications that are\\ncensorship-resistant and encourage meaningful freedom of expression.\\n\\n### Web3 infrastructure\\n\\nInfrastructure is what lies underneath. Many ways of looking at this but I\'ll\\nkeep it simple as per the original Web3 vision. You had Ethereum for\\ncompute/consensus, Swarm for storage, and Whisper for messaging. Waku has taken\\nover the mantle from Whisper and is a lot more\\n[usable](https://vac.dev/fixing-whisper-with-waku) today than Whisper ever was,\\nfor many reasons.\\n\\n![Web3 Infrastructure](/img/web3_holy_trinity.png)\\n\\nOn the privacy-front, we see how Ethereum is struggling. It is a big UX problem,\\nespecially when you try to add privacy back \\"on top\\". It takes a lot of effort\\nand it is easier to censor. We see this with recent action around Tornado Cash.\\nCompare this with something like Zcash or Monero, where privacy is there by\\ndefault.\\n\\nThere are also problems when it comes to the p2p networking side of things, for\\nexample with Ethereum validator privacy and hostile actors and jurisdictions. If\\nsomeone can easily find out where a certain validator is physically located,\\nthat\'s a problem in many parts of the world. Being able to have stronger\\nprivacy-protection guarantees would be very useful for high-value targets.\\n\\nThis doesn\'t begin to touch on the so called \\"dapps\\" that make a lot of\\nsacrifices in how they function, from the way domains work, to how websites are\\nhosted and the reliance on centralized services for communication. We see this\\ntime and time again, where centralized, single points of failure systems work\\nfor a while, but then eventually fail.\\n\\nIn many cases an individual user might not care enough though, and for platforms\\nthe lure to take shortcuts is strong. That is why it is important to be\\nprincipled, but also pragmatic in terms of the trade-offs that you allow on top.\\nWe\'ll touch more on this in the design goals around modularity that Waku has.\\n\\n### ZK for privacy-protecting infrastructure\\n\\nZKPs are a wonderful new tool. Just like smart contracts enables programmable\\nmoney, ZKPs allow us to express fundamentally new things. In line with the great\\ntradition of trust-minimization, we can prove statement while revealing the\\nabsolute minimum information necessary. This fits the definition of privacy, the\\npower to selectively reveal yourself, perfectly. I\'m sure I don\'t need to tell\\nanyone reading this but this is truly revolutionary. The technology is advancing\\nextremely fast and often it is our imagination that is the limit.\\n\\n![Zero knowledge](/img/building_private_infra_zk.png)\\n\\n### Waku\\n\\nWhat is Waku? It is a set of modular protocols for p2p communication. It has a\\nfocus on privacy, security and being able to run anywhere. It is the spiritual\\nsuccess to Whisper.\\n\\nBy modular we mean that you can pick and choose protocols and how you use them\\ndepending on constraints and trade-offs. For example, bandwidth usage vs\\nprivacy.\\n\\nIt is designed to work in resource restricted environments, such as mobile\\nphones and in web browsers. It is important that infrastructure meets users\\nwhere they are and supports their real-world use cases. Just like you don\'t need\\nyour own army and a castle to have your own private bathroom, you shouldn\'t need\\nto have a powerful always-on node to get reasonable privacy and\\ncensorship-resistance. We might call this self-sovereignty.\\n\\n### Waku - adaptive nodes\\n\\nOne way of looking at Waku is as an open service network. There are nodes with\\nvarying degrees of capabilities and requirements. For example when it comes to\\nbandwidth usage, storage, uptime, privacy requirements, latency requirements,\\nand connectivity restrictions.\\n\\nWe have a concept of adaptive nodes that can run a variety of protocols. A node\\noperator can choose which protocols they want to run. Naturally, there\'ll be\\nsome nodes that do more consumption and other nodes that do more provisioning.\\nThis gives rise to the idea of a service network, where services are provided\\nfor and consumed.\\n\\n![Adaptive Nodes](/img/building_private_infra_adaptive.png)\\n\\n### Waku - protocol interactions\\n\\nThere are many protocols that interact. Waku Relay protocol is based on libp2p\\nGossipSub for p2p messaging. We have filter for bandwidth-restricted nodes to\\nonly receive subset of messages. Lightpush for nodes with short connection\\nwindows to push messages into network. Store for nodes that want to retrieve\\nhistorical messages.\\n\\nOn the payload layer, we provide support for Noise handshakes/key-exchanges.\\nThis means that as a developers, you can get end-to-end encryption and expected\\nguarantees out of the box. We have support for setting up a secure channel from\\nscratch, and all of this paves the way for providing Signal\'s Double Ratchet at\\nthe protocol level much easier. We also have experimental support for\\nmulti-device usage. Similar features have existed in for example the Status app\\nfor a while, but with this we make it easier for any platform using Waku to use\\nit.\\n\\nThere are other protocols too, related to peer discovery, topic usage, etc. See\\n[specs](https://rfc.vac.dev/) for more details.\\n\\n![Protocol Interactions](/img/building_private_infra_interactions.png)\\n\\n### Waku - Network\\n\\nFor the Waku network, there are a few problems. For example, when it comes to\\nnetwork spam and incentivizing service nodes. We want to address these while\\nkeeping privacy-guarantees of the base layer. I\'m going to go into both of\\nthese.\\n\\nThe spam problem arises on the gossip layer when anyone can overwhelm the\\nnetwork with messages. The service incentivization is a problem when nodes don\'t\\ndirectly benefit from the provisioning of a certain service. This can happen if\\nthey are not using the protocol directly themselves as part of normal operation,\\nor if they aren\'t socially inclined to provide a certain service. This depends a\\nlot on how an individual platform decides to use the network.\\n\\n![Waku Network](/img/building_private_infra_network.png)\\n\\n### Dealing with network spam and RLN Relay\\n\\nSince the p2p relay network is open to anyone, there is a problem with spam. If\\nwe look at existing solutions for dealing with spam in traditional messaging\\nsystems, a lot of entities like Google, Facebook, Twitter, Telegram, Discord use\\nphone number verification. While this is largely sybil-resistant, it is\\ncentralized and not private at all.\\n\\nHistorically, Whisper used PoW which isn\'t good for heterogenerous networks.\\nPeer scoring is open to sybil attacks and doesn\'t directly address spam\\nprotection in an anonymous p2p network.\\n\\nThe key idea here is to use RLN for private economic spam protection using\\nzkSNARKs.\\n\\nI\'m not going to go into too much detail of RLN here. If you are interested, I\\ngave a [talk](https://www.youtube.com/watch?v=g41nHQ0mLoA) in Amsterdam at\\nDevconnect about this. We have some write-ups on RLN\\n[here](https://vac.dev/rln-relay) by Sanaz who has been pushing a lot of this\\nfrom our side. There\'s also another talk at Devcon by Tyler going into RLN in\\nmore detail. Finally, here\'s the [RLN spec](https://rfc.vac.dev/spec/32/).\\n\\nI\'ll briefly go over what it is, the interface and circuit and then talk about\\nhow it is used in Waku.\\n\\n### RLN - Overview and Flow\\n\\nRLN stands for Rate Limiting Nullifier. It is an anonyomous rate limiting\\nmechanism based on zkSNARKs. By rate limiting we mean you can only send N\\nmessages in a given period. By anonymity we mean that you can\'t link message to\\na publisher. We can think of it as a voting booth, where you are only allowed to\\nvote once every election.\\n\\n![Voting Booth](/img/building_private_infra_vote.png)\\n\\nIt can be used for spam protection in p2p messaging systems, and also rate\\nlimiting in general, such as for a decentralized captcha.\\n\\nThere are three parts to it. You register somewhere, then you can signal and\\nfinally there\'s a verification/slashing phase. You put some capital at risk,\\neither economic or social, and if you double signal you get slashed.\\n\\n### RLN - Circuit\\n\\nHere\'s what the private and public inputs to the circuit look like. The identity\\nsecret is generated locally, and we create an identity commitment that is\\ninserted into a Merkle tree. We then use Merkle proofs to prove membership.\\nRegistered member can only signal once for a given epoch or external nullifier,\\nfor example every ten seconds in Unix time. RLN identifer is for a specific RLN\\napp.\\n\\nWe also see what the circuit output looks like. This is calculated locally. `y`\\nis a share of the secret equation, and the (internal) nullifier acts as a unique\\nfingerprint for a given app/user/epoch combination. How do we calculate `y` and\\nthe internal nullifier?\\n\\n```\\n// Private input\\nsignal input identity_secret;\\nsignal input path_elements[n_levels][1];\\nsignal input identity_path_index[n_levels];\\n\\n// Public input\\nsignal input x; // signal_hash\\nsignal input epoch; // external_nullifier\\nsignal input rln_identifier;\\n\\n// Circuit output\\nsignal output y;\\nsignal output root;\\nsignal output nullifier;\\n```\\n\\n### RLN - Shamir\'s secret sharing\\n\\nThis is done using [Shamir\'s secret\\nsharing](https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing). Shamir\u2019s\\nsecret sharing is based on idea of splitting a secret into shares. This is how\\nwe enable slashing of funds.\\n\\nIn this case, we have two shares. If a given identity `a0` signals twice in\\nepoch/external nullifier, `a1` is the same. For a given RLN app,\\n`internal_nullifier` then stays the same. `x` is signal hash which is different,\\nand `y` is public, so we can reconstruct `identity_secret`. With the identity\\nsecret revealed, this gives access to e.g. financial stake.\\n\\n```\\na_0 = identity_secret // secret S\\na_1 = poseidonHash([a0, external_nullifier])\\n\\ny = a_0 + x * a_1\\n\\ninternal_nullifier = poseidonHash([a_1, rln_identifier])\\n```\\n\\n![Shamir\'s secret sharing](/img/building_private_infra_shamir.png)\\n\\n### RLN Relay\\n\\nThis is how RLN is used with Relay/GossipSub protocol. A node registers and\\nlocks up funds, and after that it can send messages. It publishes a message\\ncontaining the Zero Knowledge proof and some other details.\\n\\nEach relayer node listens to the membership contract for new members, and it\\nalso keeps track of relevant metadata and merkle tree. Metadata is needed to be\\nable to detect double signaling and perform slashing.\\n\\nBefore forwarding a message, it does some verification checks to ensure there\\nare no duplicate messages, ZKP is valid and no double signaling has occured. It\\nis worth noting that this can be combined with peer scoring, for example for\\nduplicate messages or invalid ZK proofs.\\n\\nIn line of Waku\'s goals of modularity, RLN Relay is applied on a specific subset\\nof pubsub and content topics. You can think of it as an extra secure channel.\\n\\n![RLN Relay](/img/building_private_infra_rlnrelay.png)\\n\\n### RLN Relay cross-client testnet\\n\\nWhere are we with RLN Relay deployment? We\'ve recently launched our second\\ntestnet. This is using RLN Relay with a smart contract on Goerli. It integrates\\nwith our example p2p chat application, and it does so through three different\\nclients, nwaku, go-waku and js-waku for browsers. This is our first p2p\\ncross-client testnet for RLN Relay.\\n\\nHere\'s a [video](https://www.youtube.com/watch?v=-vVrJWW0fls) that shows a user\\nregistering in a browser, signaling through JS-Waku. It then gets relayed to a\\nnwaku node, that verifies the proof. The second\\n[video](https://www.youtube.com/watch?v=Xz5q2ZhkFYs) shows what happens in the\\nspam case. when more than one message is sent in a given epoch, it detects it as\\nspam and discards it. Slashing hasn\'t been implemented fully yet in the client\\nand is a work in progress.\\n\\nIf you are curious and want to participate, you can join the effort on our [Vac\\nDiscord](https://discord.gg/PQFdubGt6d). We also have\\n[tutorials](https://github.com/status-im/nwaku/blob/master/docs/tutorial/rln-chat-cross-client.md)\\nsetup for all clients so you can play around with it.\\n\\nAs part of this, and to make it work in multiple different environments, we\'ve\\nalso been developing a new library called Zerokit. I\'ll talk about this a bit\\nlater.\\n\\n### Private settlement / Service credentials\\n\\nGoing back to the service network idea, let\'s talk about service credentials.\\nThe idea behind service credentials and private settlement is to enable two\\nactors to pay for and provide services without compromising their privacy. We do\\nnot want the payment to create a direct public link between the service provider\\nand requester.\\n\\nRecall the Waku service network illustration with adaptive nodes that choose\\nwhich protocols they want to run. Many of these protocols aren\'t very heavy and\\njust work by default. For example the relay protocol is enabled by default.\\nOther protocols are much heavier to provide, such as storing historical\\nmessages.\\n\\nIt is desirable to have additional incentives for this, especially for platforms\\nthat aren\'t community-based where some level of altruism can be assumed (e.g.\\nStatus Communities, or WalletConnect cloud infrastructure).\\n\\nYou have a node Alice that is often offline and wants to consume historical\\nmessages on some specific content topics. You have another node Bob that runs a\\nserver at home where they store historical messages for the last several weeks.\\nBob is happy to provide this service for free because he\'s excited about running\\nprivacy-preserving infrastructure and he\'s using it himself, but his node is\\ngetting overwhelmed by freeloaders and he feels like he should be paid something\\nfor continuing to provide this service.\\n\\nAlice deposits some funds in a smart contract which registers it in a tree,\\nsimilar to certain other private settlement mechanisms. A fee is taken or\\nburned. In exchange, she gets a set of tokens or service credentials. When she\\nwants to do a query with some criteria, she sends this to Bob. Bob responds with\\nsize of response, cost, and receiver address. Alice then sends a proof of\\ndelegation of a service token as a payment. Bob verifies the proof and resolves\\nthe query.\\n\\nThe end result is that Alice has consumed some service from Bob, and Bob has\\nreceived payment for this. There\'s no direct transaction link between Alice and\\nBob, and gas fees can be minimized by extending the period before settling on\\nchain.\\n\\nThis can be complemented with altruistic service provisioning, for example by\\nsplitting the peer pool into two slots, or only providing a few cheap queries\\nfor free.\\n\\nThe service provisioning is general, and can be generalized for any kind of\\nrequest/response service provisoning that we want to keep private.\\n\\nThis isn\'t a perfect solution, but it is an incremental improvement on top of\\nthe status quo. It can be augmented with more advanced techniques such as better\\nnon-repudiable node reputation, proof of correct service provisioning, etc.\\n\\nWe are currently in the raw spec / proof of concept stage of this. We expect to\\nlaunch a testnet of this later this year or early next year.\\n\\n![Service credentials flow](/img/building_private_infra_servicecred.png)\\n\\n### Zerokit\\n\\n[Zerokit](https://github.com/vacp2p/zerokit) is a set of Zero Knowledge modules,\\nwritten in Rust and designed to be used in many different environments. The\\ninitial goal is to get the best of both worlds with Circom/Solidity/JS and\\nRust/ZK ecosystem. This enables people to leverage Circom-based constructs from\\nnon-JS environments.\\n\\nFor the RLN module, it is using Circom circuits via ark-circom and Rust for\\nscaffolding. It exposes a C FFI API that can be used through other system\\nprogramming environments, like Nim and Go. It also exposes an experimental WASM\\nAPI that can be used through web browsers.\\n\\nWaku is p2p infrastructure running in many different environments, such as\\nNim/JS/Go/Rust, so this a requirement for us.\\n\\nCircom and JS strengths are access to Dapp developers, tooling, generating\\nverification code, circuits etc. Rust strengths is that it is systems-based and\\neasy to interface with other language runtime such as Nim, Go, Rust, C. It also\\ngives access to other Rust ZK ecosystems such as arkworks. This opens door for\\nusing other constructs, such as Halo2. This becomes especially relevant for\\nconstructs where you don\'t want to do a trusted setup or where circuits are more\\ncomplex/custom and performance requirements are higher.\\n\\nIn general with Zerokit, we want to make it easy to build and use ZKP in a\\nmultitude of environments, such as mobile phones and web browsers. Currently it\\nis too complex to write privacy-protecting infrastructure with ZKPs considering\\nall the languages and tools you have to learn, from JS, Solidity and Circom to\\nRust, WASM and FFI. And that isn\'t even touching on things like secure key\\nstorage or mobile dev. Luckily more and more projects are working on this,\\nincluding writing DSLs etc. It\'d also be exciting if we can make a useful\\ntoolstack for JS-less ZK dev to reduce cognitive overhead, similar to what we\\nhave with something like Foundry.\\n\\n### Other research\\n\\nI also want to mention a few other things we are doing. One thing is\\n[protocol specifications](https://rfc.vac.dev/). We think this is very important\\nfor p2p infra, and we see a lot of other projects that claim to do it p2p\\ninfrastructure but they aren\'t clear about guarantees or how stable something\\nis. That makes it hard to have multiple implementations, to collaborate across\\ndifferent projects, and to analyze things objectively.\\n\\nRelated to that is publishing [papers](https://vac.dev/publications). We\'ve put\\nout three so far, related to Waku and RLN-Relay. This makes it easier to\\ninterface with academia. There\'s a lot of good researchers out there and we want\\nto build a better bridge between academia and industry.\\n\\nAnother thing is [network](https://vac.dev/wakuv2-relay-anon)\\n[privacy](https://github.com/vacp2p/research/issues/107). Waku is modular with\\nrespect to privacy guarantees, and there are a lot of knobs to turn here\\ndepending on specific deployments. For example, if you are running the full\\nrelay protocol you currently have much stronger receiver anonymity than if you\\nare running filter protocol from a bandwidth or connectivity-restricted node.\\n\\nWe aim to make this pluggable depending on user needs. E.g. mixnets such as Nym\\ncome with some trade-offs but are a useful tool in the arsenal. A good mental\\nmodel to keep in mind is the anonymity trilemma, where you can only pick 2/3 out\\nof low latency, low bandwidth usage and strong anonymity.\\n\\nWe are currently exploring [Dandelion-like\\nadditions](https://github.com/vacp2p/research/issues/119) to the relay/gossip\\nprotocol, which would provide for stronger sender anonymity, especially in a\\nmulti-node/botnet attacker model. As part of this we are looking into different\\nparameters choices and general possibilities for lower latency usage. This could\\nmake it more amenable for latency sensitive environments, such as validator\\nprivacy, for specific threat models. The general theme here is we want to be\\nrigorous with the guarantees we provide, under what conditions and for what\\nthreat models.\\n\\nAnother thing mentioned earlier is [Noise payload\\nencryption](https://vac.dev/wakuv2-noise), and specifically things like allowing\\nfor pairing different devices with e.g. QR codes. This makes it easier for\\ndevelopers to provide secure messaging in many realistic scenarios in a\\nmulti-device world.\\n\\n![Other research](/img/building_private_infra_misc.png)\\n\\n### Summary\\n\\nWe\'ve gone over what privacy-protecting infrastructure is, why we want it and\\nhow we can build it. We\'ve seen how ZK is a fundamental building block for this.\\nWe\'ve looked at Waku, the communication layer for Web3, and how it uses Zero\\nKnowledge proofs to stay private and function better. We\'ve also looked at\\nZerokit and how we can make it easier to do ZKP in different environments.\\n\\nFinally we also looked at some other research we\'ve been doing. All of the\\nthings mentioned in this article, and more, is available as\\n[write-ups](https://vac.dev/research), [specs](https://rfc.vac.dev/), or\\ndiscussions on our [forum](forum.vac.dev/) or [Github](github.com/vacp2p/).\\n\\nIf you find any of this exciting to work on, feel free to reach out on our\\nDiscord. We are also [hiring](https://jobs.status.im/), and we have started\\nexpanding into other privacy infrastructure tech like private and provable\\ncomputation with ZK-WASM."},{"id":"wakuv2-relay-anon","metadata":{"permalink":"/rlog/wakuv2-relay-anon","source":"@site/rlog/2022-07-22-relay-anonymity.mdx","title":"Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay","description":"Introducing a basic threat model and privacy/anonymity analysis for the Waku v2 relay protocol.","date":"2022-07-22T10:00:00.000Z","formattedDate":"July 22, 2022","tags":[],"readingTime":16.78,"hasTruncateMarker":true,"authors":[{"name":"Daniel","github":"kaiserd","key":"kaiserd"}],"frontMatter":{"layout":"post","name":"Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay","title":"Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay","date":"2022-07-22T10:00:00.000Z","authors":"kaiserd","published":true,"slug":"wakuv2-relay-anon","categories":"research","image":"/img/anonymity_trilemma.svg","discuss":"https://forum.vac.dev/t/discussion-waku-privacy-and-anonymity-analysis/149","_includes":["math"],"toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"Building Privacy-Protecting Infrastructure","permalink":"/rlog/building-privacy-protecting-infrastructure"},"nextItem":{"title":"Noise handshakes as key-exchange mechanism for Waku","permalink":"/rlog/wakuv2-noise"}},"content":"Introducing a basic threat model and privacy/anonymity analysis for the Waku v2 relay protocol.\\n\\n\x3c!--truncate--\x3e\\n\\n[Waku v2](https://rfc.vac.dev/spec/10/) enables secure, privacy preserving communication using a set of modular P2P protocols.\\nWaku v2 also aims at protecting the user\'s anonymity.\\nThis post is the first in a series about Waku v2 security, privacy, and anonymity.\\nThe goal is to eventually have a full privacy and anonymity analysis for each of the Waku v2 protocols, as well as covering the interactions of various Waku v2 protocols.\\nThis provides transparency with respect to Waku\'s current privacy and anonymity guarantees, and also identifies weak points that we have to address.\\n\\nIn this post, we first give an informal description of security, privacy and anonymity in the context of Waku v2.\\nFor each definition, we summarize Waku\'s current guarantees regarding the respective property.\\nWe also provide attacker models, an attack-based threat model, and a first anonymity analysis of [Waku v2 relay](https://rfc.vac.dev/spec/11/) within the respective models.\\n\\nWaku comprises many protocols that can be combined in a modular way.\\nFor our privacy and anonymity analysis, we start with the relay protocol because it is at the core of Waku v2 enabling Waku\'s publish subscribe approach to P2P messaging.\\nIn its current form, Waku relay is a minor extension of [libp2p GossipSub](https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/README.md).\\n\\n![Figure 1: The Waku v2 relay mesh is based on the [GossipSub mesh](https://docs.libp2p.io/concepts/publish-subscribe#types-of-peering)](/img/libp2p_gossipsub_types_of_peering.png)\\n\\n## Informal Definitions: Security, Privacy, and Anonymity\\n\\nThe concepts of security, privacy, and anonymity are linked and have quite a bit of overlap.\\n\\n### Security\\n\\nOf the three, [Security](https://en.wikipedia.org/wiki/Information_security) has the clearest agreed upon definition,\\nat least regarding its key concepts: _confidentiality_, _integrity_, and _availability_.\\n\\n- confidentiality: data is not disclosed to unauthorized entities.\\n- integrity: data is not modified by unauthorized entities.\\n- availability: data is available, i.e. accessible by authorized entities.\\n\\nWhile these are the key concepts, the definition of information security has been extended over time including further concepts,\\ne.g. [authentication](https://en.wikipedia.org/wiki/Authentication) and [non-repudiation](https://en.wikipedia.org/wiki/Non-repudiation).\\nWe might cover these in future posts.\\n\\n### Privacy\\n\\nPrivacy allows users to choose which data and information\\n\\n- they want to share\\n- and with whom they want to share it.\\n\\nThis includes data and information that is associated with and/or generated by users.\\nProtected data also comprises metadata that might be generated without users being aware of it.\\nThis means, no further information about the sender or the message is leaked.\\nMetadata that is protected as part of the privacy-preserving property does not cover protecting the identities of sender and receiver.\\nIdentities are protected by the [anonymity property](#anonymity).\\n\\nOften privacy is realized by the confidentiality property of security.\\nThis neither makes privacy and security the same, nor the one a sub category of the other.\\nWhile security is abstract itself (its properties can be realized in various ways), privacy lives on a more abstract level using security properties.\\nPrivacy typically does not use integrity and availability.\\nAn adversary who has no access to the private data, because the message has been encrypted, could still alter the message.\\n\\nWaku offers confidentiality via secure channels set up with the help of the [Noise Protocol Framework](https://noiseprotocol.org/).\\nUsing these secure channels, message content is only disclosed to the intended receivers.\\nThey also provide good metadata protection properties.\\nHowever, we do not have a metadata protection analysis as of yet,\\nwhich is part of our privacy/anonymity roadmap.\\n\\n### Anonymity\\n\\nPrivacy and anonymity are closely linked.\\nBoth the identity of a user and data that allows inferring a user\'s identity should be part of the privacy policy.\\nFor the purpose of analysis, we want to have a clearer separation between these concepts.\\n\\nWe define anonymity as _unlinkablity of users\' identities and their shared data and/or actions_.\\n\\nWe subdivide anonymity into _receiver anonymity_ and _sender anonymity_.\\n\\n#### Receiver Anonymity\\n\\nWe define receiver anonymity as _unlinkability of users\' identities and the data they receive and/or related actions_.\\nThe data transmitted via Waku relay must be a [Waku message](https://rfc.vac.dev/spec/14/), which contains a content topic field.\\nBecause each message is associated with a content topic, and each receiver is interested in messages with specific content topics,\\nreceiver anonymity in the context of Waku corresponds to _subscriber-topic unlinkability_.\\nAn example for the \\"action\\" part of our receiver anonymity definition is subscribing to a specific topic.\\n\\nThe Waku message\'s content topic is not related to the libp2p pubsub topic.\\nFor now, Waku uses a single libp2p pubsub topic, which means messages are propagated via a single mesh of peers.\\nWith this, the receiver discloses its participation in Waku on the gossipsub layer.\\nWe will leave the analysis of libp2p gossipsub to a future article within this series, and only provide a few hints and pointers here.\\n\\nWaku offers k-anonymity regarding content topic interest in the global adversary model.\\n[K-anonymity](https://en.wikipedia.org/wiki/K-anonymity) in the context of Waku means an attacker can link receivers to content topics with a maximum certainty of $1/k$.\\nThe larger $k$, the less certainty the attacker gains.\\nReceivers basically hide in a pool of $k$ content topics, any subset of which could be topics they subscribed to.\\nThe attacker does not know which of those the receiver actually subscribed to,\\nand the receiver enjoys [plausible deniability](https://en.wikipedia.org/wiki/Plausible_deniability#Use_in_cryptography) regarding content topic subscription.\\nAssuming there are $n$ Waku content topics, a receiver has $n$-anonymity with respect to association to a specific content topic.\\n\\nTechnically, Waku allows distributing messages over several libp2p pubsub topics.\\nThis yields $k$-anonymity, assuming $k$ content topics share the same pubsub topic.\\nHowever, if done wrongly, such sharding of pubsub topics can breach anonymity.\\nA formal specification of anonymity-preserving topic sharding building on the concepts of [partitioned topics](https://specs.status.im/spec/10#partitioned-topic) is part of our roadmap.\\n\\nAlso, Waku is not directly concerned with 1:1 communication, so for this post, 1:1 communication is out of scope.\\nChannels for 1:1 communication can be implemented on top of Waku relay.\\nIn the future, a 1:1 communication protocol might be added to Waku.\\nSimilar to topic sharding, it would maintain receiver anonymity leveraging [partitioned topics](https://specs.status.im/spec/10#partitioned-topic).\\n\\n#### Sender Anonymity\\n\\nWe define sender anonymity as _unlinkability of users\' identities and the data they send and/or related actions_.\\nBecause the data in the context of Waku is Waku messages, sender anonymity corresponds to _sender-message unlinkability_.\\n\\nIn summary, Waku offers weak sender anonymity because of [Waku\'s strict no sign policy](https://rfc.vac.dev/spec/11/#signature-policy),\\nwhich has its origins in the [Ethereum consensus specs](https://github.com/ethereum/consensus-specs/blob/dev/specs/phase0/p2p-interface.md#why-are-we-using-the-strictnosign-signature-policy).\\n[17/WAKU-RLN-RELAY](https://rfc.vac.dev/spec/17/) and [18/WAKU2-SWAP](https://rfc.vac.dev/spec/18/) mitigate replay and injection attacks.\\n\\nWaku currently does not offer sender anonymity in stronger attacker models, as well as cannot protect against targeted attacks in weaker attacker models like the single or multi node attacker.\\nWe will cover this in more detail in later sections.\\n\\n### Anonymity Trilemma\\n\\n[The Anonymity trilemma](https://freedom.cs.purdue.edu/projects/trilemma.html) states that only two out of _strong anonymity_, _low bandwidth_, and _low latency_ can be guaranteed in the global on-net attacker model.\\nWaku\'s goal, being a modular set of protocols, is to offer any combination of two out of these three properties, as well as blends.\\nAn example for blending is an adjustable number of pubsub topics and peers in the respective pubsub topic mesh; this allows tuning the trade-off between anonymity and bandwidth.\\n\\n![Figure 2: Anonymity Trilemma: pick two. ](/img/anonymity_trilemma.svg)\\n\\nA fourth factor that influences [the anonymity trilemma](https://freedom.cs.purdue.edu/projects/trilemma.html) is _frequency and patterns_ of messages.\\nThe more messages there are, and the more randomly distributed they are, the better the anonymity protection offered by a given anonymous communication protocol.\\nSo, incentivising users to use the protocol, for instance by lowering entry barriers, helps protecting the anonymity of all users.\\nThe frequency/patterns factor is also related to the above described k-anonymity.\\n\\n### Censorship Resistance\\n\\nAnother security related property that Waku aims to offer is censorship resistance.\\nCensorship resistance guarantees that users can participate even if an attacker tries to deny them access.\\nSo, censorship resistance ties into the availability aspect of security.\\nIn the context of Waku that means users should be able to send messages as well as receive all messages they are interested in,\\neven if an attacker tries to prevent them from disseminating messages or tries to deny them access to messages.\\n\\nCurrently, Waku only guarantees censorship resistance in the weak single node attacker model.\\nWhile currently employed secure channels mitigate targeted censorship, e.g. blocking specific content topics,\\ngeneral censorship resistance in strong attacker models is part of our roadmap.\\nAmong other options, we will investigate [Pluggable Transports](https://www.pluggabletransports.info/about/) in future articles.\\n\\n## Attacker Types\\n\\nThe following lists various attacker types with varying degrees of power.\\nThe more power an attacker has, the more difficult it is to gain the respective attacker position.\\n\\nEach attacker type comes in a passive and an active variant.\\nWhile a passive attacker can stay hidden and is not suspicious,\\nthe respective active attacker has more (or at least the same) deanonymization power.\\n\\nWe also distinguish between internal and external attackers.\\n\\n### Internal\\n\\nWith respect to Waku relay, an internal attacker participates in the same pubsub topic as its victims.\\nWithout additional measures on higher layer protocols, access to an internal position is easy to get.\\n\\n#### Single Node\\n\\nThis attacker controls a single node.\\nBecause this position corresponds to normal usage of Waku relay, it is trivial to obtain.\\n\\n#### Multi Node\\n\\nThis attacker controls several nodes. We assume a smaller static number of controlled nodes.\\nThe multi node position can be achieved relatively easily by setting up multiple nodes.\\nBotnets might be leveraged to increase the number of available hosts.\\nMulti node attackers could use [Sybil attacks](https://en.wikipedia.org/wiki/Sybil_attack) to increase the number of controlled nodes.\\nA countermeasure is for nodes to only accept libp2p gossipsub graft requests from peers with different IP addresses, or even different subnets.\\n\\n#### Linearly Scaling Nodes\\n\\nThis attacker controls a number of nodes that scales linearly with the number of nodes in the network.\\nThis attacker is especially interesting to investigate in the context of DHT security,\\nwhich Waku uses for ambient peer discovery.\\n\\n### External\\n\\nAn external attacker can only see encrypted traffic (protected by a secure channel set up with [Noise](https://rfc.vac.dev/spec/35/)).\\nBecause an internal position can be easily obtained,\\nin practice external attackers would mount combined attacks that leverage both internal an external attacks.\\nWe cover this more below when describing attacks.\\n\\n#### Local\\n\\nA local attacker has access to communication links in a local network segment.\\nThis could be a rogue access point (with routing capability).\\n\\n#### AS\\n\\nAn AS attacker controls a single AS (autonomous system).\\nA passive AS attacker can listen to traffic on arbitrary links within the AS.\\nAn active AS attacker can drop, inject, and alter traffic on arbitrary links within the AS.\\n\\nIn practice, a malicious ISP would be considered as an AS attacker.\\nA malicious ISP could also easily setup a set of nodes at specific points in the network,\\ngaining internal attack power similar to a strong multi node attacker.\\n\\n#### Global On-Net\\n\\nA global on-net attacker has complete overview over the whole network.\\nA passive global attacker can listen to traffic on all links,\\nwhile the active global attacker basically carries the traffic: it can freely drop, inject, and alter traffic at all positions in the network.\\nThis basically corresponds to the [Dolev-Yao model](https://en.wikipedia.org/wiki/Dolev%E2%80%93Yao_model).\\n\\nAn entity with this power would, in practice, also have the power of the internal linearly scaling nodes attacker.\\n\\n## Attack-based Threat Analysis\\n\\nThe following lists various attacks including the weakest attacker model in which the attack can be successfully performed.\\nThe respective attack can be performed in all stronger attacker models as well.\\n\\nAn attack is considered more powerful if it can be successfully performed in a weaker attacker model.\\n\\nIf not stated otherwise, we look at these attacks with respect to their capability to deanonymize the message sender.\\n\\n### Scope\\n\\nIn this post, we introduce a simple tightly scoped threat model for Waku v2 Relay, which will be extended in the course of this article series.\\n\\nIn this first post, we will look at the relay protocol in isolation.\\nEven though many threats arise from layers Waku relay is based on, and layers that in turn live on top of relay,\\nwe want to first look at relay in isolation because it is at the core of Waku v2.\\nAddressing and trying to solve all security issues of a complex system at once is an overwhelming task, which is why we focus on the soundness of relay first.\\n\\nThis also goes well with the modular design philosophy of Waku v2, as layers of varying levels of security guarantees can be built on top of relay, all of which can relay on the guarantees that Waku provides.\\nInstead of looking at a multiplicative explosion of possible interactions, we look at the core in this article, and cover the most relevant combinations in future posts.\\n\\nFurther restricting the scope, we will look at the data field of a relay message as a black box.\\nIn a second article on Waku v2 relay, we will look into the data field, which according to the [specification of Waku v2 relay](https://rfc.vac.dev/spec/11/#message-fields) must be a [Waku v2 message](https://rfc.vac.dev/spec/14/).\\nWe only consider messages with version field `2`, which indicates that the payload has to be encoded using [35/WAKU2-NOISE](https://rfc.vac.dev/spec/35/).\\n\\n### Prerequisite: Get a Specific Position in the Network\\n\\nSome attacks require the attacker node(s) to be in a specific position in the network.\\nIn most cases, this corresponds to trying to get into the mesh peer list for the desired pubsub topic of the victim node.\\n\\nIn libp2p gossipsub, and by extension Waku v2 relay, nodes can simply send a graft message for the desired topic to the victim node.\\nIf the victim node still has open slots, the attacker gets the desired position.\\nThis only requires the attacker to know the gossipsub multiaddress of the victim node.\\n\\nA linearly scaling nodes attacker can leverage DHT based discovery systems to boost the probability of malicious nodes being returned, which in turn significantly increases the probability of attacker nodes ending up in the peer lists of victim nodes.\\n[Waku v2 discv5](https://vac.dev/wakuv2-apd) will employ countermeasures that mitigate the amplifying effect this attacker type can achieve.\\n\\n### Replay Attack\\n\\nIn the scope we defined above, Waku v2 is resilient against replay attacks.\\nGossipSub nodes, and by extension Waku relay nodes, feature a `seen` cache, and only relay messages they have not seen before.\\nFurther, replay attacks will be punished by [RLN](https://rfc.vac.dev/spec/17/) and [SWAP](https://rfc.vac.dev/spec/18/).\\n\\n### Neighbourhood Surveillance\\n\\nThis attack can be performed by a single node attacker that is connected to all peers of the victim node $v$ with respect to a specific topic mesh.\\nThe attacker also has to be connected to $v$.\\nIn this position, the attacker will receive messages $m_v$ sent by $v$ both on the direct path from $v$, and on indirect paths relayed by peers of $v$.\\nIt will also receive messages $m_x$ that are not sent by $v$. These messages $m_x$ are relayed by both $v$ and the peers of $v$.\\nMessages that are received (significantly) faster from $v$ than from any other of $v$\'s peers are very likely messages that $v$ sent,\\nbecause for these messages the attacker is one hop closer to the source.\\n\\nThe attacker can (periodically) measure latency between itself and $v$, and between itself and the peers of $v$ to get more accurate estimates for the expected timings.\\nAn AS attacker (and if the topology allows, even a local attacker) could also learn the latency between $v$ and its well-behaving peers.\\nAn active AS attacker could also increase the latency between $v$ and its peers to make the timing differences more prominent.\\nThis, however, might lead to $v$ switching to other peers.\\n\\nThis attack cannot (reliably) distinguish messages $m_v$ sent by $v$ from messages $m_y$ relayed by peers of $v$ the attacker is not connected to.\\nStill, there are hop-count variations that might be leveraged.\\nMessages $m_v$ always have a hop-count of 1 on the path from $v$ to the attacker, while all other paths are longer.\\nMessages $m_y$ might have the same hop-count on the path from $v$ as well as on other paths.\\n\\n### Controlled Neighbourhood\\n\\nIf a multi node attacker manages to control all peers of the victim node, it can trivially tell which messages originated from $v$.\\n\\n### Observing Messages\\n\\nIf Waku relay was not protected with Noise, the AS attacker could simply check for messages leaving $v$ which have not been relayed to $v$.\\nThese are the messages sent by $v$.\\nWaku relay protects against this attack by employing secure channels setup using Noise.\\n\\n### Correlation\\n\\nMonitoring all traffic (in an AS or globally), allows the attacker to identify traffic correlated with messages originating from $v$.\\nThis (alone) does not allow an external attacker to learn which message $v$ sent, but it allows identifying the respective traffic propagating through the network.\\nThe more traffic in the network, the lower the success rate of this attack.\\n\\nCombined with just a few nodes controlled by the attacker, the actual message associated with the correlated traffic can eventually be identified.\\n\\n### DoS\\n\\nAn active single node attacker could run a disruption attack by\\n\\n- (1) dropping messages that should be relayed\\n- (2) flooding neighbours with bogus messages\\n\\nWhile (1) has a negative effect on availability, the impact is not significant.\\nA linearly scaling botnet attacker, however, could significantly disrupt the network with such an attack.\\n(2) is thwarted by [RLN](https://rfc.vac.dev/spec/17/).\\nAlso [SWAP](https://rfc.vac.dev/spec/18/) helps mitigating DoS attacks.\\n\\nA local attacker can DoS Waku by dropping all Waku traffic within its controlled network segment.\\nAn AS attacker can DoS Waku within its authority, while a global attacker can DoS the whole network.\\nA countermeasure are censorship resistance techniques like [Pluggable Transports](https://www.pluggabletransports.info/about/).\\n\\n## Summary and Future Work\\n\\nCurrently, Waku v2 relay offers k-anonymity with respect to receiver anonymity.\\nThis also includes k-anonymity towards legitimate members of the same topic.\\n\\nWaku v2 relay offers sender anonymity in the single node attacker model with its [strict no sign policy](https://rfc.vac.dev/spec/11/#signature-policy).\\nCurrently, Waku v2 does not guarantee sender anonymity in the multi node and stronger attacker models.\\nHowever, we are working on modular anonymity-preserving protocols and building blocks as part of our privacy/anonymity roadmap.\\nThe goal is to allow tunable anonymity with respect to trade offs between _strong anonymity_, _low bandwidth_, and _low latency_.\\nAll of these cannot be fully guaranteed as the [the anonymity trilemma](https://freedom.cs.purdue.edu/projects/trilemma.html) states.\\nSome applications have specific requirements, e.g. low latency, which require a compromise on anonymity.\\nAnonymity-preserving mechanisms we plan to investigate and eventually specify as pluggable anonymity protocols for Waku comprise\\n\\n- [Dandelion++](https://arxiv.org/abs/1805.11060) for lightweight anonymity;\\n- [onion routing](https://en.wikipedia.org/wiki/Onion_routing) as a building block adding a low latency anonymization layer;\\n- [a mix network](https://en.wikipedia.org/wiki/Mix_network) for providing strong anonymity (on top of onion routing) even in the strongest attacker model at the cost of higher latency.\\n\\nThese pluggable anonymity-preserving protocols will form a sub-set of the Waku v2 protocol set.\\nAs an intermediate step, we might directly employ Tor for onion-routing, and [Nym](https://nymtech.net/) as a mix-net layer.\\n\\nIn future research log posts, we will cover further Waku v2 protocols and identify anonymity problems that will be added to our roadmap.\\nThese protocols comprise\\n\\n- [13/WAKU2-STORE](https://rfc.vac.dev/spec/13/), which can violate receiver anonymity as it allows filtering by content topic.\\n  A countermeasure is using the content topic exclusively for local filters.\\n- [12/WAKU2-FILTER](https://rfc.vac.dev/spec/12/), which discloses nodes\' interest in topics;\\n- [19/WAKU2-LIGHTPUSH](https://rfc.vac.dev/spec/19/), which also discloses nodes\' interest in topics and links the lightpush client as the sender of a message to the lightpush service node;\\n- [21/WAKU2-FTSTORE](https://rfc.vac.dev/spec/21/), which discloses nodes\' interest in specific time ranges allowing to infer information like online times.\\n\\nWhile these protocols are not necessary for the operation of Waku v2, and can be seen as pluggable features,\\nwe aim to provide alternatives without the cost of lowering the anonymity level.\\n\\n## References\\n\\n- [10/WAKU2](https://rfc.vac.dev/spec/10/)\\n- [11/WAKU2-RELAY](https://rfc.vac.dev/spec/11/)\\n- [libp2p GossipSub](https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/README.md)\\n- [Security](https://en.wikipedia.org/wiki/Information_security)\\n- [Authentication](https://en.wikipedia.org/wiki/Authentication)\\n- [Non-repudiation](https://en.wikipedia.org/wiki/Non-repudiation)\\n- [Noise Protocol Framework](https://noiseprotocol.org/)\\n- [plausible deniability](https://en.wikipedia.org/wiki/Plausible_deniability#Use_in_cryptography)\\n- [Waku v2 message](https://rfc.vac.dev/spec/14/)\\n- [partitioned topics](https://specs.status.im/spec/10#partitioned-topic)\\n- [Sybil attack](https://en.wikipedia.org/wiki/Sybil_attack)\\n- [Dolev-Yao model](https://en.wikipedia.org/wiki/Dolev%E2%80%93Yao_model)\\n- [35/WAKU2-NOISE](https://rfc.vac.dev/spec/35/)\\n- [33/WAKU2-DISCV5](https://vac.dev/wakuv2-apd)\\n- [strict no sign policy](https://github.com/ethereum/consensus-specs/blob/dev/specs/phase0/p2p-interface.md#why-are-we-using-the-strictnosign-signature-policy)\\n- [Waku v2 strict no sign policy](https://rfc.vac.dev/spec/11/#signature-policy)\\n- [17/WAKU-RLN-RELAY](https://rfc.vac.dev/spec/17/)\\n- [anonymity trilemma](https://freedom.cs.purdue.edu/projects/trilemma.html)\\n- [18/WAKU2-SWAP](https://rfc.vac.dev/spec/18/)\\n- [Pluggable Transports](https://www.pluggabletransports.info/about/)\\n- [Nym](https://nymtech.net/)\\n- [Dandelion++](https://arxiv.org/abs/1805.11060)\\n- [13/WAKU2-STORE](https://rfc.vac.dev/spec/13/)\\n- [12/WAKU2-FILTER](https://rfc.vac.dev/spec/12/)\\n- [19/WAKU2-LIGHTPUSH](https://rfc.vac.dev/spec/19/)\\n- [21/WAKU2-FTSTORE](https://rfc.vac.dev/spec/21/)"},{"id":"wakuv2-noise","metadata":{"permalink":"/rlog/wakuv2-noise","source":"@site/rlog/2022-05-17-noise.mdx","title":"Noise handshakes as key-exchange mechanism for Waku","description":"We provide an overview of the Noise Protocol Framework as a tool to design efficient and secure key-exchange mechanisms in Waku2.","date":"2022-05-17T10:00:00.000Z","formattedDate":"May 17, 2022","tags":[],"readingTime":21.115,"hasTruncateMarker":true,"authors":[{"name":"s1fr0","github":"s1fr0","key":"s1fr0"}],"frontMatter":{"layout":"post","name":"Noise handshakes as key-exchange mechanism for Waku","title":"Noise handshakes as key-exchange mechanism for Waku","date":"2022-05-17T10:00:00.000Z","authors":"s1fr0","published":true,"slug":"wakuv2-noise","categories":"research","summary":null,"image":"/img/noise/NM.png","discuss":"https://forum.vac.dev/t/discussion-noise-handshakes-as-key-exchange-mechanism-for-waku/137","_includes":["math"]},"prevItem":{"title":"Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay","permalink":"/rlog/wakuv2-relay-anon"},"nextItem":{"title":"Waku v2 Ambient Peer Discovery","permalink":"/rlog/wakuv2-apd"}},"content":"We provide an overview of the Noise Protocol Framework as a tool to design efficient and secure key-exchange mechanisms in Waku2.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nIn this post we will provide an overview of how [Waku v2](https://rfc.vac.dev/spec/10/) users can adopt [Noise handshakes](http://www.noiseprotocol.org/noise.html) to agree on cryptographic keys used to securely encrypt messages.\\n\\nThis process belongs to the class of _key-exchange_ mechanisms, consisting of all those protocols that, with different levels of complexity and security guarantees, allow two parties to publicly agree on a secret without letting anyone else know what this secret is.\\n\\nBut why do we need key-exchange mechanisms in the first place?\\n\\nWith the advent of [public-key cryptography](https://en.wikipedia.org/wiki/Public-key_cryptography), it become possible to decouple encryption from decryption through use of two distinct cryptographic keys: one _public_, used to encrypt information and that can be made available to anyone, and one _private_ (kept secret), which enables decryption of messages encrypted with its corresponding public key. The same does not happen in the case of [symmetric encryption schemes](https://en.wikipedia.org/wiki/Symmetric-key_algorithm) where, instead, the same key is used for both encryption and decryption operations and hence cannot be publicly revealed as for public keys.\\n\\nIn order to address specific application needs, many different public, symmetric and hybrid cryptographic schemes were designed: [Waku v1](https://rfc.vac.dev/spec/6/) and [Waku v2](https://rfc.vac.dev/spec/10/), which inherits part of their design from the Ethereum messaging protocol [Whisper](https://ethereum.org/en/developers/docs/networking-layer/#whisper), provide [support](https://rfc.vac.dev/spec/26/) to both public-key primitives ([`ECIES`](https://en.wikipedia.org/wiki/Integrated_Encryption_Scheme), [`ECDSA`](https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm)) and symmetric primitives ([`AES-256-GCM`](https://en.wikipedia.org/wiki/Galois/Counter_Mode), [`KECCAK-256`](https://en.wikipedia.org/wiki/SHA-3)), used to sign, hash, encrypt and decrypt exchanged messages.\\n\\nIn principle, when communications employ public-key based encryption schemes (`ECIES`, in the case of Waku), there is no need for a key-agreement among parties: messages can be directly encrypted using the recipient\'s public-key before being sent over the network. However, public-key encryption and decryption primitives are usually very inefficient in processing large amount of data, and this may constitute a bottleneck for many of today\'s applications. Symmetric encryption schemes such as `AES-256-GCM`, on the other hand, are much more efficient, but the encryption/decryption key needs to be shared among users beforehand any encrypted messages is exchanged.\\n\\nTo counter the downsides given by each of these two approaches while taking advantage of their strengths, hybrid constructions were designed. In these, public-key primitives are employed to securely agree on a secret key which, in turn, is used with a symmetric cipher for encrypting messages. In other words, such constructions specify a (public-key based) key-agreement mechanism!\\n\\nWaku, up to [payload version 1](https://rfc.vac.dev/spec/14/#payload-encryption), does not implement nor recommend any protocol for exchanging symmetric ciphers\' keys, leaving such task to the application layer. It is important to note that the kind of key-agreement employed has a direct impact on the security properties that can be granted on later encrypted messages, while security requirements usually depend on the specific application for which encryption is needed in the first place.\\n\\nIn this regard, [Status](https://status.im), which builds on top of Waku, [implements](https://specs.status.im/spec/5) a custom version of the [X3DH](https://signal.org/docs/specifications/x3dh/) key-agreement protocol, in order to allow users to instantiate end-to-end encrypted communication channels. However, although such a solution is optimal when applied to (distributed) E2E encrypted chats, it is not flexible enough to fit or simplify the variety of applications Waku aims to address.\\nHence, proposing and implementing one or few key-agreements which provide certain (presumably _strong_) security guarantees, would inevitably degrade performances of all those applications for which, given their security requirements, more tailored and efficient key-exchange mechanisms can be employed.\\n\\nGuided by different examples, in the following sections we will overview Noise, a protocol framework we are [currently integrating](https://rfc.vac.dev/spec/35/) in Waku, for building secure key-agreements between two parties. One of the great advantage of using Noise is that it is possible to add support to new key-exchanges by just specifying users\' actions from a predefined list, requiring none to minimal modifications to existing implementations. Furthermore, Noise provides a framework to systematically analyze protocols\' security properties and the corresponding attacker threat models. This allows not only to easily design new key-agreements eventually optimized for specific applications we want to address, but also to easily analyze or even [formally verify](https://noiseexplorer.com/) any of such custom protocol!\\n\\nWe believe that with its enormous flexibility and features, Noise represents a perfect candidate for bringing key-exchange mechanisms in Waku.\\n\\n## The Diffie-Hellman Key-exchange\\n\\nThe formalization of modern public-key cryptography started with the pioneering work of Whitefield Diffie and Martin Hellman, who detailed one of the earliest known key-agreement protocols: the famous [Diffie-Hellman Key-Exchange](https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange).\\n\\nDiffie-Hellman (DH) key-exchange is largely used today and represents the main cryptographic building block on which Noise handshakes\' security is based.\\n\\nIn turn, the security of DH is based on a mathematical problem called [discrete logarithm](https://en.wikipedia.org/wiki/Discrete_logarithm) which is believed to be hard when the agreement is practically instantiated using certain [elliptic curves](https://en.wikipedia.org/wiki/Elliptic_curve) $E$ defined over finite fields $\\\\mathbb{F}_p$.\\n\\nInformally, a DH exchange between Alice and Bob proceeds as follows:\\n\\n- Alice picks a secret scalar $s_A\\\\in\\\\mathbb{F}_p$ and computes, using the underlying [curve\'s arithmetic](https://en.wikipedia.org/wiki/Elliptic_curve_point_multiplication), the point $P_A = s_A\\\\cdot P\\\\in E(\\\\mathbb{F}_p)$ for a certain pre-agreed public generator $P$ of the elliptic curve $E(\\\\mathbb{F}_p)$. She then sends $P_A$ to Bob.\\n- Similarly, Bob picks a secret scalar $s_B\\\\in\\\\mathbb{F}_p$, computes $P_B = s_B\\\\cdot P\\\\in E(\\\\mathbb{F}_p)$ and sends $P_B$ to Alice.\\n- By commutativity of scalar multiplication, both Alice and Bob can now compute the point $P_{AB} = s_As_B\\\\cdot P$, using the elliptic curve point received from the other party and their secret scalar.\\n\\nThe assumed hardness of computing discrete logarithms in the elliptic curve, ensures that it is not possible to compute $s_A$ or $s_B$ from $P_A$ and $P_B$, respectively. Another security assumption (named [Computational Diffie-Hellman assumption](https://en.wikipedia.org/wiki/Computational_Diffie%E2%80%93Hellman_assumption)) ensures that it is not possible to compute $P_{AB}$ from $P$, $P_A$ and $P_B$. Hence the point $P_{AB}$ shared by Alice and Bob at the end of the above protocol cannot be efficiently computed by an attacker intercepting $P_A$ and $P_B$, and can then be used to generate a secret to be later employed, for example, as a symmetric encryption key.\\n\\nOn a side note, this protocol shows the interplay between two components typical to public-key based schemes: the scalars $s_A$ and $s_B$ can be seen as _private keys_ associated to the _public keys_ $P_A$ and $P_B$, respectively, which allow Alice and Bob only to compute the shared secret point $P_{AB}$.\\n\\n## Ephemeral and Static Public Keys\\n\\nAlthough we assumed that it is practically impossible for an attacker to compute the randomly picked secret scalar from the corresponding public elliptic curve point, it may happen that such scalar gets compromised or can be guessed due to a faulty employed random number generator. In such cases, an attacker will be able to recover the final shared secret and all encryption keys eventually derived from that, with clear catastrophic consequences for the privacy of exchanged messages.\\n\\nTo mitigate such issues, multiple DH operations can be combined using two different types of exchanged elliptic curve points or, better, _public keys_: _ephemeral keys_, that is random keys used only once in a DH operation, and long-term _static keys_, used mainly for authentication purposes since employed multiple times.\\n\\nJust to provide an example, let us suppose Alice and Bob perform the following custom DH-based key-exchange protocol:\\n\\n- Alice generates an ephemeral key $E_A=e_A\\\\cdot P$ by picking a random scalar $e_A$ and sends $E_A$ to Bob;\\n- Similarly, Bob generates an ephemeral key $E_B=e_B\\\\cdot P$ and sends $E_B$ to Alice;\\n- Alice and Bob computes $E_{AB} = e_Ae_B \\\\cdot P$ and from it derive a secret encryption key $k$.\\n- Bob sends to Alice his static key $S_B = s_B\\\\cdot P$ encrypted with $k$.\\n- Alice encrypts with $k$ her static key $S_A = s_A\\\\cdot P$ and sends it to Bob.\\n- Alice and Bob decrypt the received static keys, compute the secret $S_{AB} = s_As_B \\\\cdot P$ and use it together with $E_{AB}$ to derive a new encryption key $\\\\tilde{k}$ to be later used with a symmetric cipher.\\n\\nIn this protocol, if Alice\'s and/or Bob\'s static keys get compromised, it would not possible to derive the final secret key $\\\\tilde{k}$, since at least one ephemeral key among $E_A$ and $E_B$ has to be compromised too in order to recover the secret $E_{AB}$. Furthermore, since Alice\'s and Bob\'s long-term static keys are encrypted, an attacker intercepting exchanged (encrypted) public keys will not be able to link such communication to Alice or Bob, unless one of the ephemeral key is compromised (and, even in such case, none of the messages encrypted under the key $\\\\tilde{k}$ can be decrypted).\\n\\n## The Noise Protocol Framework\\n\\nIn previous section we gave a small intuition on how multiple DH operations over ephemeral and static users\' public keys can be combined to create different key-exchange protocols.\\n\\nThe [Noise Protocol Framework](http://www.noiseprotocol.org/noise.html), defines various rules for building custom key-exchange protocols while allowing easy analysis of the security properties and threat models provided given the type and order of the DH operations employed.\\n\\nIn Noise terminology, a key-agreement or _Noise protocol_ consists of one or more _Noise handshakes_. During a Noise handshake, Alice and Bob exchange multiple (handshake) messages containing their ephemeral keys and/or static keys. These public keys are then used to perform a handshake-dependent sequence of Diffie-Hellman operations, whose results are all hashed into a shared secret key. Similarly as we have seen above, after a handshake is complete, each party will use the derived secret key to send and receive [authenticated encrypted data](https://en.wikipedia.org/wiki/Authenticated_encryption) by employing a symmetric cipher.\\n\\nDepending on the _handshake pattern_ adopted, different security guarantees can be provided on messages encrypted using a handshake-derived key.\\n\\nThe Noise handshakes we support in Waku all provide the following security properties:\\n\\n- **Confidentiality**: the adversary should not be able to learn what data is being sent between Alice and Bob.\\n- **Strong forward secrecy**: an active adversary cannot decrypt messages nor infer any information on the employed encryption key, even in the case he has access to Alice\'s and Bob\'s long-term private keys (during or after their communication).\\n- **Authenticity**: the adversary should not be able to cause either Alice or Bob to accept messages coming from a party different than their original senders.\\n- **Integrity**: the adversary should not be able to cause Alice or Bob to accept data that has been tampered with.\\n- **Identity-hiding**: once a secure communication channel is established, a passive adversary should not be able to link exchanged encrypted messages to their corresponding sender and recipient by knowing their long-term static keys.\\n\\nWe refer to [Noise specification](http://www.noiseprotocol.org/noise.html) for more formal security definitions and precise threat models relative to Waku [supported Noise Handshake patterns](#Supported-Noise-Handshakes-in-Waku).\\n\\n## Message patterns\\n\\nNoise handshakes involving DH operations over ephemeral and static keys can be succinctly sketched using the following set of _handshake message tokens_: `e`,`s`,`ee`,`se`,`es`,`ss`.\\n\\nTokens employing single letters denote (the type of) users\' public keys: `e` refers to randomly generated ephemeral key(s), while `s` indicates the users\' long-term static key(s).\\n\\nTwo letters tokens, instead, denotes DH operations over the two users\' public keys the token refers to, given that the left token letter refers to the handshake _initiator\'s_ public key, while the right token letter indicates the used _responder\'s_ public key. Thus, if Alice started a handshake with Bob, the `es` token will shortly represent a DH operation among Alice\'s ephemeral key `e` and Bob\'s static key `s`.\\n\\nSince, in order to perform any DH operations users need to share (or pre-share) the corresponding public keys, Noise compactly represents messages\' exchanges using the two direction `->` and `<-`, where the `->` denotes a message (arbitrary and/or DH public key) from the initiator to the responder, while `<-` the opposite.\\n\\nHence a _message pattern_ consisting of a direction and one or multiple tokens such as `<- e, s, es` has to be interpreted one token at a time: in this example, the responder is sending his ephemeral and static key to the initiator and is then executing a DH operation over the initiator\'s ephemeral key `e` (shared in a previously exchanged message pattern) and his static key `s`. On the other hand, such message indicates also that the initiator received the responder\'s ephemeral and static keys `e` and `s`, respectively, and performed a DH operation over his ephemeral key and the responder\'s just received static key `s`. In this way, both parties will be able to derive at the end of each message pattern processed the same shared secret, which is eventually used to update any derived symmetric encryption keys computed so far.\\n\\nIn some cases, DH public keys employed in a handshake are pre-shared before the handshake itself starts. In order to chronologically separate exchanged keys and DH operations performed before and during a handshake, Noise employs the `...` delimiter.\\n\\nFor example, the following message patterns\\n\\n```\\n<- e\\n...\\n-> e, ee\\n```\\n\\nindicates that the initiator knew the responder\'s ephemeral key before he sends his own ephemeral key and executes a DH operation between both parties ephemeral keys (similarly, the responder receives the initiator\'s ephemeral key and does a `ee` DH operation).\\n\\nAt this point it should be clear how such notation is able to compactly represent a large variety of DH based key-agreements. Nevertheless, we can easily define additional tokens and processing rules in order to address specific applications and security requirements, such as the [`psk`](http://www.noiseprotocol.org/noise.html#handshake-tokens) token used to process arbitrary pre-shared key material.\\n\\nAs an example of Noise flexibility, the custom protocol we detailed [above](#Ephemeral-and-Static-Public-Keys) can be shortly represented as _(Alice is on the left)_:\\n\\n```\\n-> e\\n<- e, ee, s\\n-> s, ss\\n```\\n\\nwhere after each DH operation an encryption key is derived (along with the secrets computed by all previously executed DH operations) in order to encrypt/decrypt any subsequent sent/received message.\\n\\nAnother example is given by the possibility to replicate within Noise the well established Signal\'s [X3DH](https://signal.org/docs/specifications/x3dh/) key-agreement protocols, thus making the latter a general framework to design and study security of many practical and widespread DH-based key-exchange protocols.\\n\\n## The Noise State Objects\\n\\nWe mentioned multiple times that parties derive an encryption key each time they perform a DH operation, but how does this work in more details?\\n\\nNoise defines three _state object_: a _Handshake State_, a _Symmetric State_ and a _Cipher State_, each encapsulated into each other and instantiated during the execution of a handshake.\\n\\nThe Handshake State object stores the user\'s and other party\'s received ephemeral and static keys (if any) and embeds a Symmetric State object.\\n\\nThe Symmetric State, instead, stores a handshake hash value `h`, iteratively updated with any message read/received and DH secret computed, and a chaining key `ck`, updated using a key derivation function every time a DH secret is computed. This object further embeds a Cipher State.\\n\\nLastly, the Cipher State stores a symmetric encryption `k` key and a counter `n` used to encrypt and decrypt messages exchanged during the handshake (not only static keys, but also arbitrary payloads). These key and counter are refreshed every time the chaining key is updated.\\n\\nWhile processing each handshake\'s message pattern token, all these objects are updated according to some specific _processing rules_ which employ a combination of public-key primitives, hash and key-derivation functions and symmetric ciphers. It is important to note, however, that at the end of each processed message pattern, the two users will share the same Symmetric and Cipher State embedded in their respective Handshake States.\\n\\nOnce a handshake is complete, users derive two new Cipher States and can then discard the Handshake State object (and, thus, the embedded Symmetric State and Cipher State objects)\\nemployed during the handshake.\\n\\nThese two Cipher states are used to encrypt and decrypt all outbound and inbound after-handshake messages, respectively, and only to these will be granted the confidentiality, authenticity, integrity and identity-hiding properties we detailed above.\\n\\nFor more details on processing rules, we refer to [Noise specifications](http://www.noiseprotocol.org/noise.html).\\n\\n## Supported Noise Handshakes in Waku\\n\\nThe Noise handshakes we provided support to in Waku address four typical scenarios occurring when an encrypted communication channel between Alice and Bob is going to be created:\\n\\n- Alice and Bob know each others\' static key.\\n- Alice knows Bob\'s static key;\\n- Alice and Bob share no key material and they don\'t know each others\' static key.\\n- Alice and Bob share some key material, but they don\'t know each others\' static key.\\n\\nThe possibility to have handshakes based on the reciprocal knowledge parties have of each other, allows designing Noise handshakes that can quickly reach the desired level of security on exchanged encrypted messages while keeping the number of interactions between Alice and Bob minimum.\\n\\nNonetheless, due to the pure _token-based_ nature of handshake processing rules, implementations can easily add support to any custom handshake pattern with minor modifications, in case more specific application use-cases need to be addressed.\\n\\nOn a side note, we already mentioned that identity-hiding properties can be guaranteed against a passive attacker that only reads the communication occurring between Alice and Bob. However, an active attacker who compromised one party\'s static key and actively interferes with the parties\' exchanged messages, may lower the identity-hiding security guarantees provided by some handshake patterns. In our security model we exclude such adversary, but, for completeness, in the following we report a summary of possible de-anonymization attacks that can be performed by such an active attacker.\\n\\nFor more details on supported handshakes and on how these are implemented in Waku, we refer to [35/WAKU2-NOISE](https://rfc.vac.dev/spec/35/) RFC.\\n\\n### The K1K1 Handshake\\n\\nIf Alice and Bob know each others\' static key (e.g., these are public or were already exchanged in a previous handshake) , they MAY execute a `K1K1` handshake. In Noise notation _(Alice is on the left)_ this can be sketched as:\\n\\n```\\n K1K1:\\n    ->  s\\n    <-  s\\n       ...\\n    ->  e\\n    <-  e, ee, es\\n    ->  se\\n```\\n\\nWe note that here only ephemeral keys are exchanged. This handshake is useful in case Alice needs to instantiate a new separate encrypted communication channel with Bob, e.g. opening multiple parallel connections, file transfers, etc.\\n\\n**Security considerations on identity-hiding (active attacker)**: no static key is transmitted, but an active attacker impersonating Alice can check candidates for Bob\'s static key.\\n\\n### The XK1 Handshake\\n\\nHere, Alice knows how to initiate a communication with Bob and she knows his public static key: such discovery can be achieved, for example, through a publicly accessible register of users\' static keys, smart contracts, or through a previous public/private advertisement of Bob\'s static key.\\n\\nA Noise handshake pattern that suits this scenario is `XK1`:\\n\\n```\\n XK1:\\n    <-  s\\n       ...\\n    ->  e\\n    <-  e, ee, es\\n    ->  s, se\\n```\\n\\nWithin this handshake, Alice and Bob reciprocally authenticate their static keys `s` using ephemeral keys `e`. We note that while Bob\'s static key is assumed to be known to Alice (and hence is not transmitted), Alice\'s static key is sent to Bob encrypted with a key derived from both parties ephemeral keys and Bob\'s static key.\\n\\n**Security considerations on identity-hiding (active attacker)**: Alice\'s static key is encrypted with forward secrecy to an authenticated party. An active attacker initiating the handshake can check candidates for Bob\'s static key against recorded/accepted exchanged handshake messages.\\n\\n### The XX and XXpsk0 Handshakes\\n\\nIf Alice is not aware of any static key belonging to Bob (and neither Bob knows anything about Alice), she can execute an `XX` handshake, where each party tran**X**mits to the other its own static key.\\n\\nThe handshake goes as follows:\\n\\n```\\n XX:\\n    ->  e\\n    <-  e, ee, s, es\\n    ->  s, se\\n```\\n\\nWe note that the main difference with `XK1` is that in second step Bob sends to Alice his own static key encrypted with a key obtained from an ephemeral-ephemeral Diffie-Hellman exchange.\\n\\nThis handshake can be slightly changed in case both Alice and Bob pre-shares some secret `psk` which can be used to strengthen their mutual authentication during the handshake execution. One of the resulting protocol, called `XXpsk0`, goes as follow:\\n\\n```\\n XXpsk0:\\n    ->  psk, e\\n    <-  e, ee, s, es\\n    ->  s, se\\n```\\n\\nThe main difference with `XX` is that Alice\'s and Bob\'s static keys, when transmitted, would be encrypted with a key derived from `psk` as well.\\n\\n**Security considerations on identity-hiding (active attacker)**: Alice\'s static key is encrypted with forward secrecy to an authenticated party for both `XX` and `XXpsk0` handshakes. In `XX`, Bob\'s static key is encrypted with forward secrecy but is transmitted to a non-authenticated user which can then be an active attacker. In `XXpsk0`, instead, Bob\'s secret key is protected by forward secrecy to a partially authenticated party (through the pre-shared secret `psk` but not through any static key), provided that `psk` was not previously compromised (in such case identity-hiding properties provided by the `XX` handshake applies).\\n\\n## Session Management and Multi-Device Support\\n\\nWhen two users complete a Noise handshake, an encryption/decryption session - or _Noise session_ - consisting of two Cipher States is instantiated.\\n\\nBy identifying Noise session with a `session-id` derived from the handshake\'s cryptographic material, we can take advantage of the [PubSub/GossipSub](https://github.com/libp2p/specs/tree/master/pubsub) protocols used by Waku for relaying messages in order to manage instantiated Noise sessions.\\n\\nThe core idea is to exchange after-handshake messages (encrypted with a Cipher State specific to the Noise session), over a content topic derived from the (secret) `session-id` the corresponding session refers to.\\n\\nThis allows to decouple the handshaking phase from the actual encrypted communication, thus improving users\' identity-hiding capabilities.\\n\\nFurthermore, by publicly revealing a value derived from `session-id` on the corresponding session content topic, a Noise session can be marked as _stale_, enabling peers to save resources by discarding any eventually [stored](https://rfc.vac.dev/spec/13/) message sent to such content topic.\\n\\nOne relevant aspect in today\'s applications is the possibility for users to employ different devices in their communications. In some cases, this is non-trivial to achieve since, for example, encrypted messages might be required to be synced on different devices which do not necessarily share the necessary key material for decryption and may be temporarily offline.\\n\\nWe address this by requiring each user\'s device to instantiate multiple Noise sessions either with all user\'s other devices which, in turn, all together share a Noise session with the other party, or by directly instantiating a Noise session with all other party\'s devices.\\n\\nWe named these two approaches $N11M$ and $NM$, respectively, which are in turn loosely based on the paper [\u201cMulti-Device for Signal\u201d](https://eprint.iacr.org/2019/1363.pdf) and [Signal\u2019s Sesame Algorithm](https://signal.org/docs/specifications/sesame/).\\n\\n![](//img/noise/N11M.png)\\n\\nInformally, in the $N11M$ session management scheme, once the first Noise session between any of Alice\u2019s and Bob\u2019s device is instantiated, its session information is securely propagated to all other devices using previously instantiated Noise sessions. Hence, all devices are able to send and receive new messages on the content topic associated to such session.\\n\\n![](//img/noise/NM.png)\\n\\nIn the $NM$ session management scheme, instead, all pairs of Alice\'s and Bob\'s devices have a distinct Noise session: a message is then sent from the currently-in-use sender\u2019s device to all recipient\u2019s devices, by properly encrypting and sending it to the content topics of each corresponding Noise session. If sent messages should be available on all sender\u2019s devices as well, we require each pair of sender\u2019s devices to instantiate a Noise session used for syncing purposes.\\n\\nFor more technical details on how Noise sessions are instantiated and managed within these two mechanisms and the different trade-offs provided by the latter, we refer to [37/WAKU2-NOISE-SESSIONS](https://rfc.vac.dev/spec/37/).\\n\\n## Conclusions\\n\\nIn this post we provided an overview of Noise, a protocol framework for designing Diffie-Hellman based key-exchange mechanisms allowing systematic security and threat model analysis.\\n\\nThe flexibility provided by Noise components allows not only to fully replicate with same security guarantees well established key-exchange primitives such as X3DH, currently employed by Status [5/TRANSPORT-SECURITY](https://specs.status.im/spec/5), but enables also optimizations based on the reciprocal knowledge parties have of each other while allowing easier protocols\' security analysis and (formal) verification.\\n\\nFurthermore, different handshakes can be combined and executed one after each other, a particularly useful feature to authenticate multiple static keys employed by different applications but also to ease keys revocation.\\n\\nThe possibility to manage Noise sessions over multiple devices and the fact that handshakes can be concretely instantiated using modern, fast and secure cryptographic primitives such as [ChaChaPoly](https://datatracker.ietf.org/doc/html/rfc7539) and [BLAKE2b](https://datatracker.ietf.org/doc/html/rfc7693), make Noise one of the best candidates for efficiently and securely address the many different needs of applications built on top of Waku requiring key-agreement.\\n\\n## Future steps\\n\\nThe available [implementation](https://github.com/status-im/nwaku/tree/master/waku/v2/waku_noise) of Noise in `nwaku`, although mostly complete, is still in its testing phase. As future steps we would like to:\\n\\n- have an extensively tested and robust Noise implementation;\\n- formalize, implement and test performances of the two proposed $N11M$ and $NM$ session management mechanisms and their suitability for common use-case scenarios;\\n- provide Waku network nodes a native protocol to readily support key-exchanges, strongly-encrypted communication and multi-device session management mechanisms with none-to-little interaction besides applications\' connection requests.\\n\\n## References\\n\\n- [6/WAKU1](https://rfc.vac.dev/spec/6/)\\n- [10/WAKU2](https://rfc.vac.dev/spec/10/)\\n- [13/WAKU2-STORE](https://rfc.vac.dev/spec/13/)\\n- [26/WAKU-PAYLOAD](https://rfc.vac.dev/spec/26/)\\n- [35/WAKU2-NOISE](https://rfc.vac.dev/spec/35/)\\n- [37/WAKU2-NOISE-SESSIONS](https://rfc.vac.dev/spec/37/)\\n- [5/TRANSPORT-SECURITY](https://specs.status.im/spec/5)\\n- [The PubSub/GossipSub Protocols](https://github.com/libp2p/specs/tree/master/pubsub)\\n- [The Noise Protocol Framework](http://www.noiseprotocol.org/noise.html)\\n- [The X3DH Key-agreement Protocol](https://signal.org/docs/specifications/x3dh/)\\n- [\u201cMulti-Device for Signal\u201d](https://eprint.iacr.org/2019/1363.pdf)\\n- [Signal\u2019s Sesame Algorithm](https://signal.org/docs/specifications/sesame/).\\n- [Public-key cryptography](https://en.wikipedia.org/wiki/Public-key_cryptography)\\n- [Elliptic curves](https://en.wikipedia.org/wiki/Elliptic_curve)\\n- [Elliptic Curve point multiplication](https://en.wikipedia.org/wiki/Elliptic_curve_point_multiplication)\\n- [Symmetric key algorithm](https://en.wikipedia.org/wiki/Symmetric-key_algorithm)\\n- [Authenticated encryption](https://en.wikipedia.org/wiki/Authenticated_encryption)\\n- [Diffie-Hellman Key-Exchange](https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange)\\n- [The Discrete Logarithm Problem](https://en.wikipedia.org/wiki/Discrete_logarithm)\\n- [Computational Diffie-Hellman Assumption](https://en.wikipedia.org/wiki/Computational_Diffie%E2%80%93Hellman_assumption)\\n- [The ECIES Encryption Algorithm](https://en.wikipedia.org/wiki/Integrated_Encryption_Scheme)\\n- [The ECDSA Signature Algorithm](https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm)\\n- [The Galois Counter Mode mode of operation](https://en.wikipedia.org/wiki/Galois/Counter_Mode)\\n- [The ChaChaPoly AEAD Cipher](https://datatracker.ietf.org/doc/html/rfc7539)\\n- [The BLAKE2b Hash Function](https://datatracker.ietf.org/doc/html/rfc7693)\\n- [The SHA-3 Hash Function](https://en.wikipedia.org/wiki/SHA-3)"},{"id":"wakuv2-apd","metadata":{"permalink":"/rlog/wakuv2-apd","source":"@site/rlog/2022-05-09-ambient-peer-discovery.mdx","title":"Waku v2 Ambient Peer Discovery","description":"Introducing and discussing ambient peer discovery methods currently used by Waku v2, as well as future plans in this area.","date":"2022-05-09T10:00:00.000Z","formattedDate":"May 9, 2022","tags":[],"readingTime":17.67,"hasTruncateMarker":true,"authors":[{"name":"Daniel","github":"kaiserd","key":"kaiserd"}],"frontMatter":{"layout":"post","name":"Waku v2 Ambient Peer Discovery","title":"Waku v2 Ambient Peer Discovery","date":"2022-05-09T10:00:00.000Z","authors":"kaiserd","published":true,"slug":"wakuv2-apd","categories":"research","image":"/img/waku_v2_discv5_random_walk_estimation.svg","discuss":"https://forum.vac.dev/t/discussion-waku-v2-ambient-peer-discovery/133","_includes":["math"]},"prevItem":{"title":"Noise handshakes as key-exchange mechanism for Waku","permalink":"/rlog/wakuv2-noise"},"nextItem":{"title":"Introducing nwaku","permalink":"/rlog/introducing-nwaku"}},"content":"Introducing and discussing ambient peer discovery methods currently used by Waku v2, as well as future plans in this area.\\n\\n\x3c!--truncate--\x3e\\n\\n[Waku v2](https://rfc.vac.dev/spec/10/) comprises a set of modular protocols for secure, privacy preserving communication.\\nAvoiding centralization, these protocols exchange messages over a P2P network layer.\\nIn order to build a P2P network, participating nodes first have to discover peers within this network.\\nThis is where [_ambient peer discovery_](https://docs.libp2p.io/concepts/publish-subscribe/#discovery) comes into play:\\nit allows nodes to find peers, making it an integral part of any decentralized application.\\n\\nIn this post the term _node_ to refers to _our_ endpoint or the endpoint that takes action,\\nwhile the term _peer_ refers to other endpoints in the P2P network.\\nThese endpoints can be any device connected to the Internet: e.g. servers, PCs, notebooks, mobile devices, or applications like a browser.\\nAs such, nodes and peers are the same. We use these terms for the ease of explanation without loss of generality.\\n\\nIn Waku\'s modular design, ambient peer discovery is an umbrella term for mechanisms that allow nodes to find peers.\\nVarious ambient peer discovery mechanisms are supported, and each is specified as a separate protocol.\\nWhere do these protocols fit into Waku\'s protocol stack?\\nThe P2P layer of Waku v2 builds on [libp2p gossipsub](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/README.md).\\nNodes participating in a gossipsub protocol manage a mesh network that is used for routing messages.\\nThis mesh network is an [unstructured P2P network](https://en.wikipedia.org/wiki/Peer-to-peer#Unstructured_networks)\\noffering high robustness and resilience against attacks.\\nGossipsub implements many improvements overcoming the shortcomings typically associated with unstructured P2P networks, e.g. inefficient flooding based routing.\\nThe gossipsub mesh network is managed in a decentralized way, which requires each node to know other participating peers.\\nWaku v2 may use any combination of its ambient discovery protocols to find appropriate peers.\\n\\nSummarizing, Waku v2 comprises a _peer management layer_ based on libp2p gossipsub,\\nwhich manages the peers of nodes, and an _ambient peer discovery layer_,\\nwhich provides information about peers to the peer management layer.\\n\\nWe focus on ambient peer discovery methods that are in line with our goal of building a fully decentralized, generalized, privacy-preserving and censorship-resistant messaging protocol.\\nSome of these protocols still need adjustments to adhere to our privacy and anonymity requirements. For now, we focus on operational stability and feasibility.\\nHowever, when choosing techniques, we pay attention to selecting mechanisms that can feasibly be tweaked for privacy in future research efforts.\\nBecause of the modular design and the fact that Waku v2 has several discovery methods at its disposal, we could even remove a protocol in case future evaluation deems it not fitting our standards.\\n\\nThis post covers the current state and future considerations of ambient peer discovery for Waku v2,\\nand gives reason for changes and modifications we made or plan to make.\\nThe ambient peer discovery protocols currently supported by Waku v2 are a modified version of Ethereum\'s [Discovery v5](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5.md)\\nand [DNS-based discovery](https://vac.dev/dns-based-discovery).\\nWaku v2 further supports [gossipsub\'s peer exchange protocol](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.1.md#prune-backoff-and-peer-exchange).\\nIn addition, we plan to introduce protocols for general peer exchange and capability discovery, respectively.\\nThe former allows resource restricted nodes to outsource querying for peers to stronger peers,\\nthe latter allows querying peers for their supported capabilities.\\nBesides these new protocols, we are working on integrating capability discovery in our existing ambient peer discovery protocols.\\n\\n## Static Node Lists\\n\\nThe simplest method of learning about peers in a P2P network is via static node lists.\\nThese can be given to nodes as start-up parameters or listed in a config-file.\\nThey can also be provided in a script-parseable format, e.g. in JSON.\\nWhile this method of providing bootstrap nodes is very easy to implement, it requires static peers, which introduce centralized elements.\\nAlso, updating static peer information introduces significant administrative overhead:\\ncode and/or config files have to be updated and released.\\nTypically, static node lists only hold a small number of bootstrap nodes, which may lead to high load on these nodes.\\n\\n## DNS-based Discovery\\n\\nCompared to static node lists,\\n[DNS-based discovery](https://vac.dev/dns-based-discovery) (specified in [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459))\\nprovides a more dynamic way of discovering bootstrap nodes.\\nIt is very efficient, can easily be handled by resource restricted devices and provides very good availability.\\nIn addition to a naive DNS approach, Ethereum\'s DNS-based discovery introduces efficient authentication leveraging [Merkle trees](https://en.wikipedia.org/wiki/Merkle_tree).\\n\\nA further advantage over static node lists is the separation of code/release management and bootstrap node management.\\nHowever, changing and updating the list of bootstrap nodes still requires administrative privileges because DNS records have to be added or updated.\\n\\nWhile this method of discovery still requires centralized elements,\\nnode list management can be delegated to various DNS zones managed by other entities mitigating centralization.\\n\\n## Discovery V5\\n\\nA much more dynamic method of ambient peer discovery is [Discovery v5](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5.md), which is Ethereum\'s peer discovery protocol.\\nIt is based on the [Kademlia](https://en.wikipedia.org/wiki/Kademlia) distributed hashtable (DHT).\\nAn [introduction to discv5 and its history](https://vac.dev/kademlia-to-discv5), and a [discv5 Waku v2 feasibility study](https://vac.dev/feasibility-discv5)\\ncan be found in previous posts on this research log.\\n\\nWe use Discovery v5 as an ambient peer discovery method for Waku v2 because it is decentralized, efficient, actively researched, and has web3 as its main application area.\\nDiscv5 also offers mitigation techniques for various attacks, which we cover later in this post.\\n\\nUsing a DHT (structured P2P network) as a means for ambient peer discovery, while using the gossipsub mesh network (unstructured P2P network) for transmitting actual messages,\\nWaku v2 leverages advantages from both worlds.\\nOne of the main benefits of DHTs is offering a global view over participating nodes.\\nThis, in turn, allows sampling random sets of nodes which is important for equally distributing load.\\nGossipsub, on the other hand, offers great robustness and resilience against attacks.\\nEven if discv5 discovery should not work in advent of a DoS attack, Waku v2 can still operate switching to different discovery methods.\\n\\nDiscovery methods that use separate P2P networks still depend on bootstrapping,\\nwhich Waku v2 does via parameters on start-up or via DNS-based discovery.\\nThis might raise the question of why such discovery methods are beneficial.\\nThe answer lies in the aforementioned global view of DHTs. Without discv5 and similar methods, the bootstrap nodes are used as part of the gossipsub mesh.\\nThis might put heavy load on these nodes and further, might open pathways to inference attacks.\\nDiscv5, on the other hand, uses the bootstrap nodes merely as an entry to the discovery network and can provide random sets of nodes (sampled from a global view)\\nfor bootstrapping or expanding the mesh.\\n\\n### DHT Background\\n\\nDistributed Hash Tables are a class of structured P2P overlay networks.\\nA DHT can be seen as a distributed node set of which each node is responsible for a part of the hash space.\\nIn contrast to unstructured P2P networks, e.g. the mesh network maintained by gossipsub,\\nDHTs have a global view over the node set and the hash space (assuming the participating nodes behave well).\\n\\nDHTs are susceptible to various kinds of attacks, especially [Sybil attacks](https://en.wikipedia.org/wiki/Sybil_attack)\\nand [eclipse attacks](https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/heilman).\\nWhile security aspects have been addressed in various research papers, general practical solutions are not available.\\nHowever, discv5 introduced various practical mitigation techniques.\\n\\n### Random Walk Discovery\\n\\nWhile discv5 is based on the Kademlia DHT, it only uses the _distributed node set_ aspect of DHTs.\\nIt does not map values (items) into the distributed hash space.\\nThis makes sense, because the main purpose of discv5 is discovering other nodes that support discv5, which are expected to be Ethereum nodes.\\nEthereum nodes that want to discover other Ethereum nodes simply query the discv5 network for a random set of peers.\\nIf Waku v2 would do the same, only a small subset of the retrieved nodes would support Waku v2.\\n\\nA first naive solution for Waku v2 discv5 discovery is\\n\\n- retrieve a random node set, which is achieved by querying for a set of randomly chosen node IDs\\n- filter the returned nodes on the query path based on Waku v2 capability via the [Waku v2 ENR](https://rfc.vac.dev/spec/31/)\\n- repeat until enough Waku v2 capable nodes are found\\n\\nThis query process boils down to random walk discovery, which is very resilient against attacks, but also very inefficient if the number of nodes supporting the desired capability is small.\\nWe refer to this as the needle-in-the-haystack problem.\\n\\n### Random Walk Performance Estimation\\n\\nThis subsection provides a rough estimation of the overhead introduced by random walk discovery.\\n\\nGiven the following parameters:\\n\\n- $n$ number of total nodes participating in discv5\\n- $p$ percentage of nodes supporting Waku\\n- $W$ the event of having at least one Waku node in a random sample\\n- $k$ the size of a random sample (default = 16)\\n- $\\\\alpha$ the number of parallel queries started\\n- $b$ bits per hop\\n- $q$ the number of queries\\n\\nA query takes $log_{2^b}n$ hops to retrieve a random sample of nodes.\\n\\n$P(W) = 1 - (1-p/100)^k$ is the probability of having at least one Waku node in the sample.\\n\\n$P(W^q) = 1 - (1-p/100)^{kq}$ is the probability of having at least one Waku node in the union of $q$ samples.\\n\\nExpressing this in terms of $q$, we can write:\\n$$P(W^q) = 1 - (1-p/100)^{kq} \\\\iff  q = log_{(1-p/100)^k}(1-P(W^q))$$\\n\\nFigure 1 shows a log-log plot for $P(W^q) = 90\\\\%$.\\n\\n![Figure 1: log-log plot showing the number of queries necessary to retrieve a Waku v2 node with a probability of 90% in relation to the Waku v2 node concentration in the network.](/img/waku_v2_discv5_random_walk_estimation.svg)\\n\\nAssuming $p=0.1$, we would need\\n\\n$$0.9 = 1 - (1-0.1/100)^{16q} => q \\\\approx 144$$\\n\\nqueries to get a Waku node with 90% probability, which leads to $\\\\approx 144 * 18 = 2592$ overlay hops.\\nChoosing $b=3$ would reduce the number to $\\\\approx 144 * 6 = 864$.\\nEven when choosing $\\\\alpha = 10$ we would have to wait at least 80 RTTs.\\nThis effort is just for retrieving a single Waku node. Ideally, we want at least 3 Waku nodes for bootstrapping a Waku relay.\\n\\n[The discv5 doc](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5-theory.md#ad-placement-and-topic-radius) roughly estimates $p=1%$ to be the threshold for acceptably efficient random walk discovery.\\nThis is in line with our estimation:\\n\\n$$0.9 = 1 - (1-1/100)^{16q} => q \\\\approx 14$$\\n\\nThe number of necessary queries is linearly dependent on the percentage $p$ of Waku nodes.\\nThe number of hops per query is logarithmically dependent on $n$.\\nThus, random walk searching is inefficient for small percentages $p$.\\nStill, random walks are more resilient against attacks.\\n\\nWe can conclude that a Waku node concentration below 1% renders vanilla discv5 unfit for our needs.\\nOur current solution and future plans for solving this issue are covered in the next subsections.\\n\\n### Simple Solution: Separate Discovery Network\\n\\nThe simple solution we currently use for [Waku v2 discv5](https://rfc.vac.dev/spec/33/) is a separate discv5 network.\\nAll (well behaving) nodes in this network support Waku v2, resulting in a very high query efficiency.\\nHowever, this solution reduces resilience because the difficulty of attacking a DHT scales with the number of participating nodes.\\n\\n### Discv5 Topic Discovery\\n\\nWe did not base our solution on the [current version of discv5 topic discovery](https://github.com/ethereum/devp2p/blob/master/discv5/discv5-theory.md#topic-advertisement),\\nbecause, similar to random walk discovery, it suffers from poor performance for relatively rare capabilities/topics.\\n\\nHowever, there is [ongoing research](https://github.com/harnen/service-discovery-paper) in discv5 topic discovery which is close to ideas we explored when pondering efficient and resilient Waku discv5 solutions.\\nWe keep a close eye on this research, give feedback, and make suggestions, as we plan to switch to this version of topic discovery in the future.\\n\\nIn a nutshell, topic discovery will manage separate routing tables for each topic.\\nThese topic specific tables are initialized with nodes from the discv5 routing table.\\nWhile the buckets of the discv5 routing table represent distance intervals from the node\'s `node ID`, the topic table buckets represent distance intervals from `topic ID`s.\\n\\nNodes that want to register a topic try to register that topic at one random peer per bucket.\\nThis leads to registering the topic at peers in closer and closer neighbourhoods around the topic ID, which\\nyields a very efficient and resilient compromise between random walk discovery and DHT discovery.\\nPeers in larger neighbourhoods around the topic ID are less efficient to discover, however more resilient against eclipse attacks and vice versa.\\n\\nFurther, this works well with the overload and DoS protection discv5 employs.\\nDiscv5 limits the amount of nodes registered per topic on a single peer. Further, discv5 enforces a waiting time before nodes can register topics at peers.\\nSo, for popular topics, a node might fail to register the topic in a close neighbourhood.\\nHowever, because the topic is popular (has a high occurrence percentage $p$), it can still be efficiently discovered.\\n\\nIn the future, we also plan to integrate Waku v2 capability discovery, which will not only allow asking for nodes that support Waku v2,\\nbut asking for Waku v2 nodes supporting specific Waku v2 protocols like filter or store.\\nFor the store protocol we envision sub-capabilities reflecting message topics and time frames of messages.\\nWe will also investigate related security implications.\\n\\n### Attacks on DHTs\\n\\nIn this post, we only briefly describe common attacks on DHTs.\\nThese attacks are mainly used for denial of service (DoS),\\nbut can also used as parts of more sophisticated attacks, e.g. deanonymization attacks.\\nA future post on this research log will cover security aspects of ambient peer discovery with a focus on privacy and anonymity.\\n\\n_Sybil Attack_\\n\\nThe power of an attacker in a DHT is proportional to the number of controlled nodes.\\nControlling nodes comes at a high resource cost and/or requires controlling a botnet via a preliminary attack.\\n\\nIn a Sybil attack, an attacker generates lots of virtual node identities.\\nThis allows the attacker to control a large portion of the ID space in a DHT at a relatively low cost.\\nSybil attacks are especially powerful when the attacker can freely choose the IDs of generated nodes,\\nbecause this allows positioning at chosen points in the DHT.\\n\\nBecause Sybil attacks amplify the power of many attacks against DHTs,\\nmaking Sybil attacks as difficult as possible is the basis for resilient DHT operation.\\nThe typical abstract mitigation approach is binding node identities to physical network interfaces.\\nTo some extend, this can be achieved by introducing IP address based limits.\\nFurther, generating node IDs can be bound by proof of work (PoW),\\nwhich, however, comes with a set of shortcomings, e.g. relatively high costs on resource restricted devices.\\n[The discv5 doc](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5-rationale.md#sybil-and-eclipse-attacks)\\ndescribes both Sybil and eclipse attacks, as well as concrete mitigation techniques employed by discv5.\\n\\n_Eclipse Attack_\\n\\nIn an eclipse attack, nodes controlled by the attacker poison the routing tables of other nodes in a way that parts of the DHT become eclipsed, i.e. invisible.\\nWhen a controlled node is asked for the next step in a path,\\nit provides another controlled node as the next step,\\neffectively navigating the querying node around or away from certain areas of the DHT.\\nWhile several mitigation techniques have been researched, there is no definitive protection against eclipse attacks available as of yet.\\nOne mitigation technique is increasing $\\\\alpha$, the number of parallel queries, and following each concurrent path independently for the lookup.\\n\\nThe eclipse attack becomes very powerful in combination with a successful Sybil attack;\\nespecially when the attacker can freely choose the position of the Sybil nodes.\\n\\nThe aforementioned new topic discovery of discv5 provides a good balance between protection against eclipse attacks and query performance.\\n\\n## Peer Exchange Protocol\\n\\nWhile discv5 based ambient peer discovery has many desirable properties, resource restricted nodes and nodes behind restrictive NAT setups cannot run discv5 satisfactory.\\nWith these nodes in mind, we started working on a simple _peer exchange protocol_ based on ideas proposed [here](https://github.com/libp2p/specs/issues/222).\\nThe peer exchange protocol will allow nodes to ask peers for additional peers.\\nSimilar to discv5, the peer exchange protocol will also support capability discovery.\\n\\nThe new peer exchange protocol can be seen as a simple replacement for the [Rendezvous protocol](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/rendezvous/README.md), which Waku v2 does not support.\\nWhile the rendezvous protocol involves nodes registering at rendezvous peers, the peer exchange protocol simply allows nodes to ask any peer for a list of peers (with a certain set of capabilities).\\nRendezvous tends to introduce centralized elements as rendezvous peers have a super-peer role.\\n\\nIn the future, we will investigate resource usage of [Waku v2 discv5](https://rfc.vac.dev/spec/33/) and provide suggestions for minimal resources nodes should have to run discv5 satisfactory.\\n\\n## Further Protocols Related to Discovery\\n\\nWaku v2 comprises further protocols related to ambient peer discovery. We shortly mention them for context, even though they are not strictly ambient peer discovery protocols.\\n\\n### Gossipsub Peer Exchange Protocol\\n\\nGossipsub provides an integrated [peer exchange](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.1.md#prune-backoff-and-peer-exchange) mechanism which is also supported by Waku v2.\\nGossipsub peer exchange works in a _push_ manner. Nodes send peer lists to peers they prune from the active mesh.\\nThis pruning is part of the gossipsub peer management, blurring the boundaries of _peer management_ and _ambient peer discovery_.\\n\\nWe will investigate anonymity implications of this protocol and might disable it in favour of more anonymity-preserving protocols.\\nSending a list of peers discloses information about the sending node.\\nWe consider restricting these peer lists to cached peers that are currently not used in the active gossipsub mesh.\\n\\n### Capability Negotiation\\n\\nSome of the ambient peer discovery methods used by Waku2 will support capability discovery.\\nThis allows to narrow down the set of retrieved peers to peers that support specific capabilities.\\nThis is efficient because it avoids establishing connections to nodes that we are not interested in.\\n\\nHowever, the ambient discovery interface does not require capability discovery, which will lead to nodes having peers with unknown capabilities in their peer lists.\\nWe work on a _capability negotiation protocol_ which allows nodes to ask peers\\n\\n- for their complete list of capabilities, and\\n- whether they support a specific capability\\n\\nWe will investigate security implications, especially when sending full capability lists.\\n\\n## NAT traversal\\n\\nFor [NAT traversal](https://docs.libp2p.io/concepts/nat/), Waku v2 currently supports the port mapping protocols [UPnP](https://en.wikipedia.org/wiki/Universal_Plug_and_Play) and [NAT-PMP](https://datatracker.ietf.org/doc/html/rfc6886) / [PCP](https://datatracker.ietf.org/doc/html/rfc6887).\\n\\nIn the future, we plan to add support for parts of [ICE](https://datatracker.ietf.org/doc/html/rfc8445), e.g. [STUN](https://datatracker.ietf.org/doc/html/rfc7350).\\nWe do not plan to support [TURN](https://www.rfc-editor.org/rfc/rfc5928) because TURN relays would introduce a centralized element.\\nA modified decentralized version of TURN featuring incentivization might be an option in the future;\\nstrong peers could offer a relay service similar to TURN.\\n\\nThere are [plans to integrate more NAT traversal into discv5](https://github.com/ethereum/devp2p/issues/199), in which we might participate.\\nSo far, the only traversal technique supported by discv5 is nodes receiving their external IP address in pong messages.\\n\\nWhile NAT traversal is very important, adding more NAT traversal techniques is not a priority at the moment.\\nNodes behind restrictive symmetric NAT setups cannot be discovered, but they can still discover peers in less restrictive setups.\\nWhile we wish to have as many nodes as possible to be discoverable via ambient peer discovery, two nodes behind a restrictive symmetric NAT can still exchange Waku v2 messages if they discovered a shared peer.\\nThis is one of the nice resilience related properties of flooding based routing algorithms.\\n\\nFor mobile nodes, which suffer from changing IP addresses and double NAT setups, we plan using the peer exchange protocol to ask peers for more peers.\\nBesides saving resources on resource restricted devices, this approach works as long as peers are in less restrictive environments.\\n\\n## Conclusion and Future Prospects\\n\\n_Ambient peer discovery_ is an integral part of decentralized applications. It allows nodes to learn about peers in the network.\\nAs of yet, Waku v2 supports DNS-based discovery and a slightly modified version of discv5.\\nWe are working on further protocols, including a peer exchange protocol that allows resource restricted nodes to ask stronger peers for peer lists.\\nFurther, we are working on adding capability discovery to our ambient discovery protocols, allowing nodes to find peers with desired properties.\\n\\nThese protocols can be combined in a modular way and allow Waku v2 nodes to build a strong and resilient mesh network,\\neven if some discovery methods are not available in a given situation.\\n\\nWe will investigate security properties of these discovery mechanisms with a focus on privacy and anonymity in a future post on this research log.\\nAs an outlook we can already state that DHT approaches typically allow inferring information about the querying node.\\nFurther, sending peer lists allows inferring the position of a node within the mesh, and by extension information about the node.\\nWaku v2 already provides some mitigation, because the mesh for transmitting actual messages, and the peer discovery network are separate.\\nTo mitigate information leakage by transmitting peer lists, we plan to only reply with lists of peers that nodes do not use in their active meshes.\\n\\n---\\n\\n## References\\n\\n- [Waku v2](https://rfc.vac.dev/spec/10/)\\n- [libp2p gossipsub](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/README.md)\\n- [unstructured P2P network](https://en.wikipedia.org/wiki/Peer-to-peer#Unstructured_networks)\\n- [ambient peer discovery](https://docs.libp2p.io/concepts/publish-subscribe/#discovery)\\n- [Discovery v5](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5.md)\\n- [Kademlia](https://en.wikipedia.org/wiki/Kademlia)\\n- [Discv5 history](https://vac.dev/kademlia-to-discv5)\\n- [Discv5 Waku v2 feasibility study](https://vac.dev/feasibility-discv5)\\n- [DNS-based discovery](https://vac.dev/dns-based-discovery)\\n- [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459)\\n- [Merkle trees](https://en.wikipedia.org/wiki/Merkle_tree)\\n- [Sybil attack](https://en.wikipedia.org/wiki/Sybil_attack)\\n- [eclipse attack](https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/heilman)\\n- [Waku v2 ENR](https://rfc.vac.dev/spec/31/)\\n- [Discv5 topic discovery](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5-theory.md#ad-placement-and-topic-radius)\\n- [Discv5 paper](https://github.com/harnen/service-discovery-paper)\\n- [Discv5 vs Sybil and eclipse attacks](https://github.com/ethereum/devp2p/blob/6b0abc3d956a626c28dce1307ee9f546db17b6bd/discv5/discv5-rationale.md#sybil-and-eclipse-attacks)\\n- [peer exchange idea](https://github.com/libp2p/specs/issues/222)\\n- [Rendezvous protocol](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/rendezvous/README.md)\\n- [Waku v2 discv5](https://rfc.vac.dev/spec/33/)\\n- [Gossipsub peer exchange](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.1.md#prune-backoff-and-peer-exchange)\\n- [NAT traversal](https://docs.libp2p.io/concepts/nat/)\\n- [UPnP](https://en.wikipedia.org/wiki/Universal_Plug_and_Play)\\n- [NAT-PMP](https://datatracker.ietf.org/doc/html/rfc6886)\\n- [PCP](https://datatracker.ietf.org/doc/html/rfc6887).\\n- [Discv5 topic efficiency issue](https://github.com/ethereum/devp2p/issues/199)"},{"id":"introducing-nwaku","metadata":{"permalink":"/rlog/introducing-nwaku","source":"@site/rlog/2022-04-12-introducing-nwaku.mdx","title":"Introducing nwaku","description":"Introducing nwaku, a Nim-based Waku v2 client, including a summary of recent developments and preview of current and future focus areas.","date":"2022-04-12T10:00:00.000Z","formattedDate":"April 12, 2022","tags":[],"readingTime":10.765,"hasTruncateMarker":true,"authors":[{"name":"Hanno Cornelius","twitter":"4aelius","github":"jm-clius","key":"hanno"}],"frontMatter":{"layout":"post","name":"Introducing nwaku","title":"Introducing nwaku","date":"2022-04-12T10:00:00.000Z","authors":"hanno","published":true,"slug":"introducing-nwaku","categories":"research","discuss":"https://forum.vac.dev/","toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"Waku v2 Ambient Peer Discovery","permalink":"/rlog/wakuv2-apd"},"nextItem":{"title":"Opinion: Pseudo-ethics in the Surveillance Tech Industry","permalink":"/rlog/ethics-surveillance-tech"}},"content":"Introducing nwaku, a Nim-based Waku v2 client, including a summary of recent developments and preview of current and future focus areas.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nIf you\'ve been following our [research log](https://vac.dev/research-log/),\\nyou\'ll know that many things have happened in the world of Waku v2 since [our last general update](/waku-v2-ethereum-coscup).\\nIn line with our [long term goals](https://vac.dev/#about),\\nwe\'ve introduced new protocols,\\ntweaked our existing protocols\\nand expanded our team.\\nWe\'ve also shown [in a series of practical experiments](/waku-v1-v2-bandwidth-comparison) that Waku v2 does indeed deliver on some of the [theoretical advantages](/waku-v2-plan) it was designed to have over its predecessor, Waku v1.\\nA [sustainability and business workshop](https://forum.vac.dev/t/vac-sustainability-and-business-workshop/116) led to the formulation of a clearer vision for Vac as a team.\\n\\nFrom the beginning, our protocol development has been complemented by various client implementations of these protocols,\\nfirst in [Nim](https://github.com/status-im/nim-waku),\\nbut later also in [JavaScript](https://github.com/status-im/js-waku)\\nand [Go](https://github.com/status-im/go-waku).\\nA follow-up post will clarify the purposes, similarities and differences between these three clients.\\nThe [Nim client](https://github.com/status-im/nim-waku/tree/d2fccb5220144893f994a67f2cc26661247f101f/waku/v2), is our reference implementation,\\ndeveloped by the research team in parallel with the specs\\nand building on a home-grown implementation of [`libp2p`](https://github.com/status-im/nim-libp2p).\\nThe Nim client is suitable to run as [a standalone adaptive node](/waku-update),\\nmanaged by individual operators\\nor as an encapsulated service node in other applications.\\nThis post looks at some recent developments within the Nim client.\\n\\n## 1. _**nim-waku**_ is now known as _**nwaku**_\\n\\nPronounced NWHA-koo.\\nYou may already have seen us refer to \\"`nwaku`\\" on Vac communication channels,\\nbut it is now official:\\nThe `nim-waku` Waku v2 client has been named `nwaku`.\\nWhy? Well, we needed a recognizable name for our client that could easily be referred to in everyday conversations\\nand `nim-waku` just didn\'t roll off the tongue.\\nWe\'ve followed the example of the closely related [`nimbus` project](https://github.com/status-im/nimbus-eth2) to find a punchier name\\nthat explicitly links the client to both the Waku set of protocols and the Nim language.\\n\\n## 2. Improvements in stability and performance\\n\\nThe initial implementation of Waku v2 demonstrated how the suite of protocols can be applied\\nto form a generalized, peer-to-peer messaging network,\\nwhile addressing a wide range of adaptive requirements.\\nThis allowed us to lift several protocol [specifications](https://rfc.vac.dev/) from `raw` to `draft` status,\\nindicating that a reference implementation exists for each.\\nHowever, as internal dogfooding increased and more external applications started using `nwaku`,\\nwe stepped up our focus on the client\'s stability and performance.\\nThis is especially true where we want `nwaku` to run unsupervised in a production environment\\nwithout any degradation in the services it provides.\\n\\nSome of the more significant productionization efforts over the last couple of months included:\\n\\n1. Reworking the `store` implementation to maintain stable memory usage\\n   while storing historical messages\\n   and serving multiple clients querying history simultaneously.\\n   Previously, a `store` node would see gradual service degradation\\n   due to inefficient memory usage when responding to history queries.\\n   Queries that often took longer than 8 mins now complete in under 100 ms.\\n\\n2. Improved peer management.\\n   For example, `filter` nodes will now remove unreachable clients after a number of connection failures,\\n   whereas they would previously keep accumulating dead peers.\\n\\n3. Improved disk usage.\\n   `nwaku` nodes that persist historical messages on disk now manage their own storage size based on the `--store-capacity`.\\n   This can significantly improve node start-up times.\\n\\nMore stability issues may be addressed in future as `nwaku` matures,\\nbut we\'ve noticed a marked improvement in the reliability of running `nwaku` nodes.\\nThese include environments where `nwaku` nodes are expected to run with a long uptime.\\nVac currently operates two long-running fleets of `nwaku` nodes, `wakuv2.prod` and `wakuv2.test`,\\nfor internal dogfooding and\\nto serve as experimental bootstrapping nodes.\\nStatus has also recently deployed similar fleets for production and testing based on `nwaku`.\\nOur goal is to have `nwaku` be stable, performant and flexible enough\\nto be an attractive option for operators to run and maintain their own Waku v2 nodes.\\nSee also the [future work](#future-work) section below for more on our general goal of _`nwaku` for operators_.\\n\\n## 3. Improvements in interoperability\\n\\nWe\'ve implemented several features that improve `nwaku`\'s usability in different environments\\nand its interoperability with other Waku v2 clients.\\nOne major step forward here was adding support for both secure and unsecured WebSocket connections as `libp2p` transports.\\nThis allows direct connectivity with `js-waku`\\nand paves the way for native browser usage.\\nWe\'ve also added support for parsing and resolving DNS-type `multiaddrs`,\\ni.e. multiaddress protocol schemes [`dns`, `dns4`, `dns6` and `dnsaddr`](https://github.com/multiformats/multiaddr/blob/b746a7d014e825221cc3aea6e57a92d78419990f/protocols.csv#L8-L11).\\nA `nwaku` node can now also be [configured with its own IPv4 DNS domain name](https://github.com/status-im/nim-waku/tree/d2fccb5220144893f994a67f2cc26661247f101f/waku/v2#configuring-a-domain-name)\\nallowing dynamic IP address allocation without impacting a node\'s reachability by its peers.\\n\\n## 4. Peer discovery\\n\\n_Peer discovery_ is the method by which nodes become aware of each other\u2019s existence.\\nThe question of peer discovery in a Waku v2 network has been a focus area since the protocol was first conceptualized.\\nSince then several different approaches to discovery have been proposed and investigated.\\nWe\'ve implemented three discovery mechanisms in `nwaku` so far:\\n\\n### DNS-based discovery\\n\\n`nwaku` nodes can retrieve an authenticated, updateable list of peers via DNS to bootstrap connection to a Waku v2 network.\\nOur implementation is based on [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459).\\n\\n### GossipSub peer exchange\\n\\n[GossipSub Peer Exchange (PX)](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.1.md#prune-backoff-and-peer-exchange) is a GossipSub v1.1 mechanism\\nwhereby a pruning peer may provide a pruned peer with a set of alternative peers\\nwhere it can connect to reform its mesh.\\nThis is a very suitable mechanism to gradually discover more peers\\nfrom an initial connection to a small set of bootstrap peers.\\nIt is enabled in a `nwaku` node by default.\\n\\n### Waku Node Discovery Protocol v5\\n\\nThis is a DHT-based discovery mechanism adapted to store and relay _node records_.\\nOur implementation is based on [Ethereum\'s Discovery v5 protocol](https://github.com/ethereum/devp2p/blob/fa6428ada7385c13551873b2ae6ad2457c228eb8/discv5/discv5-theory.md)\\nwith some [minor modifications](https://rfc.vac.dev/spec/33/) to isolate our discovery network from that of Ethereum.\\nThe decision to separate the Waku Discovery v5 network from Ethereum\'s was made on considerations of lookup efficiency.\\nThis comes at a possible tradeoff in network resilience.\\nWe are considering merging with the Ethereum Discovery v5 network in future,\\nor even implement a hybrid solution.\\n[This post](https://forum.vac.dev/t/waku-v2-discv5-roadmap-discussion/121/8) explains the decision and future steps.\\n\\n## 5. Spam protection using RLN\\n\\nAn early addition to our suite of protocols was [an extension of `11/WAKU-RELAY`](https://rfc.vac.dev/spec/32/)\\nthat provided spam protection using [Rate Limiting Nullifiers (RLN)](https://rfc.vac.dev/spec/32/).\\nThe `nwaku` client now contains a working demonstration and integration of RLN relay.\\nCheck out [this tutorial](https://github.com/status-im/nim-waku/blob/ee96705c7fbe4063b780ac43b7edee2f6c4e351b/docs/tutorial/rln-chat2-live-testnet.md) to see the protocol in action using a toy chat application built on `nwaku`.\\nWe\'d love for people to join us in dogfooding RLN spam protection as part of our operator incentive testnet.\\nFeel free to join our [Vac Discord](https://discord.gg/KNj3ctuZvZ) server\\nand head to the `#rln` channel for more information.\\n\\n## Future work\\n\\nAs we continue working towards our goal of a fully decentralized, generalized and censorship-resistant messaging protocol,\\nthese are some of the current and future focus areas for `nwaku`:\\n\\n### Reaching out to operators:\\n\\nWe are starting to push for operators to run and maintain their own Waku v2 nodes,\\npreferably contributing to the default Waku v2 network as described by the default pubsub topic (`/waku/2/default-waku/proto`).\\nAmongst other things, a large fleet of stable operator-run Waku v2 nodes will help secure the network,\\nprovide valuable services to a variety of applications\\nand ensure the future sustainability of both Vac as a research organization and the Waku suite of protocols.\\n\\nWe are targeting `nwaku` as the main option for operator-run nodes.  \\nSpecifically, we aim to provide through `nwaku`:\\n\\n1.  a lightweight and robust Waku v2 client.\\n    This client must be first in line to support innovative and new Waku v2 protocols,\\n    but configurable enough to serve the adaptive needs of various operators.\\n2.  an easy-to-follow guide for operators to configure,\\n    set up and maintain their own nodes\\n3.  a set of operator-focused tools to monitor and maintain a running node\\n\\n### Better conversational security layer guarantees\\n\\nConversational security guarantees in Waku v2 are currently designed around the Status application.\\nDevelopers building their own applications on top of Waku would therefore\\neither have to reimplement a set of tools similar to Status\\nor build their own security solutions on the application layer above Waku.\\nWe are working on [a set of features](https://github.com/vacp2p/research/issues/97) built into Waku\\nthat will provide the general security properties Waku users may desire\\nand do so in a modern and simple way.\\nThis is useful for applications outside of Status that want similar security guarantees.\\nAs a first step, we\'ve already made good progress toward [integrating noise handshakes](https://forum.vac.dev/t/noise-handshakes-as-key-exchange-mechanism-for-waku2/130) as a key exchange mechanism in Waku v2.\\n\\n### Protocol incentivization\\n\\nWe want to design incentivization around our protocols to encourage desired behaviors in the Waku network,\\nrewarding nodes providing costly services\\nand punishing adversarial actions.\\nThis will increase the overall security of the network\\nand encourage operators to run their own Waku nodes.\\nIn turn, the sustainability of Vac as an organization will be better guaranteed.\\nAs such, protocol incentivization was a major focus in our recent [Vac Sustainability and Business Workshop](https://forum.vac.dev/t/vac-sustainability-and-business-workshop/).\\nOur first step here is to finish integrating RLN relay into Waku\\nwith blockchain interaction to manage members,\\npunish spammers\\nand reward spam detectors.\\nAfter this, we want to design monetary incentivization for providers of `store`, `lightpush` and `filter` services.\\nThis may also tie into a reputation mechanism for service nodes based on a network-wide consensus on service quality.\\nA big challenge for protocol incentivization is doing it in a private fashion,\\nso we can keep similar metadata protection guarantees as the Waku base layer.\\nThis ties into our focus on [Zero Knowledge tech](https://forum.vac.dev/t/vac-3-zk/97).\\n\\n### Improved store capacity\\n\\nThe `nwaku` store currently serves as an efficient in-memory store for historical messages,\\ndimensioned by the maximum number of messages the store node is willing to keep.\\nThis makes the `nwaku` store appropriate for keeping history over a short term\\nwithout any time-based guarantees,\\nbut with the advantage of providing fast responses to history queries.\\nSome applications, such as Status, require longer-term historical message storage\\nwith time-based dimensioning\\nto guarantee that messages will be stored for a specified minimum period.\\nBecause of the relatively high cost of memory compared to disk space,\\na higher capacity store, with time guarantees, should operate as a disk-only database of historical messages.\\nThis is an ongoing effort.\\n\\n### Multipurpose discovery\\n\\nIn addition to [the three discovery methods](#4-peer-discovery) already implemented in `nwaku`,\\nwe are working on improving discovery on at least three fronts:\\n\\n#### _Capability discovery:_\\n\\nWaku v2 nodes may be interested in peers with specific capabilities, for example:\\n\\n1. peers within a specific pubsub topic mesh,\\n2. peers with **store** capability,\\n3. **store** peers with x days of history for a specific content topic, etc.\\n\\nCapability discovery entails mechanisms by which such capabilities can be advertised and discovered/negotiated.\\nOne major hurdle to overcome is the increased complexity of finding a node with specific capabilities within the larger network (a needle in a haystack).\\nSee the [original problem statement](https://github.com/vacp2p/rfc/issues/429) for more.\\n\\n#### _Improvements in Discovery v5_\\n\\nOf the implemented discovery methods,\\nDiscovery v5 best addresses our need for a decentralized and scalable discovery mechanism.\\nWith the basic implementation done,\\nthere are some improvements planned for Discovery v5,\\nincluding methods to increase security such as merging with the Ethereum Discovery v5 network,\\nintroducing explicit NAT traversal\\nand utilizing [topic advertisement](https://github.com/ethereum/devp2p/blob/fa6428ada7385c13551873b2ae6ad2457c228eb8/discv5/discv5-theory.md#topic-advertisement).\\nThe [Waku v2 Discovery v5 Roadmap](https://forum.vac.dev/t/waku-v2-discv5-roadmap-discussion/121) contains more details.\\n\\n#### _Generalized peer exchange_\\n\\n`nwaku` already implements [GossipSub peer exchange](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.1.md#prune-backoff-and-peer-exchange).\\nWe now need a general request-response mechanism outside of GossipSub\\nby which a node may learn about other Waku v2 nodes\\nby requesting and receiving a list of peers from a neighbor.\\nThis could, for example, be a suitable way for resource-restricted devices to request a stronger peer\\nto perform a random Discovery v5 lookup on their behalf\\nor simply to be informed of a subset of the peers known to that neighbor.\\nSee [this issue](https://github.com/vacp2p/rfc/issues/495) for more.\\n\\n---\\n\\nThis concludes a general outline of some of the main recent developments in the `nwaku` client\\nand a summary of the current and future focus areas.\\nMuch more is happening behind the scenes, of course,\\nso for more information, or to join the conversation,\\nfeel free to join our [Vac Discord](https://discord.gg/KNj3ctuZvZ) server\\nor to check out the [`nwaku` repo on Github](https://github.com/status-im/nim-waku).\\nYou can also view the changelog for past releases [here](https://github.com/status-im/nim-waku/releases).\\n\\n## References\\n\\n- [17/WAKU-RLN-RELAY](https://rfc.vac.dev/spec/17/)\\n- [32/RLN](https://rfc.vac.dev/spec/32/)\\n- [33/WAKU2-DISCV5](https://rfc.vac.dev/spec/33/)\\n- [Capabilities advertising](https://github.com/vacp2p/rfc/issues/429)\\n- [Configuring a domain name](https://github.com/status-im/nim-waku/tree/d2fccb5220144893f994a67f2cc26661247f101f/waku/v2#configuring-a-domain-name)\\n- [Conversational security](https://github.com/vacp2p/research/issues/97)\\n- [Discovery v5 Topic Advertisement](https://github.com/ethereum/devp2p/blob/fa6428ada7385c13551873b2ae6ad2457c228eb8/discv5/discv5-theory.md#topic-advertisement)\\n- [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459)\\n- [GossipSub Peer Exchange](https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.1.md#prune-backoff-and-peer-exchange)\\n- [go-waku](https://github.com/status-im/go-waku)\\n- [js-waku](https://github.com/status-im/js-waku)\\n- [`multiaddr` formats](https://github.com/multiformats/multiaddr/blob/b746a7d014e825221cc3aea6e57a92d78419990f/protocols.csv#L8-L11)\\n- [nimbus-eth2](https://github.com/status-im/nimbus-eth2)\\n- [nim-libp2p](https://github.com/status-im/nim-libp2p)\\n- [nim-waku](https://github.com/status-im/nim-waku)\\n- [nim-waku releases](https://github.com/status-im/nim-waku/releases)\\n- [Node Discovery Protocol v5 - Theory](https://github.com/ethereum/devp2p/blob/fa6428ada7385c13551873b2ae6ad2457c228eb8/discv5/discv5-theory.md)\\n- [Noise handshakes](https://forum.vac.dev/t/noise-handshakes-as-key-exchange-mechanism-for-waku2/130)\\n- [RLN tutorial](https://github.com/status-im/nim-waku/blob/ee96705c7fbe4063b780ac43b7edee2f6c4e351b/docs/tutorial/rln-chat2-live-testnet.md)\\n- [Vac <3 ZK](https://forum.vac.dev/t/vac-3-zk/97)\\n- [Vac About page](https://vac.dev/#about)\\n- [Vac Research log](https://vac.dev/research-log/)\\n- [Vac RFC site](https://rfc.vac.dev/)\\n- [Vac Sustainability and Business Workshop](https://forum.vac.dev/t/vac-sustainability-and-business-workshop/)\\n- [Waku Update](/waku-update)\\n- [Waku v1 vs Waku v2: Bandwidth Comparison](/waku-v1-v2-bandwidth-comparison)\\n- [Waku v2 Peer Exchange](https://github.com/vacp2p/rfc/issues/495)\\n- [Waku v2 Discovery v5 Roadmap](https://forum.vac.dev/t/waku-v2-discv5-roadmap-discussion/121)\\n- [What\'s the Plan for Waku v2?](/waku-v2-plan)"},{"id":"ethics-surveillance-tech","metadata":{"permalink":"/rlog/ethics-surveillance-tech","source":"@site/rlog/2021-12-03-ethics-surveillance-tech.mdx","title":"Opinion: Pseudo-ethics in the Surveillance Tech Industry","description":"A look at typical ethical shortfalls in the global surveillance tech industry.","date":"2021-12-03T10:00:00.000Z","formattedDate":"December 3, 2021","tags":[],"readingTime":11.715,"hasTruncateMarker":true,"authors":[{"name":"Circe","twitter":"vacp2p","github":"thecirce","key":"circe"}],"frontMatter":{"layout":"post","name":"Opinion: Pseudo-ethics in the Surveillance Tech Industry","title":"Opinion: Pseudo-ethics in the Surveillance Tech Industry","date":"2021-12-03T10:00:00.000Z","authors":"circe","published":true,"slug":"ethics-surveillance-tech","categories":"research","summary":null,"discuss":null},"prevItem":{"title":"Introducing nwaku","permalink":"/rlog/introducing-nwaku"},"nextItem":{"title":"Waku v1 vs Waku v2: Bandwidth Comparison","permalink":"/rlog/waku-v1-v2-bandwidth-comparison"}},"content":"A look at typical ethical shortfalls in the global surveillance tech industry.\\n\\n\x3c!--truncate--\x3e\\n\\n_This is an opinion piece by pseudonymous contributor, circe._\\n\\n## Preface\\n\\nThe Vac team aims to provide a public good in the form of freely available, open source tools and protocols for decentralized communication.\\nAs such, we value our independence and the usefulness of our protocols for a wide range of applications.\\nAt the same time, we realize that all technical development, including ours, has a moral component.\\nAs a diverse team we are guided by a shared devotion to the principles of human rights and liberty.\\nThis explains why we place such a high premium on security, censorship-resistance and privacy -\\na stance we [share with the wider Status Network](https://our.status.im/our-principles/).\\nThe post below takes a different approach from our usual more technical analyses,\\nby starting to peel back the curtain on the ethical shortfalls of the global surveillance tech industry.\\n\\n## Spotlight on an industry\\n\\n[Apple\'s announcement](https://www.apple.com/newsroom/2021/11/apple-sues-nso-group-to-curb-the-abuse-of-state-sponsored-spyware/) of their lawsuit against Israel\'s NSO Group\\nmarks the latest in a series of recent setbacks for the surveillance tech company.\\nIn early November, the [United States blacklisted the firm](https://public-inspection.federalregister.gov/2021-24123.pdf),\\nciting concerns about the use of their spyware by foreign governments targeting civilians such as \\"journalists, businesspeople, activists\\" and more.\\nThe company is already [embroiled in a lawsuit with Whatsapp](https://www.reuters.com/article/us-facebook-cyber-whatsapp-nsogroup-idUSKBN1X82BE)\\nover their exploit of the chat app\'s video calling service to install malware on target devices.\\nNSO Group\'s most infamous product, [Pegasus](https://forbiddenstories.org/case/the-pegasus-project/), operates as a hidden exploit installed on victims\' mobile phones,\\nsometimes without even requiring as much as an unguarded click on a malicious link.\\nIt has the potential to lay bare, and report to its owners, _everything_ within the reach of the infected device.\\nFor most people this amounts to a significant portion of their private lives and thoughts.\\nPegasus can read your private messages (even encrypted), collect your passwords, record calls, track your location and access your device\'s microphone and camera.\\nNo activity or application on an infected phone would be hidden.\\n\\nThe latest controversies are perhaps less because of the novelty of the revelations -\\nthe existence of Pegasus has been known to civil activists [since at least 2016](https://www.bbc.com/news/technology-37192670).\\nRather, the public was reminded again of the potential scope of surveillance tech\\nin the indiscriminate use of Pegasus on private citizens.\\nThis has far-reaching implications for human freedoms worldwide.\\nEarlier this year, a [leaked list of over 50,000 targets](https://www.theguardian.com/world/2021/jul/18/revealed-leak-uncovers-global-abuse-of-cyber-surveillance-weapon-nso-group-pegasus), or possible targets, of Pegasus included\\nthe phone numbers of human rights advocates, independent journalists, lawyers and political activists.\\nThis should have come as no surprise.\\nThe type of autocratically inclined agents, and governments, who would venture to buy and use such invasive cyber-arms often target those they find politically inconvenient.\\nPegasus, and similar technologies, simply extend the reach and capacity of such individuals and governments -\\nno border or distance, no political rank or social advantage, no sanctity of profession or regard for dignity,\\nprovide any indemnity from becoming a victim.\\nYour best hope is to remain uninteresting enough to escape consideration.\\n\\nThe NSO Group has, of course, denied allegations of culpability and questions the authenticity of the list.\\nAt this stage, the latter is almost beside the point:\\nAmnesty International\'s cybersecurity team, Security Lab, _did_ find [forensic evidence of Pegasus](https://www.amnesty.org/en/latest/research/2021/07/forensic-methodology-report-how-to-catch-nso-groups-pegasus/#_ftn1) on the phones of several volunteers whose numbers appeared on the original list,\\nincluding those of journalists and human rights activists.\\n(Security Lab has since opened up their [infection finding tool](https://github.com/mvt-project/mvt) to the public.)\\nFrench intelligence has similarly [inspected and confirmed](https://www.theguardian.com/news/2021/aug/02/pegasus-spyware-found-on-journalists-phones-french-intelligence-confirms) infection of at least three devices belonging to journalists.\\nThe phones of several people who were close to the Saudi-American journalist, Jamal Khashoggi, were [confirmed hacked](https://www.bbc.com/news/world-57891506)\\nboth before and after Khashoggi\'s brutal murder at the Saudi embassy in Istanbul in 2018.\\n[More reports](https://www.theguardian.com/news/2021/sep/21/hungary-journalist-daniel-nemeth-phones-infected-with-nso-pegasus-spyware) of confirmed Pegasus hacks are still published with some regularity.\\nIt is now an open secret that many authoritarian governments have bought Pegasus.\\nIt\'s not difficult to extrapolate from existing reports and such clients\' track records\\nwhat the potential injuries to human freedoms are that they can inflict with access to such a powerful cyberweapon.\\n\\n## A typical response\\n\\n[NSO\'s response](https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments) to the allegations follows a textbook approach\\nof avoiding earnest ethical introspection on the manufacturing, and selling, of cyber-arms.\\nFirstly, shift ethical responsibility to a predetermined process, a list of checkboxes of your own making.\\nThe Group, for example, claims to sell only to \\"vetted governments\\", following a classification process\\nof which they have now [published some procedural details](https://www.nsogroup.com/wp-content/uploads/2021/06/ReportBooklet.pdf) but no tangible criteria.\\nThe next step is to reaffirm continuously, and repetitively, your dedication to the _legal_ combat against crime,\\n[\\"legitimate law enforcement agencies\\"](https://www.nsogroup.com/wp-content/uploads/2021/06/ReportBooklet.pdf) (note the almost tautological phrasing),\\nadherence to international arms trade laws,\\ncompliance clauses in customer contracts, etc.\\nThirdly, having been absolved of any moral suspicions that might exist about product and process,\\nfrom conception to engineering to trade,\\ndistance yourself from the consequences of its use in the world.\\n[\\"NSO does not operate its technology, does not collect, nor possesses, nor has any access to any kind of data of its customers.\\"](https://www.theguardian.com/news/2021/jul/18/response-from-nso-and-governments)\\nIt is interesting that directly after this statement they claim with contradictory confidence that\\ntheir \\"technology was not associated in any way with the heinous murder of Jamal Khashoggi\\".\\nThe unapologetic tone seems hardly appropriate when the same document confirms that the Group had to\\nshut down customers\' systems due to \\"confirmed misuse\\" and have had to do so \\"multiple times\\" in the past.\\nGiven all this, the response manages to evade any serious interrogation of the \\"vetting\\" process itself,\\nwhich forced the company to reject \\"approximately 15% of potential new opportunities for Pegasus\\" in one year.\\nCourageous.\\n\\nWe have heard this all before.\\nThere exists a multi-billion dollar industry of private companies and engineering firms [thriving on proceeds](https://www.economist.com/business/2019/12/12/offering-software-for-snooping-to-governments-is-a-booming-business) from\\nselling surveillance tools and cyber-arms to dubious agencies and foreign governments.\\nIn turn, the most power-hungry and oppressive regimes often _rely_ on such technological innovations -\\nfor which they lack the in-country engineering expertise -\\nto maintain control, suppress uprisings, intimidate opposing journalists, and track their citizens.\\nIt\'s a lucrative business opportunity, and resourceful companies have sprung up everywhere to supply this demand,\\noften in countries where citizens, including employees of the company, would be horrified if they were similarly subject to the oppressions of their own products.\\nWhen, in 2014, Italy\'s _HackingTeam_ were pulsed by the United Nations about their (then alleged) selling of spyware to Sudan,\\nwhich would have been a contravention of the UN\'s weapon export ban,\\nthey simply replied that their product was not controlled as a weapon and therefore not subject to such scrutiny.\\nThey remained within their legal bounds, technically.\\nFurthermore, they similarly shifted ethical responsibility to external standards of legitimacy,\\nclaiming their [\\"software is not sold to governments that are blacklisted by the EU, the US, NATO, and similar international organizations\\"](https://citizenlab.ca/2014/02/mapping-hacking-teams-untraceable-spyware/).\\nWhen the company themselves were [hacked in 2015](https://www.wired.com/2015/07/hacking-team-breach-shows-global-spying-firm-run-amok/),\\nrevelations (confirmations, that is) of widespread misuse by repressive governments were damaging enough to force them to disappear and rebrand as Memento Labs.\\n[Their website](https://www.mem3nt0.com/en/) boasts an impressive list of statutes, regulations, procedures, export controls and legal frameworks,\\nall of which the rebranded hackers proudly comply with.\\nSurely no further ethical scrutiny is necessary?\\n\\n## Ethics != the law\\n\\n### The law is trailing behind\\n\\nSuch recourse to the _legality_ of your action as ethical justification is moot for several reasons.\\nThe first is glaringly obvious -\\nour laws are ill-equipped to address the implications of modern technology.\\nLegal systems are a cumbersome inheritance built over generations.\\nThis is especially true of the statutes and regulations governing international trade, behind which these companies so often hide.\\nOur best legal systems are trailing miles behind the technology for which we seek guidelines.\\nLegislators are still struggling to make sense of technologies like face recognition,\\nthe repercussions of smart devices acting \\"on their own\\" and biases in algorithms.\\nTo claim you are performing ethical due diligence by resorting to an outdated and incomplete system of legal codes is disingenuous.\\n\\n### The law depends on ethics\\n\\nThe second reason is more central to my argument,\\nand an important flaw in these sleight of hand justifications appearing from time to time in the media.\\nEthics can in no way be confused as synonymous with legality or legitimacy.\\nThese are incommensurable concepts.\\nIn an ideal world, of course, the law is meant to track the minimum standards of ethical conduct in a society.\\nLaws are often drafted exactly from some ethical, and practical, impulse to minimize harmful conduct\\nand provide for corrective and punitive measures where transgressions do occur.\\nThe law, however, has a much narrower scope than ethics.\\nIt can be just or unjust.\\nIn fact, it is in need of ethics to constantly reform.\\nEthics and values are born out of collective self-reflection.\\nIt develops in our conversation with ourselves and others about the type of society we strive for.\\nAs such, an ethical worldview summarizes our deepest intuitions about how we should live and measure our impact on the world.\\nFor this reason, ethics is primarily enforced by social and internal pressures, not legal boundaries -\\nour desire to do what _ought_ to be done, however we define that.\\nEthics is therefore a much grander scheme than global legal systems\\nand the diplomatic frameworks that grants legitimacy to governments.\\nThese are but one limited outflow of the human aspiration to form societies in accordance with our ideologies and ethics.\\n\\n### International law is vague and exploitable\\n\\nOf course, the cyber-arms trade has a favorite recourse, _international_ law, which is even more limited.\\nSince such products are seldomly sold to governments and agencies within the country of production,\\nit enables a further distancing from consequences.\\nMany private surveillance companies are based in fairly liberal societies with (seemingly) strict emphases on human rights in their domestic laws.\\nInternational laws are much more complicated - for opportunists a synonym for \\"more grey areas in which to hide\\".\\nCompany conduct can now be governed, and excused, by a system that follows\\nthe whims of autocrats with exploitative intent and vastly different ethical conceptions from the company\'s purported aims.\\nInternational law, and the ways it is most often enforced by way of, say, UN-backed sanctions,\\nhave long been shaped by the compromises of international diplomacy.\\nTo be blunt: these laws are weak and subject to exactly the sort of narrow interests behind which mercenaries have always hidden.\\nThe surveillance tech industry is no exception.\\n\\n## Conclusion\\n\\nMy point is simple:\\nselling cyber-arms with the potential to become vast tools of oppression to governments and bodies with blatant histories of human rights violations,\\nand all but the publicly announced intention to continue operating in this way,\\nis categorically unconscionable.\\nThis seems obvious no matter what ethics system you argue from,\\nprovided it harbors any consideration for human dignity and freedom.\\nIt is a sign of poor moral discourse that such recourses to law and legitimacy are often considered synonymous with ethical justification.\\n\\"_I have acted within the bounds of law_\\", _\\"We supply only to legitimate law enforcement agencies\\"_, etc. are no substitutes.\\nEthical conduct requires an honest evaluation of an action against some conception of \\"the good\\",\\nhowever you define that.\\nToo often the surveillance tech industry precisely sidesteps this question,\\nboth in internal processes and external rationalisations to a concerned public.\\n\\nJohn Locke, he of the life-liberty-and-property, articulated the idea that government exists solely through the consent of the governed.\\nTowards the end of the 17th century, he wrote in his _Second Treatise on Civil Government_,\\n\\"[w]henever legislators endeavor to take away,\\nand destroy the property of the people, or to reduce them to slavery under arbitrary power,\\nthey put themselves in a state of war with the people, who are thereupon absolved from any further obedience\\".\\nThe inference is straightforward and humanist in essence:\\nlegitimacy is not something that is conferred by governments and institutions.\\nRather, they derive their legitimacy from us, their citizens, holding them to standards of ethics and societal ideals.\\nThis legitimacy only remains in tact as long as this mandate is honored and continuously extended by a well-informed public.\\nThis is the principle of informed consent on which all reciprocal ethics is based.\\n\\nThe surveillance tech industry may well have nothing more or less noble in mind than profit-making within legal bounds\\nwhen developing and selling their products.\\nHowever, when such companies are revealed again and again to have supplied tools of gross human rights violations to known human rights violators,\\nthey will do well to remember that ethics always _precedes_ requirements of legality and legitimacy.\\nIt is a fallacy to take normative guidance from the concept of \\"legitimacy\\"\\nif the concept itself depends on such normative guidelines for definition.\\nWithout examining the ethical standards by which institutions, governments, and laws, were created,\\nno value-judgements about their legitimacy can be made.\\nHiding behind legal compliance as substitute for moral justification is not enough.\\nTargets of increasingly invasive governmental snooping are too often chosen precisely to suppress the mechanisms from which the legitimacy of such governments flow -\\nthe consent of ordinary civilians.\\nFree and fair elections, free speech, free media, freedom of thought are all at risk.\\n\\n## References\\n\\n- [Status Principles](https://our.status.im/our-principles/)\\n- [Federal Register: Addition of Certain Entities to the Entity List](https://public-inspection.federalregister.gov/2021-24123.pdf)\\n- [forbiddenstories.org: The Pegasus Project](https://forbiddenstories.org/case/the-pegasus-project/)\\n- [theguardian.com: The Pegasus Project](https://www.theguardian.com/news/series/pegasus-project)\\n- [amnesty.org Forensic Methodology Report: How to catch NSO Group\u2019s Pegasus](https://www.amnesty.org/en/latest/research/2021/07/forensic-methodology-report-how-to-catch-nso-groups-pegasus/#_ftn1)\\n- [Apple sues NSO Group to curb the abuse of state-sponsored spyware](https://www.apple.com/newsroom/2021/11/apple-sues-nso-group-to-curb-the-abuse-of-state-sponsored-spyware/)\\n- [bbc.com: Who are the hackers who cracked the iPhone?](https://www.bbc.com/news/technology-37192670)\\n- [bbc.com: Pegasus: Who are the alleged victims of spyware targeting?](https://www.bbc.com/news/world-57891506)\\n- [citizenlab.ca: Mapping Hacking Team\u2019s \u201cUntraceable\u201d Spyware](https://citizenlab.ca/2014/02/mapping-hacking-teams-untraceable-spyware/)\\n- [economist.com: Offering software for snooping to governments is a booming business](https://www.economist.com/business/2019/12/12/offering-software-for-snooping-to-governments-is-a-booming-business)\\n- [Memento Labs](https://www.mem3nt0.com/en/)\\n- [Mobile Verification Toolkit to identify compromised devices](https://github.com/mvt-project/mvt)\\n- [NSO Group: Transparency and Responsibility Report 2021](https://www.nsogroup.com/wp-content/uploads/2021/06/ReportBooklet.pdf)\\n- [reuters.com: WhatsApp sues Israel\'s NSO for allegedly helping spies hack phones around the world](https://www.reuters.com/article/us-facebook-cyber-whatsapp-nsogroup-idUSKBN1X82BE)\\n- [wired.com: Hacking Team Breach Shows a Global Spying Firm Run Amok](https://www.wired.com/2015/07/hacking-team-breach-shows-global-spying-firm-run-amok/)"},{"id":"waku-v1-v2-bandwidth-comparison","metadata":{"permalink":"/rlog/waku-v1-v2-bandwidth-comparison","source":"@site/rlog/2021-10-25-waku-v1-vs-waku-v2.mdx","title":"Waku v1 vs Waku v2: Bandwidth Comparison","description":"A local comparison of bandwidth profiles showing significantly improved scalability in Waku v2 over Waku v1.","date":"2021-11-03T10:00:00.000Z","formattedDate":"November 3, 2021","tags":[],"readingTime":9.345,"hasTruncateMarker":true,"authors":[{"name":"Hanno Cornelius","twitter":"4aelius","github":"jm-clius","key":"hanno"}],"frontMatter":{"layout":"post","name":"Waku v1 vs Waku v2: Bandwidth Comparison","title":"Waku v1 vs Waku v2: Bandwidth Comparison","date":"2021-11-03T10:00:00.000Z","authors":"hanno","published":true,"slug":"waku-v1-v2-bandwidth-comparison","categories":"research","image":"/img/waku1-vs-waku2/waku1-vs-waku2-overall-network-size.png","discuss":"https://forum.vac.dev/t/discussion-waku-v1-vs-waku-v2-bandwidth-comparison/110"},"prevItem":{"title":"Opinion: Pseudo-ethics in the Surveillance Tech Industry","permalink":"/rlog/ethics-surveillance-tech"},"nextItem":{"title":"[Talk at COSCUP] Vac, Waku v2 and Ethereum Messaging","permalink":"/rlog/waku-v2-ethereum-coscup"}},"content":"A local comparison of bandwidth profiles showing significantly improved scalability in Waku v2 over Waku v1.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nThe [original plan](https://vac.dev/waku-v2-plan) for Waku v2 suggested theoretical improvements in resource usage over Waku v1,\\nmainly as a result of the improved amplification factors provided by GossipSub.\\nIn its turn, [Waku v1 proposed improvements](https://vac.dev/fixing-whisper-with-waku) over its predecessor, Whisper.\\n\\nGiven that Waku v2 is aimed at resource restricted environments,\\nwe are specifically interested in its scalability and resource usage characteristics.\\nHowever, the theoretical performance improvements of Waku v2 over Waku v1,\\nhas never been properly benchmarked and tested.\\n\\nAlthough we\'re working towards a full performance evaluation of Waku v2,\\nthis would require significant planning and resources,\\nif it were to simulate \\"real world\\" conditions faithfully and measure bandwidth and resource usage across different network connections,\\nrobustness against attacks/losses, message latencies, etc.\\n(There already exists a fairly comprehensive [evaluation of GossipSub v1.1](https://research.protocol.ai/publications/gossipsub-v1.1-evaluation-report/vyzovitis2020.pdf),\\non which [`11/WAKU2-RELAY`](https://rfc.vac.dev/spec/11/) is based.)\\n\\nAs a starting point,\\nthis post contains a limited and local comparison of the _bandwidth_ profile (only) between Waku v1 and Waku v2.\\nIt reuses and adapts existing network simulations for [Waku v1](https://github.com/status-im/nim-waku/blob/master/waku/v1/node/quicksim.nim) and [Waku v2](https://github.com/status-im/nim-waku/blob/master/waku/v2/node/quicksim2.nim)\\nand compares bandwidth usage for similar message propagation scenarios.\\n\\n## Theoretical improvements in Waku v2\\n\\nMessages are propagated in Waku v1 using [flood routing](<https://en.wikipedia.org/wiki/Flooding_(computer_networking)>).\\nThis means that every peer will forward every new incoming message to all its connected peers (except the one it received the message from).\\nThis necessarily leads to unnecessary duplication (termed _amplification factor_),\\nwasting bandwidth and resources.\\nWhat\'s more, we expect this effect to worsen the larger the network becomes,\\nas each _connection_ will receive a copy of each message,\\nrather than a single copy per peer.\\n\\nMessage routing in Waku v2 follows the `libp2p` _GossipSub_ protocol,\\nwhich lowers amplification factors by only sending full message contents to a subset of connected peers.\\nAs a Waku v2 network grows, each peer will limit its number of full-message (\\"mesh\\") peerings -\\n`libp2p` suggests a maximum of `12` such connections per peer.\\nThis allows much better scalability than a flood-routed network.\\nFrom time to time, a Waku v2 peer will send metadata about the messages it has seen to other peers (\\"gossip\\" peers).\\n\\nSee [this explainer](https://hackmd.io/@vac/main/%2FYYlZYBCURFyO_ZG1EiteWg#11WAKU2-RELAY-gossipsub) for a more detailed discussion.\\n\\n## Methodology\\n\\nThe results below contain only some scenarios that provide an interesting contrast between Waku v1 and Waku v2.\\nFor example, [star network topologies](https://en.wikipedia.org/wiki/Star_network) do not show a substantial difference between Waku v1 and Waku v2.\\nThis is because each peer relies on a single connection to the central node for every message,\\nwhich barely requires any routing:\\neach connection receives a copy of every message for both Waku v1 and Waku v2.\\nHybrid topologies similarly show only a difference between Waku v1 and Waku v2 for network segments with [mesh-like connections](https://en.wikipedia.org/wiki/Mesh_networking),\\nwhere routing decisions need to be made.\\n\\nFor this reason, the following approach applies to all iterations:\\n\\n1. Simulations are run **locally**.\\n   This limits the size of possible scenarios due to local resource constraints,\\n   but is a way to quickly get an approximate comparison.\\n2. Nodes are treated as a **blackbox** for which we only measure bandwidth,\\n   using an external bandwidth monitoring tool.\\n   In other words, we do not consider differences in the size of the envelope (for v1) or the message (for v2).\\n3. Messages are published at a rate of **50 new messages per second** to each network,\\n   except where explicitly stated otherwise.\\n4. Each message propagated in the network carries **8 bytes** of random payload, which is **encrypted**.\\n   The same symmetric key cryptographic algorithm (with the same keys) are used in both Waku v1 and v2.\\n5. Traffic in each network is **generated from 10 nodes** (randomly-selected) and published in a round-robin fashion to **10 topics** (content topics for Waku v2).\\n   In practice, we found no significant difference in _average_ bandwidth usage when tweaking these two parameters (the number of traffic generating nodes and the number of topics).\\n6. Peers are connected in a decentralized **full mesh topology**,\\n   i.e. each peer is connected to every other peer in the network.\\n   Waku v1 is expected to flood all messages across all existing connections.\\n   Waku v2 gossipsub will GRAFT some of these connections for full-message peerings,\\n   with the rest being gossip-only peerings.\\n7. After running each iteration, we **verify that messages propagated to all peers** (comparing the number of published messages to the metrics logged by each peer).\\n\\nFor Waku v1, nodes are configured as \\"full\\" nodes (i.e. with full bloom filter),\\nwhile Waku v2 nodes are `relay` nodes, all subscribing and publishing to the same PubSub topic.\\n\\n## Network size comparison\\n\\n### Iteration 1: 10 nodes\\n\\nLet\'s start with a small network of 10 nodes only and see how Waku v1 bandwidth usage compares to that of Waku v2.\\nAt this small scale we don\'t expect to see improved bandwidth usage in Waku v2 over Waku v1,\\nsince all connections, for both Waku v1 and Waku v2, will be full-message connections.\\nThe number of connections is low enough that Waku v2 nodes will likely GRAFT all connections to full-message peerings,\\nessentially flooding every message on every connection in a similar fashion to Waku v1.\\nIf our expectations are confirmed, it helps validate our methodology,\\nshowing that it gives more or less equivalent results between Waku v1 and Waku v2 networks.\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-10-nodes.png)\\n\\nSure enough, the figure shows that in this small-scale setup,\\nWaku v1 actually has a lower per-peer bandwidth usage than Waku v2.\\nOne reason for this may be the larger overall proportion of control messages in a gossipsub-routed network such as Waku v2.\\nThese play a larger role when the total network traffic is comparatively low, as in this iteration.\\nAlso note that the average bandwidth remains more or less constant as long as the rate of published messages remains stable.\\n\\n### Iteration 2: 30 nodes\\n\\nNow, let\'s run the same scenario for a larger network of highly-connected nodes, this time consisting of 30 nodes.\\nAt this point, the Waku v2 nodes will start pruning some connections to limit the number of full-message peerings (to a maximum of `12`),\\nwhile the Waku v1 nodes will continue flooding messages to all connected peers.\\nWe therefore expect to see a somewhat improved bandwidth usage in Waku v2 over Waku v1.\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-30-nodes.png)\\n\\nBandwidth usage in Waku v2 has increased only slightly from the smaller network of 10 nodes (hovering between 2000 and 3000 kbps).\\nThis is because there are only a few more full-message peerings than before.\\nCompare this to the much higher increase in bandwidth usage for Waku v1, which now requires more than 4000 kbps on average.\\n\\n### Iteration 3: 50 nodes\\n\\nFor an even larger network of 50 highly connected nodes,\\nthe divergence between Waku v1 and Waku v2 is even larger.\\nThe following figure shows comparative average bandwidth usage for a throughput of 50 messages per second.\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-50-nodes.png)\\n\\nAverage bandwidth usage (for the same message rate) has remained roughly the same for Waku v2 as it was for 30 nodes,\\nindicating that the number of full-message peerings per node has not increased.\\n\\n### Iteration 4: 85 nodes\\n\\nWe already see a clear trend in the bandwidth comparisons above,\\nso let\'s confirm by running the test once more for a network of 85 nodes.\\nDue to local resource constraints, the effective throughput for Waku v1 falls to below 50 messages per second,\\nso the v1 results below have been normalized and are therefore approximate.\\nThe local Waku v2 simulation maintains the message throughput rate without any problems.\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-85-nodes.png)\\n\\n### Iteration 5: 150 nodes\\n\\nFinally, we simulate message propagation in a network of 150 nodes.\\nDue to local resource constraints, we run this simulation at a lower rate -\\n35 messages per second -\\nand for a shorter amount of time.\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-150-nodes.png)\\n\\nNotice how the Waku v1 bandwidth usage is now more than 10 times worse than that of Waku v2.\\nThis is to be expected, as each Waku v1 node will try to flood each new message to 149 other peers,\\nwhile the Waku v2 nodes limit their full-message peerings to no more than 12.\\n\\n### Discussion\\n\\nLet\'s summarize average bandwidth growth against network growth for a constant message propagation rate.\\nSince we are particularly interested in how Waku v1 compares to Waku v2 in terms of bandwidth usage,\\nthe results are normalised to the Waku v2 average bandwidth usage for each network size.\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-overall-network-size.png)\\n\\nExtrapolation is a dangerous game,\\nbut it\'s safe to deduce that the divergence will only grow for even larger network topologies.\\nAlthough control signalling contributes more towards overall bandwidth for Waku v2 networks,\\nthis effect becomes less noticeable for larger networks.\\nFor network segments with more than ~18 densely connected nodes,\\nthe advantage of using Waku v2 above Waku v1 becomes clear.\\n\\n## Network traffic comparison\\n\\nThe analysis above controls the average message rate while network size grows.\\nIn reality, however, active users (and therefore message rates) are likely to grow in conjunction with the network.\\nThis will have an effect on bandwidth for both Waku v1 and Waku v2, though not in equal measure.\\nConsider the impact of an increasing rate of messages in a network of constant size:\\n\\n![](//img/waku1-vs-waku2/waku1-vs-waku2-overall-message-rate.png)\\n\\nThe _rate_ of increase in bandwidth for Waku v2 is slower than that for Waku v1 for a corresponding increase in message propagation rate.\\nIn fact, for a network of 30 densely-connected nodes,\\nif the message propagation rate increases by 1 per second,\\nWaku v1 requires an increased average bandwidth of almost 70kbps at each node.\\nA similar traffic increase in Waku v2 requires on average 40kbps more bandwidth per peer, just over half that of Waku v1.\\n\\n## Conclusions\\n\\n- **Waku v2 scales significantly better than Waku v1 in terms of average bandwidth usage**,\\n  especially for densely connected networks.\\n- E.g. for a network consisting of **150** or more densely connected nodes,\\n  Waku v2 provides more than **10x** better average bandwidth usage rates than Waku v1.\\n- As the network continues to scale, both in absolute terms (number of nodes) and in network traffic (message rates) the disparity between Waku v2 and Waku v1 becomes even larger.\\n\\n## Future work\\n\\nNow that we\'ve confirmed that Waku v2\'s bandwidth improvements over its predecessor matches theory,\\nwe can proceed to a more in-depth characterisation of Waku v2\'s resource usage.\\nSome questions that we want to answer include:\\n\\n- What proportion of Waku v2\'s bandwidth usage is used to propagate _payload_ versus bandwidth spent on _control_ messaging to maintain the mesh?\\n- To what extent is message latency (time until a message is delivered to its destination) affected by network size and message rate?\\n- How _reliable_ is message delivery in Waku v2 for different network sizes and message rates?\\n- What are the resource usage profiles of other Waku v2 protocols (e.g.[`12/WAKU2-FILTER`](https://rfc.vac.dev/spec/12/) and [`19/WAKU2-LIGHTPUSH`](https://rfc.vac.dev/spec/19/))?\\n\\nOur aim is to get ever closer to a \\"real world\\" understanding of Waku v2\'s performance characteristics,\\nidentify and fix vulnerabilities\\nand continually improve the efficiency of our suite of protocols.\\n\\n## References\\n\\n- [Evaluation of GossipSub v1.1](https://research.protocol.ai/publications/gossipsub-v1.1-evaluation-report/vyzovitis2020.pdf)\\n- [Fixing Whisper with Waku](https://vac.dev/fixing-whisper-with-waku)\\n- [GossipSub vs flood routing](https://hackmd.io/@vac/main/%2FYYlZYBCURFyO_ZG1EiteWg#11WAKU2-RELAY-gossipsub)\\n- [Network topologies: star](https://www.techopedia.com/definition/13335/star-topology#:~:text=Star%20topology%20is%20a%20network,known%20as%20a%20star%20network.)\\n- [Network topologies: mesh](https://en.wikipedia.org/wiki/Mesh_networking)\\n- [Waku v2 original plan](https://vac.dev/waku-v2-plan)"},{"id":"waku-v2-ethereum-coscup","metadata":{"permalink":"/rlog/waku-v2-ethereum-coscup","source":"@site/rlog/2021-08-06-coscup-waku-ethereum.mdx","title":"[Talk at COSCUP] Vac, Waku v2 and Ethereum Messaging","description":"Learn more about Waku v2, its origins, goals, protocols, implementation and ongoing research. Understand how it is used and how it can be useful for messaging in Ethereum.","date":"2021-08-06T12:00:00.000Z","formattedDate":"August 6, 2021","tags":[],"readingTime":7.12,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"[Talk at COSCUP] Vac, Waku v2 and Ethereum Messaging","title":"[Talk at COSCUP] Vac, Waku v2 and Ethereum Messaging","date":"2021-08-06T12:00:00.000Z","authors":"oskarth","published":true,"slug":"waku-v2-ethereum-coscup","categories":"research","image":"/img/coscup-waku/talk.png","discuss":"https://forum.vac.dev/t/discussion-talk-at-coscup-vac-waku-v2-and-ethereum-messaging/95"},"prevItem":{"title":"Waku v1 vs Waku v2: Bandwidth Comparison","permalink":"/rlog/waku-v1-v2-bandwidth-comparison"},"nextItem":{"title":"Presenting JS-Waku: Waku v2 in the Browser","permalink":"/rlog/presenting-js-waku"}},"content":"Learn more about Waku v2, its origins, goals, protocols, implementation and ongoing research. Understand how it is used and how it can be useful for messaging in Ethereum.\\n\\n\x3c!--truncate--\x3e\\n\\n_This is the English version of a talk originally given in Chinese at COSCUP in Taipei._\\n\\n[video recording with Chinese and English subtitles.](https://www.youtube.com/watch?v=s0ATpQ4_XFc)\\n\\n---\\n\\n## Introduction\\n\\nHi everyone!\\n\\nToday I\'ll talk to you about Waku v2. What it is, what problems it is solving,\\nand how it can be useful for things such as messaging in Ethereum. First, let me\\nstart with some brief background.\\n\\n## Brief history and background\\n\\nBack when Ethereum got started, there used to be this concept of the \\"holy\\ntrinity\\". You had Ethereum for compute/consensus, Swarm for storage, and Whisper\\nfor messaging. This is partly where the term Web3 comes from.\\n\\nStatus started out as an app with the goal of being a window onto Ethereum and\\na secure messenger. As one of the few, if not the only, apps using Whisper in\\nproduction, not to mention on a mobile phone, we quickly realized there were\\nproblems with the underlying protocols and infrastructure. Protocols such as\\nWhisper weren\'t quite ready for prime time yet when it came to things such as\\nscalability and working in the real world.\\n\\nAs we started addressing some of these challenges, and moved from app\\ndevelopement to focusing on protocols, research and infrastructure, we created\\nVac. Vac is an r&d unit doing protocol research focused on creating modular p2p\\nmessaging protocols for private, secure, censorship resistant communication.\\n\\nI won\'t go into too much detail on the issues with Whisper, if you are\\ninterested in this check out this talk\\n[here](https://www.youtube.com/watch?v=6lLT33tsJjs) or this\\n[article](https://vac.dev/fixing-whisper-with-waku).\\n\\nIn a nutshell, we forked Whisper to address immediate shortcomings and this\\nbecame Waku v1. Waku v2 is complete re-thought implementation from scratch on top\\nof libp2p. This will be the subject of today\'s talk.\\n\\n## Waku v2\\n\\n### Overview\\n\\nWaku v2 is a privacy-preserving peer-to-peer messaging protocol for resource\\nrestricted devices. We can look at Waku v2 as several things:\\n\\n- Set of protocols\\n- Set of implementations\\n- Network of nodes\\n\\nLet\'s first look at what the goals are.\\n\\n### Goals\\n\\nWaku v2 provides a PubSub based messaging protocol with the following\\ncharacteristics:\\n\\n1. **Generalized messaging**. Applications that require a messaging protocol to\\n   communicate human to human, machine to machine, or a mix.\\n2. **Peer-to-peer**. For applications that require a p2p solution.\\n3. **Resource restricted**. For example, running with limited bandwidth, being\\n   mostly-offline, or in a browser.\\n4. **Privacy**. Applications that have privacy requirements, such as pseudonymity,\\n   metadata protection, etc.\\n\\nAnd to provide these properties in a modular fashion, where applications can\\nchoose their desired trade-offs.\\n\\n### Protocols\\n\\nWaku v2 consists of several protocols. Here we highlight a few of the most\\nimportant ones:\\n\\n- 10/WAKU2 - main specification, details how all the pieces fit together\\n- 11/RELAY - thin layer on top of GossipSub for message dissemination\\n- 13/STORE - fetching of historical messages\\n- 14/MESSAGE - message payload\\n\\nThis is the recommended subset for a minimal Waku v2 client.\\n\\nIn addition to this there are many other types of specifications at various\\nstages of maturity, such as: content based filtering, bridge mode to Waku v1,\\nJSON RPC API, zkSNARKS based spam protection with RLN, accounting and\\nsettlements with SWAP, fault-tolerant store nodes, recommendations around topic\\nusage, and more.\\n\\nSee https://rfc.vac.dev/ for a full overview.\\n\\n### Implementations\\n\\nWaku v2 consists of multiple implementations. This allows for client diversity,\\nmakes it easier to strengthen the protocols, and allow people to use Waku v2 in\\ndifferent contexts.\\n\\n- nim-waku - the reference client written in Nim, most full-featured.\\n- js-waku - allow usage of Waku v2 from browsers, focus on interacting with dapps.\\n- go-waku - subset of Waku v2 to ease integration into the Status app.\\n\\n### Testnet Huilong and dogfooding\\n\\nIn order to test the protocol we have setup a testnet across all implementations\\ncalled Huilong. Yes, that\'s the Taipei subway station!\\n\\n![](/img/coscup-waku/huilong.jpg)\\n\\nAmong us core devs we have disabled the main #waku Discord channel used for\\ndevelopment, and people run their own node connected to this toy chat application.\\n\\nFeel free to join and say hi! Instructions can be found here:\\n\\n- [nim-waku chat](https://github.com/status-im/nim-waku/blob/master/docs/tutorial/chat2.md)\\n\\n- [js-waku chat](https://status-im.github.io/js-waku/)\\n\\n- [go-waku chat](https://github.com/status-im/go-waku/tree/master/examples/chat2)\\n\\n### Research\\n\\nWhile Waku v2 is being used today, we are actively researching improvements.\\nSince the design is modular, we can gracefully introduce new capabilities. Some\\nof these research areas are:\\n\\n- Privacy-preserving spam protection using zkSNARKs and RLN\\n- Accounting and settlement of resource usage to incentivize nodes to provide services with SWAP\\n- State synchronization for store protocol to make it easier to run a store node without perfect uptime\\n- Better node discovery\\n- More rigorous privacy analysis\\n- Improving interaction with wallets and dapp\\n\\n## Use cases\\n\\nLet\'s look at where Waku v2 is and can be used.\\n\\n### Prelude: Topics in Waku v2\\n\\nTo give some context, there are two different types of topics in Waku v2. One is\\na PubSub topic, for routing. The other is a content topic, which is used for\\ncontent based filtering. Here\'s an example of the default PubSub topic:\\n\\n`/waku/2/default-waku/proto`\\n\\nThis is recommended as it increases privacy for participants and it is stored by\\ndefault, however this is up to the application.\\n\\nThe second type of topic is a content topic, which is application specific. For\\nexample, here\'s the content topic used in our testnet:\\n\\n`/toychat/2/huilong/proto`\\n\\nFor more on topics, see https://rfc.vac.dev/spec/23/\\n\\n### Status app\\n\\nIn the Status protocol, content topics - topics in Whisper/Waku v1 - are used for several things:\\n\\n- Contact code topic to discover X3DH bundles for perfect forward secrecy\\n  - Partitioned into N (currently 5000) content topics to balance privacy with efficiency\\n- Public chats correspond to hash of the plaintext name\\n- Negotiated topic for 1:1 chat with DHKE derived content topic\\n\\nSee more here https://specs.status.im/spec/10\\n\\nCurrently, Status app is in the process of migrating to and testing Waku v2.\\n\\n### DappConnect: Ethereum messaging\\n\\nIt is easy to think of Waku as being for human messaging, since that\'s how it is\\nprimarily used in the Status app, but the goal is to be useful for generalized\\nmessaging, which includes Machine-To-Machine (M2M) messaging.\\n\\nRecall the concept of the holy trinity with Ethereum/Swarm/Whisper and Web3 that\\nwe mentioned in the beginning. Messaging can be used as a building block for\\ndapps, wallets, and users to communicate with each other. It can be used for\\nthings such as:\\n\\n- Multisig and DAO vote transactions only needing one on-chain operation\\n- Giving dapps ability to send push notifications to users\\n- Giving users ability to directly respond to requests from dapps\\n- Decentralized WalletConnect\\n- Etc\\n\\nBasically anything that requires communication and doesn\'t have to be on-chain.\\n\\n### WalletConnect v2\\n\\nWalletConnect is an open protocol for connecting dapps to wallets with a QR\\ncode. Version 2 is using Waku v2 as a communication channel to do so in a\\ndecentralized and private fashion.\\n\\n![](/img/coscup-waku/walletconnect.png)\\n\\nSee for more: https://docs.walletconnect.org/v/2.0/tech-spec\\n\\nWalletConnect v2 is currently in late alpha using Waku v2.\\n\\n### More examples\\n\\n- Gasless voting and vote aggregation off-chain\\n- Dapp games using Waku as player discovery mechanism\\n- Send encrypted message to someone with an Ethereum key\\n- &lt;Your dapp here&gt;\\n\\nThese are all things that are in progress / proof of concept stage.\\n\\n## Contribute\\n\\nWe\'d love to see contributions of any form!\\n\\n- You can play with it here: [nim-waku chat](https://github.com/status-im/nim-waku/blob/master/docs/tutorial/chat2.md) (/ [js-waku browser chat](https://status-im.github.io/js-waku/))\\n- Use Waku to build a dapp: [js-waku docs](https://status-im.github.io/js-waku/docs/)\\n- Contribute to code: [js-waku](https://github.com/status-im/js-waku) / [nim-waku](https://github.com/status-im/nim-waku)\\n- Contribute to specs: [vacp2p/rfc](https://github.com/vacp2p/rfc)\\n- We are hiring: Wallet & Dapp Integration Developer, Distributed Systems Engineer, Protocol Engineer, Protocol Researcher - all [job listings](https://status.im/our_team/jobs.html)\\n- Join our new [Discord](https://discord.gg/bJCTqS5H)\\n\\n## Conclusion\\n\\nIn this talk we\'ve gone over the original vision for Web3 and how Waku came to\\nbe. We\'ve also looked at what Waku v2 aims to do. We looked at its protocols,\\nimplementations, the current testnet as well as briefly on some ongoing\\nresearch for Vac.\\n\\nWe\'ve also looked at some specific use cases for Waku. First we looked at how\\nStatus uses it with different topics. Then we looked at how it can be useful for\\nmessaging in Ethereum, including for things like WalletConnect.\\n\\nI hope this talk gives you a better idea of what Waku is, why it exists, and\\nthat it inspires you to contribute, either to Waku itself or by using it in your\\nown project!"},{"id":"presenting-js-waku","metadata":{"permalink":"/rlog/presenting-js-waku","source":"@site/rlog/2021-06-04-presenting-js-waku.mdx","title":"Presenting JS-Waku: Waku v2 in the Browser","description":"JS-Waku is bringing Waku v2 to the browser. Learn what we achieved so far and what is next in our pipeline!","date":"2021-06-04T12:00:00.000Z","formattedDate":"June 4, 2021","tags":[],"readingTime":6.84,"hasTruncateMarker":true,"authors":[{"name":"Franck","twitter":"fryorcraken","github":"fryorcraken","key":"franck"}],"frontMatter":{"layout":"post","name":"Presenting JS-Waku: Waku v2 in the Browser","title":"Presenting JS-Waku: Waku v2 in the Browser","date":"2021-06-04T12:00:00.000Z","authors":"franck","published":true,"slug":"presenting-js-waku","categories":"platform","image":"/img/js-waku-gist.png","discuss":"https://forum.vac.dev/t/discussion-presenting-js-waku-waku-v2-in-the-browser/81"},"prevItem":{"title":"[Talk at COSCUP] Vac, Waku v2 and Ethereum Messaging","permalink":"/rlog/waku-v2-ethereum-coscup"},"nextItem":{"title":"Privacy-preserving p2p economic spam protection in Waku v2","permalink":"/rlog/rln-relay"}},"content":"JS-Waku is bringing Waku v2 to the browser. Learn what we achieved so far and what is next in our pipeline!\\n\\n\x3c!--truncate--\x3e\\n\\nFor the past 3 months, we have been working on bringing Waku v2 to the browser.\\nOur aim is to empower dApps with Waku v2, and it led to the creation of a new library.\\nWe believe now is good time to introduce it!\\n\\n## Waku v2\\n\\nFirst, let\'s review what Waku v2 is and what problem it is trying to solve.\\n\\nWaku v2 comes from a need to have a more scalable, better optimised solution for the Status app to achieve decentralised\\ncommunications on resource restricted devices (i.e., mobile phones).\\n\\nThe Status chat feature was initially built over Whisper.\\nHowever, Whisper has a number of caveats which makes it inefficient for mobile phones.\\nFor example, with Whisper, all devices are receiving all messages which is not ideal for limited data plans.\\n\\nTo remediate this, a Waku mode (then Waku v1), based on devp2p, was introduced.\\nTo further enable web and restricted resource environments, Waku v2 was created based on libp2p.\\nThe migration of the Status chat feature to Waku v2 is currently in progress.\\n\\nWe see the need of such solution in the broader Ethereum ecosystem, beyond Status.\\nThis is why we are building Waku v2 as a decentralised communication platform for all to use and build on.\\nIf you want to read more about Waku v2 and what it aims to achieve,\\ncheckout [What\'s the Plan for Waku v2?](/waku-v2-plan).\\n\\nSince last year, we have been busy defining and implementing Waku v2 protocols in [nim-waku](https://github.com/status-im/nim-waku),\\nfrom which you can build [wakunode2](https://github.com/status-im/nim-waku#wakunode).\\nWakunode2 is an adaptive and modular Waku v2 node,\\nit allows users to run their own node and use the Waku v2 protocols they need.\\nThe nim-waku project doubles as a library, that can be used to add Waku v2 support to native applications.\\n\\n## Waku v2 in the browser\\n\\nWe believe that dApps and wallets can benefit from the Waku network in several ways.\\nFor some dApps, it makes sense to enable peer-to-peer communications.\\nFor others, machine-to-machine communications would be a great asset.\\nFor example, in the case of a DAO,\\nWaku could be used for gas-less voting.\\nEnabling the DAO to notify their users of a new vote,\\nand users to vote without interacting with the blockchain and spending gas.\\n\\n[Murmur](https://github.com/status-im/murmur) was the first attempt to bring Whisper to the browser,\\nacting as a bridge between devp2p and libp2p.\\nOnce Waku v2 was started and there was a native implementation on top of libp2p,\\na [chat POC](https://github.com/vacp2p/waku-web-chat) was created to demonstrate the potential of Waku v2\\nin web environment.\\nIt showed how using js-libp2p with few modifications enabled access to the Waku v2 network.\\nThere was still some unresolved challenges.\\nFor example, nim-waku only support TCP connections which are not supported by browser applications.\\nHence, to connect to other node, the POC was connecting to a NodeJS proxy application using websockets,\\nwhich in turn could connect to wakunode2 via TCP.\\n\\nHowever, to enable dApp and Wallet developers to easily integrate Waku in their product,\\nwe need to give them a library that is easy to use and works out of the box:\\nintroducing [JS-Waku](https://github.com/status-im/js-waku).\\n\\nJS-Waku is a JavaScript library that allows your dApp, wallet or other web app to interact with the Waku v2 network.\\nIt is available right now on [npm](https://www.npmjs.com/package/js-waku):\\n\\n`npm install js-waku`.\\n\\nAs it is written in TypeScript, types are included in the npm package to allow easy integration with TypeScript, ClojureScript and other typed languages that compile to JavaScript.\\n\\nKey Waku v2 protocols are already available:\\n[message](https://rfc.vac.dev/spec/14/), [store](https://rfc.vac.dev/spec/13/), [relay](https://rfc.vac.dev/spec/11/) and [light push](https://rfc.vac.dev/spec/19/),\\nenabling your dApp to:\\n\\n- Send and receive near-instant messages on the Waku network (relay),\\n- Query nodes for messages that may have been missed, e.g. due to poor cellular network (store),\\n- Send messages with confirmations (light push).\\n\\nJS-Waku needs to operate in the same context from which Waku v2 was born:\\na restricted environment were connectivity or uptime are not guaranteed;\\nJS-Waku brings Waku v2 to the browser.\\n\\n## Achievements so far\\n\\nWe focused the past month on developing a [ReactJS Chat App](https://status-im.github.io/js-waku/).\\nThe aim was to create enough building blocks in JS-Waku to enable this showcase web app that\\nwe now [use for dogfooding](https://github.com/status-im/nim-waku/issues/399) purposes.\\n\\nMost of the effort was on getting familiar with the [js-libp2p](https://github.com/libp2p/js-libp2p) library\\nthat we heavily rely on.\\nJS-Waku is the second implementation of Waku v2 protocol,\\nso a lot of effort on interoperability was needed.\\nFor example, to ensure compatibility with the nim-waku reference implementation,\\nwe run our [tests against wakunode2](https://github.com/status-im/js-waku/blob/90c90dea11dfd1277f530cf5d683fb92992fe141/src/lib/waku_relay/index.spec.ts#L137) as part of the CI.\\n\\nThis interoperability effort helped solidify the current Waku v2 specifications:\\nBy clarifying the usage of topics\\n([#327](https://github.com/vacp2p/rfc/issues/327), [#383](https://github.com/vacp2p/rfc/pull/383)),\\nfix discrepancies between specs and nim-waku\\n([#418](https://github.com/status-im/nim-waku/issues/418), [#419](https://github.com/status-im/nim-waku/issues/419))\\nand fix small nim-waku & nim-libp2p bugs\\n([#411](https://github.com/status-im/nim-waku/issues/411), [#439](https://github.com/status-im/nim-waku/issues/439)).\\n\\nTo fully access the waku network, JS-Waku needs to enable web apps to connect to nim-waku nodes.\\nA standard way to do so is using secure websockets as it is not possible to connect directly to a TCP port from the browser.\\nUnfortunately websocket support is not yet available in [nim-libp2p](https://github.com/status-im/nim-libp2p/issues/407) so\\nwe ended up deploying [websockify](https://github.com/novnc/websockify) alongside wakunode2 instances.\\n\\nAs we built the [web chat app](https://github.com/status-im/js-waku/tree/main/examples/web-chat),\\nwe were able to fine tune the API to provide a simple and succinct interface.\\nYou can start a node, connect to other nodes and send a message in less than ten lines of code:\\n\\n```javascript\\nimport { Waku } from \'js-waku\'\\n\\nconst waku = await Waku.create({})\\n\\nconst nodes = await getStatusFleetNodes()\\nawait Promise.all(nodes.map((addr) => waku.dial(addr)))\\n\\nconst msg = WakuMessage.fromUtf8String(\\n  \'Here is a message!\',\\n  \'/my-cool-app/1/my-use-case/proto\',\\n)\\nawait waku.relay.send(msg)\\n```\\n\\nWe have also put a bounty at [0xHack](https://0xhack.dev/) for using JS-Waku\\nand running a [workshop](https://www.youtube.com/watch?v=l77j0VX75QE).\\nWe were thrilled to have a couple of hackers create new software using our libraries.\\nOne of the projects aimed to create a decentralised, end-to-end encrypted messenger app,\\nsimilar to what the [ETH-DM](https://rfc.vac.dev/spec/20/) protocol aims to achieve.\\nAnother project was a decentralised Twitter platform.\\nSuch projects allow us to prioritize the work on JS-Waku and understand how DevEx can be improved.\\n\\nAs more developers use JS-Waku, we will evolve the API to allow for more custom and fine-tune usage of the network\\nwhile preserving this out of the box experience.\\n\\n## What\'s next?\\n\\nNext, we are directing our attention towards [Developer Experience](https://github.com/status-im/js-waku/issues/68).\\nWe already have [documentation](https://www.npmjs.com/package/js-waku) available but we want to provide more:\\n[Tutorials](https://github.com/status-im/js-waku/issues/56), various examples\\nand showing how [JS-Waku can be used with Web3](https://github.com/status-im/js-waku/issues/72).\\n\\nBy prioritizing DevEx we aim to enable JS-Waku integration in dApps and wallets.\\nWe think JS-Waku builds a strong case for machine-to-machine (M2M) communications.\\nThe first use cases we are looking into are dApp notifications:\\nEnabling dApp to notify their user directly in their wallets!\\nLeveraging Waku as a decentralised infrastructure and standard so that users do not have to open their dApp to be notified\\nof events such as DAO voting.\\n\\nWe already have some POC in the pipeline to enable voting and polling on the Waku network,\\nallowing users to save gas by **not** broadcasting each individual vote on the blockchain.\\n\\nTo facilitate said applications, we are looking at improving integration with Web3 providers by providing examples\\nof signing, validating, encrypting and decrypting messages using Web3.\\nWaku is privacy conscious, so we will also provide signature and encryption examples decoupled from users\' Ethereum identity.\\n\\nAs you can read, we have grand plans for JS-Waku and Waku v2.\\nThere is a lot to do, and we would love some help so feel free to\\ncheck out the new role in our team:\\n[js-waku: Wallet & Dapp Integration Developer](https://status.im/our_team/jobs.html?gh_jid=3157894).\\nWe also have a number of [positions](https://status.im/our_team/jobs.html) open to work on Waku protocol and nim-waku.\\n\\nIf you are as excited as us by JS-Waku, why not build a dApp with it?\\nYou can find documentation on the [npmjs page](https://www.npmjs.com/package/js-waku).\\n\\nWhether you are a developer, you can come chat with us using [WakuJS Web Chat](https://status-im.github.io/js-waku/)\\nor [chat2](https://github.com/status-im/nim-waku/blob/master/docs/tutorial/chat2.md).\\nYou can get support in #dappconnect-support on [Vac Discord](https://discord.gg/j5pGbn7MHZ) or [Telegram](https://t.me/dappconnectsupport).\\nIf you have any ideas on how Waku could enable a specific dapp or use case, do share, we are always keen to hear it."},{"id":"rln-relay","metadata":{"permalink":"/rlog/rln-relay","source":"@site/rlog/2021-03-03-rln-relay.mdx","title":"Privacy-preserving p2p economic spam protection in Waku v2","description":"This post is going to give you an overview of how spam protection can be achieved in Waku Relay through rate-limiting nullifiers. We will cover a summary of spam-protection methods in centralized and p2p systems, and the solution overview and details of the economic spam-protection method. The open issues and future steps are discussed in the end.","date":"2021-03-05T12:00:00.000Z","formattedDate":"March 5, 2021","tags":[],"readingTime":20.775,"hasTruncateMarker":true,"authors":[{"name":"Sanaz","twitter":"sanaz2016","github":"staheri14","key":"sanaz"}],"frontMatter":{"layout":"post","name":"Privacy-preserving p2p economic spam protection in Waku v2","title":"Privacy-preserving p2p economic spam protection in Waku v2","date":"2021-03-05T12:00:00.000Z","authors":"sanaz","published":true,"slug":"rln-relay","categories":"reserach","image":"/img/rain.png","discuss":"https://forum.vac.dev/t/privacy-preserving-p2p-economic-spam-protection-in-waku-v2-with-rate-limiting-nullfiers/66","toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"Presenting JS-Waku: Waku v2 in the Browser","permalink":"/rlog/presenting-js-waku"},"nextItem":{"title":"[Talk] Vac, Waku v2 and Ethereum Messaging","permalink":"/rlog/waku-v2-ethereum-messaging"}},"content":"This post is going to give you an overview of how spam protection can be achieved in Waku Relay through rate-limiting nullifiers. We will cover a summary of spam-protection methods in centralized and p2p systems, and the solution overview and details of the economic spam-protection method. The open issues and future steps are discussed in the end.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nThis post is going to give you an overview of how spam protection can be achieved in Waku Relay protocol[^2] through Rate-Limiting Nullifiers[^3] [^4] or RLN for short.\\n\\nLet me give a little background about Waku(v2)[^1]. Waku is a privacy-preserving peer-to-peer (p2p) messaging protocol for resource-restricted devices. Being p2p means that Waku relies on **No** central server. Instead, peers collaboratively deliver messages in the network. Waku uses GossipSub[^16] as the underlying routing protocol (as of the writeup of this post). At a high level, GossipSub is based on publisher-subscriber architecture. That is, _peers, congregate around topics they are interested in and can send messages to topics. Each message gets delivered to all peers subscribed to the topic_. In GossipSub, a peer has a constant number of direct connections/neighbors. In order to publish a message, the author forwards its message to a subset of neighbors. The neighbors proceed similarly till the message gets propagated in the network of the subscribed peers. The message publishing and routing procedures are part of the Waku Relay[^17] protocol.\\n![Figure 1: An overview of privacy-preserving p2p economic spam protection in Waku v2 RLN-Relay protocol.](/img/rln-relay/rln-relay-overview.png)\\n\\n## What do we mean by spamming?\\n\\nIn centralized messaging systems, a spammer usually indicates an entity that uses the messaging system to send an unsolicited message (spam) to large numbers of recipients. However, in Waku with a p2p architecture, spam messages not only affect the recipients but also all the other peers involved in the routing process as they have to spend their computational power/bandwidth/storage capacity on processing spam messages. As such, we define a spammer as an entity that uses the messaging system to publish a large number of messages in a short amount of time. The messages issued in this way are called spam. In this definition, we disregard the intention of the spammer as well as the content of the message and the number of recipients.\\n\\n## Possible Solutions\\n\\nHas the spamming issue been addressed before? Of course yes! Here is an overview of the spam protection techniques with their trade-offs and use-cases. In this overview, we distinguish between protection techniques that are targeted for centralized messaging systems and those for p2p architectures.\\n\\n### Centralized Messaging Systems\\n\\nIn traditional centralized messaging systems, spam usually signifies unsolicited messages sent in bulk or messages with malicious content like malware. Protection mechanisms include\\n\\n- authentication through some piece of personally identifiable information e.g., phone number\\n- checksum-based filtering to protect against messages sent in bulk\\n- challenge-response systems\\n- content filtering on the server or via a proxy application\\n\\nThese methods exploit the fact that the messaging system is centralized and a global view of the users\' activities is available based on which spamming patterns can be extracted and defeated accordingly. Moreover, users are associated with an identifier e.g., a username which enables the server to profile each user e.g., to detect suspicious behavior like spamming. Such profiling possibility is against the user\'s anonymity and privacy.\\n\\nAmong the techniques enumerated above, authentication through phone numbers is a some-what economic-incentive measure as providing multiple valid phone numbers will be expensive for the attacker. Notice that while using an expensive authentication method can reduce the number of accounts owned by a single spammer, cannot address the spam issue entirely. This is because the spammer can still send bulk messages through one single account. For this approach to be effective, a centralized mediator is essential. That is why such a solution would not fit the p2p environments where no centralized control exists.\\n\\n### P2P Systems\\n\\nWhat about spam prevention in p2p messaging platforms? There are two techniques, namely _Proof of Work_[^8] deployed by Whisper[^9] and _Peer scoring_[^6] method (namely reputation-based approach) adopted by LibP2P. However, each of these solutions has its own shortcomings for real-life use-cases as explained below.\\n\\n#### Proof of work\\n\\nThe idea behind the Proof Of Work i.e., POW[^8] is to make messaging a computationally costly operation hence lowering the messaging rate of **all** the peers including the spammers. In specific, the message publisher has to solve a puzzle and the puzzle is to find a nonce such that the hash of the message concatenated with the nonce has at least z leading zeros. z is known as the difficulty of the puzzle. Since the hash function is one-way, peers have to brute-force to find a nonce. Hashing is a computationally-heavy operation so is the brute-force. While solving the puzzle is computationally expensive, it is comparatively cheap to verify the solution.\\n\\nPOW is also used as the underlying mining algorithm in Ethereum and Bitcoin blockchain. There, the goal is to contain the mining speed and allow the decentralized network to come to a consensus, or agree on things like account balances and the order of transactions.\\n\\nWhile the use of POW makes perfect sense in Ethereum / Bitcoin blockchain, it shows practical issues in heterogeneous p2p messaging systems with resource-restricted peers. Some peers won\'t be able to carry the designated computation and will be effectively excluded. Such exclusion showed to be practically an issue in applications like Status, which used to rely on POW for spam-protection, to the extent that the difficulty level had to be set close to zero.\\n\\n#### Peer Scoring\\n\\nThe peer scoring method[^6] that is utilized by libp2p is to limit the number of messages issued by a peer in connection to another peer. That is each peer monitors all the peers to which it is directly connected and adjusts their messaging quota i.e., to route or not route their messages depending on their past activities. For example, if a peer detects its neighbor is sending more than x messages per month, can drop its quota to z.x where z is less than one. The shortcoming of this solution is that scoring is based on peers\' local observations and the concept of the score is defined in relation to one single peer. This leaves room for an attack where a spammer can make connections to k peers in the system and publishes k.(x-1) messages by exploiting all of its k connections. Another attack scenario is through botnets consisting of a large number of e.g., a million bots. The attacker rents a botnet and inserts each of them as a legitimate peer to the network and each can publish x-1 messages per month[^7].\\n\\n#### Economic-Incentive Spam protection\\n\\nIs this the end of our spam-protection journey? Shall we simply give up and leave spammers be? Certainly not!\\nWaku RLN-Relay gives us a p2p spam-protection method which:\\n\\n- suits **p2p** systems and does not rely on any central entity.\\n- is **efficient** i.e., with no unreasonable computational, storage, memory, and bandwidth requirement! as such, it fits the network of **heterogeneous** peers.\\n- respects users **privacy** unlike reputation-based and centralized methods.\\n- deploys **economic-incentives** to contain spammers\' activity. Namely, there is a financial sacrifice for those who want to spam the system. How? follow along ...\\n\\nWe devise a general rule to save everyone\'s life and that is\\n\\n**No one can publish more than M messages per epoch without being financially charged!**\\n\\nWe set M to 1 for now, but this can be any arbitrary value. You may be thinking \\"This is too restrictive! Only one per epoch?\\". Don\'t worry, we set the epoch to a reasonable value so that it does not slow down the communication of innocent users but will make the life of spammers harder! Epoch here can be every second, as defined by UTC date-time +-20s.\\n\\nThe remainder of this post is all about the story of how to enforce this limit on each user\'s messaging rate as well as how to impose the financial cost when the limit gets violated. This brings us to the Rate Limiting Nullifiers and how we integrate this technique into Waku v2 (in specific the Waku Relay protocol) to protect our valuable users against spammers.\\n\\n## Technical Terms\\n\\n**Zero-knowledge proof**: Zero-knowledge proof (ZKP)[^14] allows a _prover_ to show a _verifier_ that they know something, without revealing what that something is. This means you can do the trust-minimized computation that is also privacy-preserving. As a basic example, instead of showing your ID when going to a bar you simply give them proof that you are over 18, without showing the doorman your id. In this write-up, by ZKP we essentially mean zkSNARK[^15] which is one of the many types of ZKPs.\\n\\n**Threshold Secret Sharing Scheme**: (m,n) Threshold secret-sharing is a method by which you can split a secret value s into n pieces in a way that the secret s can be reconstructed by having m pieces (m <= n). The economic-incentive spam protection utilizes a (2,n) secret sharing realized by Shamir Secret Sharing Scheme[^13].\\n\\n## Overview: Economic-Incentive Spam protection through Rate Limiting Nullifiers\\n\\n**Context**: We started the idea of economic-incentive spam protection more than a year ago and conducted a feasibility study to identify blockers and unknowns. The results are published in our prior [post](https://vac.dev/feasibility-semaphore-rate-limiting-zksnarks). Since then major progress has been made and the prior identified blockers that are listed below are now addressed. Kudos to [Barry WhiteHat](https://github.com/barryWhiteHat), [Onur Kilic](https://github.com/kilic), [Koh Wei Jie](https://github.com/weijiekoh/perpetualpowersoftau) for all of their hard work, research, and development which made this progress possible.\\n\\n- the proof time[^22] which was initially in the order of minutes ~10 mins and now is almost 0.5 seconds\\n- the prover key size[^21] which was initially ~110MB and now is ~3.9MB\\n- the lack of Shamir logic[^19] which is now implemented and part of the RLN repository[^4]\\n- the concern regarding the potential multi-party computation for the trusted setup of zkSNARKs which got resolved[^20]\\n- the lack of end-to-end integration that now we made it possible, have it implemented, and are going to present it in this post. New blockers are also sorted out during the e2e integration which we will discuss in the [Feasibility and Open Issues](#feasibility-and-open-issues) section.\\n\\nNow that you have more context, let\'s see how the final solution works. The fundamental point is to make it economically costly to send more than your share of messages and to do so in a privacy-preserving and e2e fashion. To do that we have the following components:\\n\\n- 1- **Group**: We manage all the peers inside a large group (later we can split peers into smaller groups, but for now consider only one). The group management is done via a smart contract which is devised for this purpose and is deployed on the Ethereum blockchain.\\n- 2- **Membership**: To be able to send messages and in specific for the published messages to get routed by all the peers, publishing peers have to register to the group. Membership involves setting up public and private key pairs (think of it as the username and password). The private key remains at the user side but the public key becomes a part of the group information on the contract (publicly available) and everyone has access to it. Public keys are not human-generated (like usernames) and instead they are random numbers, as such, they do not reveal any information about the owner (think of public keys as pseudonyms). Registration is mandatory for the users who want to publish a message, however, users who only want to listen to the messages are more than welcome and do not have to register in the group.\\n- **Membership fee**: Membership is not for free! each peer has to lock a certain amount of funds during the registration (this means peers have to have an Ethereum account with sufficient balance for this sake). This fund is safely stored on the contract and remains intact unless the peer attempts to break the rules and publish more than one message per epoch.\\n- **Zero-knowledge Proof of membership**: Do you want your message to get routed to its destination, fine, but you have to prove that you are a member of the group (sorry, no one can escape the registration phase!). Now, you may be thinking that should I attach my public key to my message to prove my membership? Absolutely Not! we said that our solution respects privacy! membership proofs are done in a zero-knowledge manner that is each message will carry cryptographic proof asserting that \\"the message is generated by one of the current members of the group\\", so your identity remains private and your anonymity is preserved!\\n- **Slashing through secret sharing**: Till now it does not seem like we can catch spammers, right? yes, you are right! now comes the exciting part, detecting spammers and slashing them. The core idea behind the slashing is that each publishing peer (not routing peers!) has to integrate a secret share of its private key inside the message. The secret share is deterministically computed over the private key and the current epoch. The content of this share is harmless for the peer\'s privacy (it looks random) unless the peer attempts to publish more than one message in the same epoch hence disclosing more than one secret share of its private key. Indeed two distinct shares of the private key under the same epoch are enough to reconstruct the entire private key. Then what should you do with the recovered private key? hurry up! go to the contract and withdraw the private key and claim its fund and get rich!! Are you thinking what if spammers attach junk values instead of valid secret shares? Of course, that wouldn\'t be cool! so, there is a zero-knowledge proof for this sake as well where the publishing peer has to prove that the secret shares are generated correctly.\\n\\nA high-level overview of the economic spam protection is shown in Figure 1.\\n\\n## Flow\\n\\nIn this section, we describe the flow of the economic-incentive spam detection mechanism from the viewpoint of a single peer. An overview of this flow is provided in Figure 3.\\n\\n## Setup and Registration\\n\\nA peer willing to publish a message is required to register. Registration is moderated through a smart contract deployed on the Ethereum blockchain. The state of the contract contains the list of registered members\' public keys. An overview of registration is illustrated in Figure 2.\\n\\nFor the registration, a peer creates a transaction that sends x amount of Ether to the contract. The peer who has the \\"private key\\" `sk` associated with that deposit would be able to withdraw x Ether by providing valid proof. Note that `sk` is initially only known by the owning peer however it may get exposed to other peers in case the owner attempts spamming the system i.e., sending more than one message per epoch.\\nThe following relation holds between the `sk` and `pk` i.e., `pk = H(sk)` where `H` denotes a hash function.\\n![Figure 2: Registration](/img/rln-relay/rln-relay.png)\\n\\n## Maintaining the membership Merkle Tree\\n\\nThe ZKP of membership that we mentioned before relies on the representation of the entire group as a [Merkle Tree](/#). The tree construction and maintenance is delegated to the peers (the initial idea was to keep the tree on the chain as part of the contract, however, the cost associated with member deletion and insertion was high and unreasonable, please see [Feasibility and Open Issues](#Feasibility-and-Open-Issues) for more details). As such, each peer needs to build the tree locally and sync itself with the contract updates (peer insertion and deletion) to mirror them on its tree.\\nTwo pieces of information of the tree are important as they enable peers to generate zero-knowledge proofs. One is the root of the tree and the other is the membership proof (or the authentication path). The tree root is public information whereas the membership proof is private data (or more precisely the index of the peer in the tree).\\n\\n## Publishing\\n\\nIn order to publish at a given epoch, each message must carry a proof i.e., a zero-knowledge proof signifying that the publishing peer is a registered member, and has not exceeded the messaging rate at the given epoch.\\n\\nRecall that the enforcement of the messaging rate was through associating a secret shared version of the peer\'s `sk` into the message together with a ZKP that the secret shares are constructed correctly. As for the secret sharing part, the peer generates the following data:\\n\\n1. `shareX`\\n2. `shareY`\\n3. `nullifier`\\n\\nThe pair (`shareX`, `shareY`) is the secret shared version of `sk` that are generated using Shamir secret sharing scheme. Having two such pairs for an identical `nullifier` results in full disclosure of peer\'s `sk` and hence burning the associated deposit. Note that the `nullifier` is a deterministic value derived from `sk` and `epoch` therefore any two messages issued by the same peer (i.e., using the same `sk`) for the same `epoch` are guaranteed to have identical `nullifier`s.\\n\\nFinally, the peer generates a zero-knowledge proof `zkProof` asserting the membership of the peer in the group and the correctness of the attached secret share (`shareX`, `shareY`) and the `nullifier`. In order to generate a valid proof, the peer needs to have two private inputs i.e., its `sk` and its authentication path. Other inputs are the tree root, epoch, and the content of the message.\\n\\n**Privacy Hint:** Note that the authentication path of each peer depends on the recent list of members (hence changes when new peers register or leave). As such, it is recommended (and necessary for privacy/anonymity) that the publisher updates her authentication path based on the latest status of the group and attempts the proof using the updated version.\\n\\nAn overview of the publishing procedure is provided in Figure 3.\\n\\n## Routing\\n\\nUpon the receipt of a message, the routing peer needs to decide whether to route it or not. This decision relies on the following factors:\\n\\n1. If the epoch value attached to the message has a non-reasonable gap with the routing peer\'s current epoch then the message must be dropped (this is to prevent a newly registered peer spamming the system by messaging for all the past epochs).\\n2. The message MUST contain valid proof that gets verified by the routing peer.\\n   If the preceding checks are passed successfully, then the message is relayed. In case of an invalid proof, the message is dropped. If spamming is detected, the publishing peer gets slashed (see [Spam Detection and Slashing](#Spam-Detection-and-Slashing)).\\n\\nAn overview of the routing procedure is provided in Figure 3.\\n\\n### Spam Detection and Slashing\\n\\nIn order to enable local spam detection and slashing, routing peers MUST record the `nullifier`, `shareX`, and `shareY` of any incoming message conditioned that it is not spam and has valid proof. To do so, the peer should follow the following steps.\\n\\n1. The routing peer first verifies the `zkProof` and drops the message if not verified.\\n2. Otherwise, it checks whether a message with an identical `nullifier` has already been relayed.\\n   - a) If such message exists and its `shareX` and `shareY` components are different from the incoming message, then slashing takes place (if the `shareX` and `shareY` fields of the previously relayed message is identical to the incoming message, then the message is a duplicate and shall be dropped).\\n   - b) If none found, then the message gets relayed.\\n\\nAn overview of the slashing procedure is provided in Figure 3.\\n![Figure 3: Publishing, Routing and Slashing workflow.](/img/rln-relay/rln-message-verification.png)\\n\\n## Feasibility and Open Issues\\n\\nWe\'ve come a long way since a year ago, blockers resolved, now we have implemented it end-to-end. We learned lot and could identify further issues and unknowns some of which are blocking getting to production. The summary of the identified issues are presented below.\\n\\n## Storage overhead per peer\\n\\nCurrently, peers are supposed to maintain the entire tree locally and it imposes storage overhead which is linear in the size of the group (see this [issue](https://github.com/vacp2p/research/issues/57)[^11] for more details). One way to cope with this is to use the light-node and full-node paradigm in which only a subset of peers who are more resourceful retain the tree whereas the light nodes obtain the necessary information by interacting with the full nodes. Another way to approach this problem is through a more storage efficient method (as described in this research issue[^12]) where peers store a partial view of the tree instead of the entire tree. Keeping the partial view lowers the storage complexity to O(log(N)) where N is the size of the group. There are still unknown unknowns to this solution, as such, it must be studied further to become fully functional.\\n\\n## Cost-effective way of member insertion and deletion\\n\\nCurrently, the cost associated with RLN-Relay membership is around 30 USD[^10]. We aim at finding a more cost-effective approach. Please feel free to share with us your solution ideas in this regard in this [issue](https://github.com/vacp2p/research/issues/56).\\n\\n## Exceeding the messaging rate via multiple registrations\\n\\nWhile the economic-incentive solution has an economic incentive to discourage spamming, we should note that there is still **expensive attack(s)**[^23] that a spammer can launch to break the messaging rate limit. That is, the attacker can pay for multiple legit registrations e.g., k, hence being able to publish k messages per epoch. We believe that the higher the membership fee is, the less probable would be such an attack, hence a stronger level of spam-protection can be achieved. Following this argument, the high fee associated with the membership (which we listed above as an open problem) can indeed be contributing to a better protection level.\\n\\n## Conclusion and Future Steps\\n\\nAs discussed in this post, Waku RLN Relay can achieve a privacy-preserving economic spam protection through rate-limiting nullifiers. The idea is to financially discourage peers from publishing more than one message per epoch. In specific, exceeding the messaging rate results in a financial charge. Those who violate this rule are called spammers and their messages are spam. The identification of spammers does not rely on any central entity. Also, the financial punishment of spammers is cryptographically guaranteed.\\nIn this solution, privacy is guaranteed since: 1) Peers do not have to disclose any piece of personally identifiable information in any phase i.e., neither in the registration nor in the messaging phase 2) Peers can prove that they have not exceeded the messaging rate in a zero-knowledge manner and without leaving any trace to their membership accounts.\\nFurthermore, all the computations are light hence this solution fits the heterogenous p2p messaging system. Note that the zero-knowledge proof parts are handled through zkSNARKs and the benchmarking result can be found in the RLN benchmark report[^5].\\n\\n**Future steps**:\\n\\nWe are still at the PoC level, and the development is in progress. As our future steps,\\n\\n- we would like to evaluate the running time associated with the Merkle tree operations. Indeed, the need to locally store Merkle tree on each peer was one of the unknowns discovered during this PoC and yet the concrete benchmarking result in this regard is not available.\\n- We would also like to pursue our storage-efficient Merkle Tree maintenance solution in order to lower the storage overhead of peers.\\n- In line with the storage optimization, the full-node light-node structure is another path to follow.\\n- Another possible improvement is to replace the membership contract with a distributed group management scheme e.g., through distributed hash tables. This is to address possible performance issues that the interaction with the Ethereum blockchain may cause. For example, the registration transactions are subject to delay as they have to be mined before being visible in the state of the membership contract. This means peers have to wait for some time before being able to publish any message.\\n\\n## Acknowledgement\\n\\nThanks to Onur K\u0131l\u0131\xe7 for his explanation and pointers and for assisting with development and runtime issues. Also thanks to Barry Whitehat for his time and insightful comments. Special thanks to Oskar Thoren for his constructive comments and his guides during the development of this PoC and the writeup of this post.\\n\\n## References\\n\\n[^1]: Waku v2: https://rfc.vac.dev/spec/10/\\n[^2]: RLN-Relay specification: https://rfc.vac.dev/spec/17/\\n[^3]: RLN documentation: [https://hackmd.io/tMTLMYmTR5eynw2lwK9n1w?both](https://hackmd.io/tMTLMYmTR5eynw2lwK9n1w?both)\\n[^4]: RLN repositories: [https://github.com/kilic/RLN](https://github.com/kilic/RLN) and [https://github.com/kilic/rlnapp](https://github.com/kilic/rlnapp)\\n[^5]: RLN Benchmark: [https://hackmd.io/tMTLMYmTR5eynw2lwK9n1w?view#Benchmarks](https://hackmd.io/tMTLMYmTR5eynw2lwK9n1w?view#Benchmarks)\\n[^6]: Peer Scoring: [https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md#peer-scoring](https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md#peer-scoring)\\n[^7]: Peer scoring security issues: [https://github.com/vacp2p/research/issues/44](https://github.com/vacp2p/research/issues/44)\\n[^8]: Proof of work: [http://www.infosecon.net/workshop/downloads/2004/pdf/clayton.pdf](http://www.infosecon.net/workshop/downloads/2004/pdf/clayton.pdf) and [https://link.springer.com/content/pdf/10.1007/3-540-48071-4_10.pdf](https://link.springer.com/content/pdf/10.1007/3-540-48071-4_10.pdf)\\n[^9]: EIP-627 Whisper: https://eips.ethereum.org/EIPS/eip-627\\n[^10]: Cost-effective way of member insertion and deletion: [https://github.com/vacp2p/research/issues/56](https://github.com/vacp2p/research/issues/56)\\n[^11]: Storage overhead per peer: [https://github.com/vacp2p/research/issues/57](https://github.com/vacp2p/research/issues/57)\\n[^12]: Storage-efficient Merkle Tree maintenance: [https://github.com/vacp2p/research/pull/54](https://github.com/vacp2p/research/pull/54)\\n[^13]: Shamir Secret Sharing Scheme: [https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing](https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing)\\n[^14]: Zero Knowledge Proof: [https://dl.acm.org/doi/abs/10.1145/3335741.3335750](https://dl.acm.org/doi/abs/10.1145/3335741.3335750) and [https://en.wikipedia.org/wiki/Zero-knowledge_proof](https://en.wikipedia.org/wiki/Zero-knowledge_proof)\\n[^15]: zkSNARKs: [https://link.springer.com/chapter/10.1007/978-3-662-49896-5_11](https://link.springer.com/chapter/10.1007/978-3-662-49896-5_11) and [https://coinpare.io/whitepaper/zcash.pdf](https://coinpare.io/whitepaper/zcash.pdf)\\n[^16]: GossipSub: [https://docs.libp2p.io/concepts/publish-subscribe/](https://docs.libp2p.io/concepts/publish-subscribe/)\\n[^17]: Waku Relay: https://rfc.vac.dev/spec/11/\\n[^18]: Prior blockers of RLN-Relay: [https://vac.dev/feasibility-semaphore-rate-limiting-zksnarks](https://vac.dev/feasibility-semaphore-rate-limiting-zksnarks)\\n[^19]: The lack of Shamir secret sharing in zkSNARKs: [https://github.com/vacp2p/research/issues/10](https://github.com/vacp2p/research/issues/10)\\n[^20]: The MPC required for zkSNARKs trusted setup: [https://github.com/vacp2p/research/issues/9](https://github.com/vacp2p/research/issues/9)\\n[^21]: Prover key size: [https://github.com/vacp2p/research/issues/8](https://github.com/vacp2p/research/issues/8)\\n[^22]: zkSNARKs proof time: [https://github.com/vacp2p/research/issues/7](https://github.com/vacp2p/research/issues/7)\\n[^23]: Attack on the messaging rate: [https://github.com/vacp2p/specs/issues/251](https://github.com/vacp2p/specs/issues/251)"},{"id":"waku-v2-ethereum-messaging","metadata":{"permalink":"/rlog/waku-v2-ethereum-messaging","source":"@site/rlog/2020-11-10-waku-v2-ethereum-messaging.mdx","title":"[Talk] Vac, Waku v2 and Ethereum Messaging","description":"Talk from Taipei Ethereum Meetup. Read on to find out about our journey from Whisper to Waku v2, as well as how Waku v2 can be useful for Etherum Messaging.","date":"2020-11-10T12:00:00.000Z","formattedDate":"November 10, 2020","tags":[],"readingTime":9.51,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"[Talk] Vac, Waku v2 and Ethereum Messaging","title":"[Talk] Vac, Waku v2 and Ethereum Messaging","date":"2020-11-10T12:00:00.000Z","authors":"oskarth","published":true,"slug":"waku-v2-ethereum-messaging","categories":"research","image":"/img/taipei_ethereum_meetup_slide.png","discuss":"https://forum.vac.dev/t/discussion-talk-vac-waku-v2-and-ethereum-messaging/60"},"prevItem":{"title":"Privacy-preserving p2p economic spam protection in Waku v2","permalink":"/rlog/rln-relay"},"nextItem":{"title":"Waku v2 Update","permalink":"/rlog/waku-v2-update"}},"content":"Talk from Taipei Ethereum Meetup. Read on to find out about our journey from Whisper to Waku v2, as well as how Waku v2 can be useful for Etherum Messaging.\\n\\n\x3c!--truncate--\x3e\\n\\n_The following post is a transcript of the talk given at the [Taipei Ethereum meetup, November 5](https://www.meetup.com/Taipei-Ethereum-Meetup/events/274033344/). There is also a [video recording](https://www.youtube.com/watch?v=lUDy1MoeYnI)._\\n\\n---\\n\\n## 0. Introduction\\n\\nHi! My name is Oskar and I\'m the protocol research lead at Vac. This talk will be divided into two parts. First I\'ll talk about the journey from Whisper, to Waku v1 and now to Waku v2. Then I\'ll talk about messaging in Ethereum. After this talk, you should have an idea of what Waku v2 is, the problems it is trying to solve, as well as where it can be useful for messaging in Ethereum.\\n\\n## PART 1 - VAC AND THE JOURNEY FROM WHISPER TO WAKU V1 TO WAKU V2\\n\\n## 1. Vac intro\\n\\nFirst, what is Vac? Vac grew out of our efforts Status to create a window on to Ethereum and secure messenger. Vac is modular protocol stack for p2p secure messaging, paying special attention to resource restricted devices, privacy and censorship resistance.\\n\\nToday we are going to talk mainly about Waku v2, which is the transport privacy / routing aspect of the Vac protocol stack. It sits \\"above\\" the p2p overlay, such as libp2p dealing with transports etc, and below a conversational security layer dealing with messaging encryption, such as using Double Ratchet etc.\\n\\n## 2. Whisper to Waku v1\\n\\nIn the beginning, there was Whisper. Whisper was part of the holy trinity of Ethereum. You had Ethereum for consensus/computation, Whisper for messaging, and Swarm for storage.\\n\\nHowever, for various reasons, Whisper didn\'t get the attention it deserved. Development dwindled, it promised too much and it suffered from many issues, such as being extremely inefficient and not being suitable for running on e.g. mobile phone. Despite this, Status used it in its app from around 2017 to 2019. As far as I know, it was one of very few, if not the only, production uses of Whisper.\\n\\nIn an effort to solve some of its immediate problems, we forked Whisper into Waku and formalized it with a proper specification. This solved immediate bandwidth issues for light nodes, introduced rate limiting for better spam protection, improved historical message support, etc.\\n\\nIf you are interested in this journey, checkout the [EthCC talk Dean and I gave in Paris earlier this year](https://www.youtube.com/watch?v=6lLT33tsJjs).\\n\\nStatus upgraded to Waku v1 early 2020. What next?\\n\\n## 3. Waku v1 to v2\\n\\nWe were far from done. The changes we had made were quite incremental and done in order to get tangible improvements as quickly as possible. This meant we couldn\'t address more fundamental issues related to full node routing scalability, running with libp2p for more transports, better security, better spam protection and incentivization.\\n\\nThis kickstarted Waku v2 efforts, which is what we\'ve been working on since July. This work was and is initally centered around a few pieces:\\n\\n(a) Moving to libp2p\\n\\n(b) Better routing\\n\\n(c) Accounting and user-run nodes\\n\\nThe general theme was: making the Waku network more scalable and robust.\\n\\nWe also did a scalability study to show at what point the network would run into issues, due to the inherent lack of routing that Whisper and Waku v1 provided.\\n\\nYou can read more about this [here](https://vac.dev/waku-v2-plan).\\n\\n## 3.5 Waku v2 - Design goals\\n\\nTaking a step back, what problem does Waku v2 attempt to solve compared to all the other solutions that exists out there? What type of applications should use it and why? We have the following design goals:\\n\\n1. **Generalized messaging**. Many applications requires some form of messaging protocol to communicate between different subsystems or different nodes. This messaging can be human-to-human or machine-to-machine or a mix.\\n\\n2. **Peer-to-peer**. These applications sometimes have requirements that make them suitable for peer-to-peer solutions.\\n\\n3. **Resource restricted**. These applications often run in constrained environments, where resources or the environment is restricted in some fashion. E.g.:\\n\\n   - limited bandwidth, CPU, memory, disk, battery, etc\\n   - not being publicly connectable\\n   - only being intermittently connected; mostly-offline\\n\\n4. **Privacy**. These applications have a desire for some privacy guarantees, such as pseudonymity, metadata protection in transit, etc.\\n\\nAs well as to do so in a modular fashion. Meaning you can find a reasonable trade-off depending on your exact requirements. For example, you usually have to trade off some bandwidth to get metadata protection, and vice versa.\\n\\nThe concept of designing for resource restricted devices also leads to the concept of adaptive nodes, where you have more of a continuum between full nodes and light nodes. For example, if you switch your phone from mobile data to WiFi you might be able to handle more bandwidth, and so on.\\n\\n## 4. Waku v2 - Breakdown\\n\\nWhere is Waku v2 at now, and how is it structured?\\n\\nIt is running over libp2p and we had our second internal testnet last week or so. As a side note, we name our testnets after subway stations in Taipei, the first one being Nangang, and the most recent one being Dingpu.\\n\\nThe main implementation is written in Nim using nim-libp2p, which is also powering Nimbus, an Ethereum 2 client. There is also a PoC for running Waku v2 in the browser. On a spec level, we have the following specifications that corresponds to the components that make up Waku v2:\\n\\n- Waku v2 - this is the main spec that explains the goals of providing generalized messaging, in a p2p context, with a focus on privacy and running on resources restricted devices.\\n- Relay - this is the main PubSub spec that provides better routing. It builds on top of GossipSub, which is what Eth2 heavily relies on as well.\\n- Store - this is a 1-1 protocol for light nodes to get historical messages, if they are mostly-offline.\\n- Filter - this is a 1-1 protocol for light nodes that are bandwidth restricted to only (or mostly) get messages they care about.\\n- Message - this explains the payload, to get some basic encryption and content topics. It corresponds roughly to envelopes in Whisper/Waku v1.\\n- Bridge - this explains how to do bridging between Waku v1 and Waku v2 for compatibility.\\n\\nRight now, all protocols, with the exception of bridge, are in draft mode, meaning they have been implemented but are not yet being relied upon in production.\\n\\nYou can read more about the breakdown in this [update](https://vac.dev/waku-v2-update) though some progress has been made since then, as well was in the [main Waku v2 spec](https://rfc.vac.dev/spec/10).\\n\\n## 5. Waku v2 - Upcoming\\n\\nWhat\'s coming up next? There are a few things.\\n\\nFor Status to use it in production, it needs to be integrated into the main app using the Nim Node API. The bridge also needs to be implemented and tested.\\n\\nFor other users, we are currently overhauling the API to allow usage from a browser, e.g. To make this experience great, there are also a few underlying infrastructure things that we need in nim-libp2p, such as a more secure HTTP server in Nim, Websockets and WebRTC support.\\n\\nThere are also some changes we made to at what level content encryption happens, and this needs to be made easier to use in the API. This means you can use a node without giving your keys to it, which is useful in some environments.\\n\\nMore generally, beyond getting to production-ready use, there are a few bigger pieces that we are working on or will work on soon. These are things like:\\n\\n- Better scaling, by using topic sharding.\\n- Accounting and user-run nodes, to account for and incentives full nodes.\\n- Stronger and more rigorous privacy guarantees, e.g. through study of GossipSub, unlinkable packet formats, etc.\\n- Rate Limit Nullifier for privacy preserving spam protection, a la what Barry Whitehat has presented before.\\n\\nAs well as better support for Ethereum M2M Messaging. Which is what I\'ll talk about next.\\n\\n## PART 2 - ETHEREUM MESSAGING\\n\\nA lot of what follows is inspired by exploratory work that John Lea has done at Status, previously Head of UX Architecture at Ubuntu.\\n\\n## 6. Ethereum Messaging - Why?\\n\\nIt is easy to think that Waku v2 is only for human to human messaging, since that\'s how Waku is currently primarily used in the Status app. However, the goal is to be useful for generalized messaging, which includes other type of information as well as machine to machine messaging.\\n\\nWhat is Ethereum M2M messaging? Going back to the Holy Trinity of Ethereum/Whisper/Swarm, the messaging component was seen as something that could facilitate messages between dapps and acts as a building block. This can help with things such as:\\n\\n- Reducing on-chain transactions\\n- Reduce latency for operations\\n- Decentralize centrally coordinated services (like WalletConnect)\\n- Improve UX of dapps\\n- Broadcast live information\\n- A message transport layer for state channels\\n\\nAnd so on.\\n\\n## 7. Ethereum Messaging - Why? (Cont)\\n\\nWhat are some examples of practical things Waku as used for Ethereum Messaging could solve?\\n\\n- Multisig transfers only needing one on chain transaction\\n- DAO votes only needing one one chain transaction\\n- Giving dapps ability to direct push notifications to users\\n- Giving users ability to directly respond to requests from daps\\n- Decentralized Wallet Connect\\n\\nEtc.\\n\\n## 8. What\'s needed to deliver this?\\n\\nWe can break it down into our actors:\\n\\n- Decentralized M2M messaging system (Waku)\\n- Native wallets (Argent, Metamask, Status, etc)\\n- Dapps that benefit from M2M messaging\\n- Users whose problems are being solved\\n\\nEach of these has a bunch of requirements in turn. The messaging system needs to be decentralized, scalable, robust, etc. Wallets need support for messaging layer, dapps need to integrate this, etc.\\n\\nThis is a lot! Growing adoption is a challenge. There is a catch 22 in terms of justifying development efforts for wallets, when no dapps need it, and likewise for dapps when no wallets support Waku. In addition to this, there must be proven usage of Waku before it can be relied on, etc. How can we break this up into smaller pieces of work?\\n\\n## 9. Breaking up the problem and a high level roadmap\\n\\nWe can start small. It doesn\'t and need to be used for critical features first. A more hybrid approach can be taken where it acts more as nice-to-haves.\\n\\n1.  Forking Whisper and solving scalablity, spam etc issues with it.\\n    This is a work in progress. What we talked about in part 1.\\n2.  Expose messaging API for Dapp developers.\\n3.  Implement decentralized version of WalletConnect.\\n    Currently wallets connect ot dapps with centralized service. Great UX.\\n4.  Solve DAO/Multi-Sig coordination problem.\\n    E.g. send message to wallet-derived key when it is time to sign a transaction.\\n5.  Extend dapp-to-user and user-to-dapp communication to more dapps.\\n    Use lessons learned and examples to drive adoptation for wallets/dapps.\\n\\nAnd then build up from there.\\n\\n## 10. We are hiring!\\n\\nA lot of this will happen in Javascript and browsers, since that\'s the primarily environment for a lot of wallets and dapps. We are currently hiring for a Waku JS Wallet integration lead to help push this effort further.\\n\\nCome talk to me after or [apply here](https://status.im/our_team/open_positions.html?gh_jid=2385338).\\n\\nThat\'s it! You can find us on Status, Telegram, vac.dev. I\'m on twitter [here](https://twitter.com/oskarth).\\n\\nQuestions?\\n\\n---"},{"id":"waku-v2-update","metadata":{"permalink":"/rlog/waku-v2-update","source":"@site/rlog/2020-09-28-waku-v2-update.mdx","title":"Waku v2 Update","description":"A research log. Read on to find out what is going on with Waku v2, a messaging protocol. What has been happening? What is coming up next?","date":"2020-09-28T12:00:00.000Z","formattedDate":"September 28, 2020","tags":[],"readingTime":7.435,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"Waku v2 Update","title":"Waku v2 Update","date":"2020-09-28T12:00:00.000Z","authors":"oskarth","published":true,"slug":"waku-v2-update","categories":"research","discuss":"https://forum.vac.dev/t/discussion-waku-v2-update/56"},"prevItem":{"title":"[Talk] Vac, Waku v2 and Ethereum Messaging","permalink":"/rlog/waku-v2-ethereum-messaging"},"nextItem":{"title":"What\'s the Plan for Waku v2?","permalink":"/rlog/waku-v2-plan"}},"content":"A research log. Read on to find out what is going on with Waku v2, a messaging protocol. What has been happening? What is coming up next?\\n\\n\x3c!--truncate--\x3e\\n\\nIt has been a while since the last post. It is time for an update on Waku v2. Aside from getting more familiar with libp2p (specifically nim-libp2p) and some vacation, what have we been up to? In this post we\'ll talk about what we\'ve gotten done since last time, and briefly talk about immediate next steps and future. But first, a recap.\\n\\n## Recap\\n\\nIn the last post ([Waku v2 plan](https://vac.dev/waku-v2-plan)) we explained the rationale of Waku v2 - the current Waku network is fragile and doesn\'t scale. To solve this, Waku v2 aims to reduce amplification factors and get more user run nodes. We broke the work down into three separate tracks.\\n\\n1. Track 1 - Move to libp2p\\n2. Track 2 - Better routing\\n3. Track 3 - Accounting and user-run nodes\\n\\nAs well as various rough components for each track. The primary initial focus is track 1. This means things like: moving to FloodSub, simplify the protocol, core integration, topic interest behavior, historical message caching, and Waku v1<\\\\>v2 bridge.\\n\\n## Current state\\n\\nLet\'s talk about the state of specs and our main implementation nim-waku. Then we\'ll go over our recent testnet, Nangang, and finish off with a Web PoC.\\n\\n## Specs\\n\\nAfter some back and forth on how to best structure things, we ended up breaking down the specs into a few pieces. While Waku v2 is best thought of as a cohesive whole in terms of its capabilities, it is made up of several protocols. Here\'s a list of the current specs and their status:\\n\\n- [Main spec](https://rfc.vac.dev/spec/10/) (draft)\\n- [Relay protocol spec](https://rfc.vac.dev/spec/11/) (draft)\\n- [Filter protocol spec](https://rfc.vac.dev/spec/12) (raw)\\n- [Store protocol spec](https://rfc.vac.dev/spec/13) (raw)\\n- [Bridge spec](https://rfc.vac.dev/spec/15/) (raw)\\n\\nRaw means there is not yet an implementation that corresponds fully to the spec, and draft means there is an implementation that corresponds to the spec. In the interest of space, we won\'t go into too much detail on the specs here except to note a few things:\\n\\n- The relay spec is essentially a thin wrapper on top of PubSub/FloodSub/GossipSub\\n- The filter protocol corresponds to previous light client mode in Waku v1\\n- The store protocol corresponds to the previous mailserver construct in Waku v1\\n\\nThe filter and store protocol allow for adaptive nodes, i.e. nodes that have various capabilities. For example, a node being mostly offline, or having limited bandwidth capacity. The bridge spec outlines how to bridge the Waku v1 and v2 networks.\\n\\n## Implementation\\n\\nThe main implementation we are working on is [nim-waku](https://github.com/status-im/nim-waku/). This builds on top of libraries such as [nim-libp2p](https://github.com/status-im/nim-libp2p) and others that the [Nimbus team](https://nimbus.team/) have been working on as part of their Ethereum 2.0 client.\\n\\nCurrently nim-waku implements the relay protocol, and is close to implementing filter and store protocol. It also exposes a [Nim Node API](https://github.com/status-im/nim-waku/blob/master/docs/api/v2/node.md) that allows libraries such as [nim-status](https://github.com/status-im/status-nim) to use it. Additionally, there is also a rudimentary JSON RPC API for command line scripting.\\n\\n## Nangang testnet\\n\\nLast week we launched a very rudimentary internal testnet called Nangang. The goal was to test basic connectivity and make sure things work end to end. It didn\'t have things like: client integration, encryption, bridging, multiple clients, store/filter protocol, or even a real interface. What it did do is allow Waku developers to \\"chat\\" via RPC calls and looking in the log output. Doing this meant we exposed and fixed a few blockers, such as connection issues, deployment, topic subscription management, protocol and node integration, and basic scripting/API usage. After this, we felt confident enough to upgrade the main and relay spec to \\"draft\\" status.\\n\\n## Waku Web PoC\\n\\nAs a bonus, we wanted to see what it\'d take to get Waku running in a browser. This is a very powerful capability that enables a lot of use cases, and something that libp2p enables with its multiple transport support.\\n\\nUsing the current stack, with nim-waku, would require quite a lot of ground work with WASM, WebRTC, Websockets support etc. Instead, we decided to take a shortcut and hack together a JS implementation called [Waku Web Chat](https://github.com/vacp2p/waku-web-chat/). This quick hack wouldn\'t be possible without the people behind [js-libp2p-examples](https://github.com/libp2p/js-libp2p-examples/) and [js-libp2p](https://github.com/libp2p/js-libp2p) and all its libraries. These are people like Jacob Heun, Vasco Santos, and Cayman Nava. Thanks!\\n\\nIt consists of a brower implementation, a NodeJS implementation and a bootstrap server that acts as a signaling server for WebRTC. It is largely a bastardized version of GossipSub, and while it isn\'t completely to spec, it does allow messages originating from a browser to eventually end up at a nim-waku node, and vice versa. Which is pretty cool.\\n\\n## Coming up\\n\\nNow that we know what the current state is, what is still missing? what are the next steps?\\n\\n## Things that are missing\\n\\nWhile we are getting closer to closing out work for track 1, there are still a few things missing from the initial scope:\\n\\n1. Store and filter protocols need to be finished. This means basic spec, implementation, API integration and proven to work in a testnet. All of these are work in progress and expected to be done very soon. Once the store protocol is done in a basic form, it needs further improvements to make it production ready, at least on a spec/basic implementation level.\\n\\n2. Core integration was mentioned in scope for track 1 initially. This work has stalled a bit, largely due to organizational bandwidth and priorities. While there is a Nim Node API that in theory is ready to be used, having it be used in e.g. Status desktop or mobile app is a different matter. The team responsible for this at Status ([status-nim](https://github.com/status-im/status-nim) has been making progress on getting nim-waku v1 integrated, and is expected to look into nim-waku v2 integration soon. One thing that makes this a especially tricky is the difference in interface between Waku v1 and v2, which brings\\n   us too...\\n\\n3. Companion spec for encryption. As part of simplifying the protocol, the routing is decoupled from the encryption in v2 ([1](https://github.com/vacp2p/specs/issues/158), [2](https://github.com/vacp2p/specs/issues/181)). There are multiple layers of encryption at play here, and we need to figure out a design that makes sense for various use cases (dapps using Waku on their own, Status app, etc).\\n\\n4. Bridge implementation. The spec is done and we know how it should work, but it needs to be implemented.\\n\\n5. General tightening up of specs and implementation.\\n\\nWhile this might seem like a lot, a lot has been done already, and the majority of the remaining tasks are more amendable to be pursued in parallel with other efforts. It is also worth mentioning that part of track 2 and 3 have been started, in the form of moving to GossipSub (amplification factors) and basics of adaptive nodes (multiple protocols). This is in addition to things like Waku Web which were not part of the initial scope.\\n\\n## Upcoming\\n\\nAside from the things mentioned above, what is coming up next? There are a few areas of interest, mentioned in no particular order. For track 2 and 3, see previous post for more details.\\n\\n1. Better routing (track 2). While we are already building on top of GossipSub, we still need to explore things like topic sharding in more detail to further reduce amplification factors.\\n\\n2. Accounting and user-run nodes (track 3). With store and filter protocol getting ready, we can start to implement accounting and light connection game for incentivization in a bottom up and iterative manner.\\n\\n3. Privacy research. Study better and more rigorous privacy guarantees. E.g. how FloodSub/GossipSub behaves for common threat models, and how custom packet\\n   format can improve things like unlinkability.\\n\\n4. zkSnarks RLN for spam protection and incentivization. We studied this [last year](https://vac.dev/feasibility-semaphore-rate-limiting-zksnarks) and recent developments have made this relevant to study again. Create an [experimental spec/PoC](https://github.com/vacp2p/specs/issues/189) as an extension to the relay protocol. Kudos to Barry Whitehat and others like Kobi Gurkan and Koh Wei Jie for pushing this!\\n\\n5. Ethereum M2M messaging. Being able to run in the browser opens up a lot of doors, and there is an opportunity here to enable things like a decentralized WalletConnect, multi-sig transactions, voting and similar use cases. This was the original goal of Whisper, and we\'d like to deliver on that.\\n\\nAs you can tell, quite a lot of thing! Luckily, we have two people joining as protocol engineers soon, which will bring much needed support for the current team of ~2-2.5 people. More details to come in further updates.\\n\\n---\\n\\nIf you are feeling adventurous and want to use early stage alpha software, check out the [docs](https://github.com/status-im/nim-waku/tree/master/docs). If you want to read the specs, head over to [Waku spec](https://rfc.vac.dev/spec/10/). If you want to talk with us, join us on [Status](https://get.status.im/chat/public/vac) or on [Telegram](https://t.me/vacp2p) (they are bridged)."},{"id":"waku-v2-plan","metadata":{"permalink":"/rlog/waku-v2-plan","source":"@site/rlog/2020-07-01-waku-v2-pitch.mdx","title":"What\'s the Plan for Waku v2?","description":"Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!","date":"2020-07-01T12:00:00.000Z","formattedDate":"July 1, 2020","tags":[],"readingTime":13.7,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"What\'s the Plan for Waku v2?","title":"What\'s the Plan for Waku v2?","date":"2020-07-01T12:00:00.000Z","authors":"oskarth","published":true,"slug":"waku-v2-plan","categories":"research","image":"/img/status_scaling_model_fig4.png","discuss":"https://forum.vac.dev/t/waku-version-2-pitch/52"},"prevItem":{"title":"Waku v2 Update","permalink":"/rlog/waku-v2-update"},"nextItem":{"title":"Feasibility Study: Discv5","permalink":"/rlog/feasibility-discv5"}},"content":"Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!\\n\\n\x3c!--truncate--\x3e\\n\\n**tldr: The Waku network is fragile and doesn\'t scale. Here\'s how to solve it.**\\n\\n_NOTE: This post was originally written with Status as a primary use case in mind, which reflects how we talk about some problems here. However, Waku v2 is a general-purpose private p2p messaging protocol, especially for people running in resource restricted environments._\\n\\n## Problem\\n\\nThe Waku network is fragile and doesn\'t scale.\\n\\nAs [Status](https://status.im) is moving into a user-acquisition phase and is improving retention rates for users they need the infrastructure to keep up, specifically when it comes to messaging.\\n\\nBased on user acquisition models, the initial goal is to support 100k DAU in September, with demand growing from there.\\n\\nWith the Status Scaling Model we have studied the current bottlenecks as a function of concurrent users (CCU) and daily active users (DAU). Here are the conclusions.\\n\\n\\\\***\\\\*1. Connection limits\\\\*\\\\***. With 100 full nodes we reach ~10k CCU based on connection limits. This can primarily be addressed by increasing the number of nodes (cluster or user operated). This assumes node discovery works. It is also worth investigating the limitations of max number of connections, though this is likely to be less relevant for user-operated nodes. For a user-operated network, this means 1% of users have to run a full node. See Fig 1-2.\\n\\n\\\\***\\\\*2. Bandwidth as a bottleneck\\\\*\\\\***. We notice that memory usage appears to not be\\nthe primary bottleneck for full nodes, and the bottleneck is still bandwidth. To support 10k DAU, and full nodes with an amplification factor of 25 the required Internet speed is ~50 Mbps, which is a fast home Internet connection. For ~100k DAU only cloud-operated nodes can keep up (500 Mbps). See Fig 3-5.\\n\\n\\\\***\\\\*3. Amplification factors\\\\*\\\\***. Reducing amplification factors with better routing, would have a high impact, but it is likely we\'d need additional measures as well, such as topic sharding or similar. See Fig 8-13.\\n\\nFigure 1-5:\\n\\n![](/img/status_scaling_model_fig1.png)\\n![](/img/status_scaling_model_fig2.png)\\n![](/img/status_scaling_model_fig3.png)\\n![](/img/status_scaling_model_fig4.png)\\n![](/img/status_scaling_model_fig5.png)\\n\\nSee <https://colab.research.google.com/drive/1Fz-oxRxxAFPpM1Cowpnb0nT52V1-yeRu#scrollTo=Yc3417FUJJ_0> for the full report.\\n\\nWhat we need to do is:\\n\\n1.  Reduce amplification factors\\n2.  Get more user-run full nodes\\n\\nDoing this means the Waku network will be able to scale, and doing so in the right way, in a robust fashion. What would a fragile way of scaling be? Increasing our reliance on a Status Pte Ltd operated cluster which would paint us in a corner where we:\\n\\n- keep increasing requirements for Internet speed for full nodes\\n- are vulnerable to censorship and attacks\\n- have to control the topology in an artifical manner to keep up with load\\n- basically re-invent a traditional centralized client-server app with extra steps\\n- deliberately ignore most of our principles\\n- risk the network being shut down when we run out of cash\\n\\n## Appetite\\n\\nOur initial risk appetite for this is 6 weeks for a small team.\\n\\nThe idea is that we want to make tangible progress towards the goal in a limited period of time, as opposed to getting bogged down in trying to find a theoretically perfect generalized solution. Fixed time, variable scope.\\n\\nIt is likely some elements of a complete solution will be done separately. See later sections for that.\\n\\n## Solution\\n\\nThere are two main parts of the solution. One is to reduce amplification factors, and the other is incentivization to get more user run full nodes with desktop, etc.\\n\\nWhat does a full node provide? It provides connectivity to the network, can act as a bandwidth \\"barrier\\" and be high or reasonably high availability. What this means right now is essentially topic interest and storing historical messages.\\n\\nThe goal is here to improve the status quo, not get a perfect solution from the get go. All of this can be iterated on further, for stronger guarantees, as well as replaced by other new modules.\\n\\nLet\'s first look at the baseline, and then go into some of the tracks and their phases. Track 1 is best done first, after which track 2 and 3 can be executed in parallel. Track 1 gives us more options for track 2 and 3. The work in track 1 is currently more well-defined, so it is likely the specifics of track 2 and 3 will get refined at a later stage.\\n\\n## Baseline\\n\\nHere\'s where we are at now. In reality, the amplification factor are likely even worse than this (15 in the graph below), up to 20-30. Especially with an open network, where we can\'t easily control connectivity and availability of nodes. Left unchecked, with a full mesh, it could even go as high x100, though this is likely excessive and can be dialed down. See scaling model for more details.\\n\\n![](/img/waku_v1_routing_small.png)\\n\\n## Track 1 - Move to libp2p\\n\\nMoving to PubSub over libp2p wouldn\'t improve amplification per se, but it would be stepping stone. Why? It paves the way for GossipSub, and would be a checkpoint on this journey. Additionally, FloodSub and GossipSub are compatible, and very likely other future forms of PubSub such as GossipSub 1.1 (hardened/more secure), EpiSub, forwarding Kademlia / PubSub over Kademlia, etc. Not to mention security This would also give us access to the larger libp2p ecosystem (multiple protocols, better encryption, quic, running in the browser, security audits, etc, etc), as well as be a joint piece of infrastructured used for Eth2 in Nimbus. More wood behind fewer arrows.\\n\\nSee more on libp2p PubSub here: <https://docs.libp2p.io/concepts/publish-subscribe/>\\n\\nAs part of this move, there are a few individual pieces that are needed.\\n\\n### 1. FloodSub\\n\\nThis is essentially what Waku over libp2p would look like in its most basic form.\\n\\nOne difference that is worth noting is that the app topics would **not** be the same as Waku topics. Why? In Waku we currently don\'t use topics for routing between full nodes, but only for edge/light nodes in the form of topic interest. In FloodSub, these topics are used for routing.\\n\\nWhy can\'t we use Waku topics for routing directly? PubSub over libp2p isn\'t built for rare and ephemeral topics, and nodes have to explicitly subscribe to a topic. See topic sharding section for more on this.\\n\\n![](/img/waku_v2_routing_flood_small.png)\\n\\nMoving to FloodSub over libp2p would also be an opportunity to clean up and simplify some components that are no longer needed in the Waku v1 protocol, see point below.\\n\\nVery experimental and incomplete libp2p support can be found in the nim-waku repo under v2: <https://github.com/status-im/nim-waku>\\n\\n### 2. Simplify the protocol\\n\\nDue to Waku\'s origins in Whisper, devp2p and as a standalone protocol, there are a lot of stuff that has accumulated (<https://rfc.vac.dev/spec/6/>). Not all of it serves it purpose anymore. For example, do we still need RLP here when we have Protobuf messages? What about extremely low PoW when we have peer scoring? What about key management / encryption when have encryption at libp2p and Status protocol level?\\n\\nNot everything has to be done in one go, but being minimalist at this stage will the protocol lean and make us more adaptable.\\n\\nThe essential characteristic that has to be maintained is that we don\'t need to change the upper layers, i.e. we still deal with (Waku) topics and some envelope like data unit.\\n\\n### 3. Core integration\\n\\nAs early as possible we want to integrate with Core via Stimbus in order to mitigate risk and catch integration issues early in the process. What this looks like in practice is some set of APIs, similar to how Whisper and Waku were working in parallel, and experimental feature behind a toggle in core/desktop.\\n\\n### 4. Topic interest behavior\\n\\nWhile we target full node traffic here, we want to make sure we maintain the existing bandwidth requirements for light nodes that Waku v1 addressed (<https://vac.dev/fixing-whisper-with-waku>). This means implementing topic-interest in the form of Waku topics. Note that this would be separate from app topics notes above.\\n\\n### 5. Historical message caching\\n\\nBasically what mailservers are currently doing. This likely looks slightly different in a libp2p world. This is another opportunity to simplify things with a basic REQ-RESP architecture, as opposed to the roundabout way things are now. Again, not everything has to be done in one go but there\'s no reason to reimplement a poor API if we don\'t have to.\\n\\nAlso see section below on adaptive nodes and capabilities.\\n\\n### 6. Waku v1 <\\\\> Libp2p bridge\\n\\nTo make the transition complete, there has to a be bridge mode between current Waku and libp2p. This is similar to what was done for Whisper and Waku, and allows any nodes in the network to upgrade to Waku v2 at their leisure. For example, this would likely look different for Core, Desktop, Research and developers.\\n\\n## Track 2 - Better routing\\n\\nThis is where we improve the amplification factors.\\n\\n### 1. GossipSub\\n\\nThis is a subprotocol of FloodSub in the libp2p world. Moving to GossipSub would allow traffic between full nodes to go from an amplification factor of ~25 to ~6. This basically creates a mesh of stable bidirectional connections, together with some gossiping capabilities outside of this view.\\n\\nExplaining how GossipSub works is out of scope of this document. It is implemented in nim-libp2p and used by Nimbus as part of Eth2. You can read the specs here in more detail if you are interested: <https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.0.md> and <https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md>\\n\\n![](/img/waku_v2_routing_gossip_small.png)\\n\\n![](/img/status_scaling_model_fig8.png)\\n![](/img/status_scaling_model_fig9.png)\\n![](/img/status_scaling_model_fig10.png)\\n![](/img/status_scaling_model_fig11.png)\\n\\nWhile we technically could implement this over existing Waku, we\'d have to re-implement it, and we\'d lose out on all the other benefits libp2p would provide, as well as the ecosystem of people and projects working on improving the scalability and security of these protocols.\\n\\n### 2. Topic sharding\\n\\nThis one is slightly more speculative in terms of its ultimate impact. The basic idea is to split the application topic into N shards, say 10, and then each full node can choose which shards to listen to. This can reduce amplification factors by another factor of 10.\\n\\n![](/img/waku_v2_routing_sharding_small.png)\\n\\n![](/img/status_scaling_model_fig12.png)\\n![](/img/status_scaling_model_fig13.png)\\n\\nNote that this means a light node that listens to several topics would have to be connected to more full nodes to get connectivity. For a more exotic version of this, see <https://forum.vac.dev/t/rfc-topic-propagation-extension-to-libp2p-pubsub/47>\\n\\nThis is orthogonal from the choice of FloodSub or GossipSub, but due to GossipSub\'s more dynamic nature it is likely best combined with it.\\n\\n### 3. Other factors\\n\\nNot a primary focus, but worth a look. Looking at the scaling model, there might be other easy wins to improve overall bandwidth consumption between full nodes. For example, can we reduce envelope size by a significant factor?\\n\\n## Track 3 - Accounting and user-run nodes\\n\\nThis is where we make sure the network isn\'t fragile, become a true p2p app, get our users excited and engaged, and allow us to scale the network without creating an even bigger cluster.\\n\\nTo work in practice, this has a soft dependency on node discovery such as DNS based discovery (<https://eips.ethereum.org/EIPS/eip-1459>) or Discovery v5 (<https://vac.dev/feasibility-discv5>).\\n\\n### 1. Adaptive nodes and capabilities\\n\\nWe want to make the gradation between light nodes, full nodes, storing (partial set of) historical messages, only acting for a specific shard, etc more flexible and explicit. This is required to identify and discover the nodes you want. See <https://github.com/vacp2p/specs/issues/87>\\n\\nDepending on how the other tracks come together, this design should allow for a desktop node to identify as a full relaying node for some some app topic shard, but also express waku topic interest and retrieve historical messages itself.\\n\\nE.g. Disc v5 can be used to supply node properties through ENR.\\n\\n### 2. Accounting\\n\\nThis is based on a few principles:\\n\\n1.  Some nodes contribute a lot more than other nodes in the network\\n2.  We can account for the difference in contribution in some fashion\\n3.  We want to incentivize nodes to tell the true, and be incentivized not to lie\\n\\nAccounting here is a stepping stone, where accounting is the raw data upon which some settlement later occurs. It can have various forms of granularity. See <https://forum.vac.dev/t/accounting-for-resources-in-waku-and-beyond/31> for discussion.\\n\\nWe also note that in GossipSub, the mesh is bidrectional. Additionally, it doesn\'t appears to be a high priority issue in terms of nodes misreporting. What is an issue is having people run full nodes in the first place. There are a few points to that. It has to be possible in the end-user UX, nodes have to be discovered, and it has to be profitable/visible that you are contributing. UX and discovery are out of scope for this work, whereas visibility/accounting is part of this scope. Settlement is a stretch goal here.\\n\\nThe general shape of the solution is inspired by the Swarm model, where we do accounting separate from settlement. It doesn\'t require any specific proofs, but nodes are incentivized to tell the truth in the following way:\\n\\n1.  Both full node and light node do accounting in a pairwise, local fashion\\n2.  If a light node doesn\'t ultimately pay or lie about reporting, they get disconnected (e.g.)\\n3.  If a full node doesn\'t provide its service the light node may pick another full node (e.g.)\\n\\nWhile accounting for individual resource usage is useful, for the ultimate end user experience we can ideally account for other things such as:\\n\\n- end to end delivery\\n- online time\\n- completeness of storage\\n\\nThis can be gradually enhanced and strengthened, for example with proofs, consistency checks, Quality of Service, reputation systems. See <https://discuss.status.im/t/network-incentivisation-first-draft/1037> for one attempt to provide stronger guarantees with periodic consistency checks and a shared fund mechanism. And <https://forum.vac.dev/t/incentivized-messaging-using-validity-proofs/51> for using validity proofs and removing liveness requirement for settlement.\\n\\nAll of this is optional at this stage, because our goal here is to improve the status quo for user run nodes. Accounting at this stage should be visible and correspond to the net benefit a node provides to another.\\n\\nAs a concrete example: a light node has some topic interest and cares about historical messages on some topic. A full node communicates envelopes as they come in, communicates their high availability (online time) and stores/forward stored messages. Both nodes have this information, and if they agree settlement (initially just a mock message) can be sending a payment to an address at some time interval / over some defined volume. See future sections for how this can be improved upon.\\n\\nAlso see below in section 4, using constructs such as eigentrust as a local reputation mechanism.\\n\\n### 3. Relax high availability requirement\\n\\nIf we want desktop nodes to participate in the storing of historical messages, high availability is a problem. It is a problem for any node, especially if they lie about it, but assuming they are honest it is still an issue.\\n\\nBy being connected to multiple nodes, we can get an overlapping online window. Then these can be combined together to get consistency. This is obviously experimental and would need to be tested before being deployed, but if it works it\'d be very useful.\\n\\nAdditionally or alternatively, instead of putting a high requirement on message availability, focus on detection of missing information. This likely requires re-thinking how we do data sync / replication.\\n\\n### 4. Incentivize light and full nodes to tell the truth (policy, etc)\\n\\nIn accounting phase it is largely assumed nodes are honest. What happens when they lie, and how do we incentivize them to be honest? In the case of Bittorrent this is done with tit-for-tat, however this is a different kind of relationship. What follows are some examples of how this can be done.\\n\\nFor light nodes:\\n\\n- if they don\'t, they get disconnected\\n- prepayment (especially to \\"high value\\" nodes)\\n\\nFor full nodes:\\n\\n- multiple nodes reporting to agree, where truth becomes a shelling point\\n- use eigentrust\\n- staking for discovery visibility with slashing\\n\\n### 5. Settlement PoC\\n\\nCan be done after phase 2 if so desired. Basically integrate payments based on accounting and policy.\\n\\n## Out of scope\\n\\n1.  We assume the Status Base model requirements are accurate.\\n2.  We assume Core will improve retention rates.\\n3.  We assume the Stimbus production team will enable integration of nim-waku.\\n4.  We assume Discovery mechanisms such as DNS and Discovery v5 will be worked on separately.\\n5.  We assume Core will, at some point, provide an UX for integrating payment of services.\\n6.  We assume the desktop client is sufficiently usable.\\n7.  We assume Core and Infra will investigate ways of improving MaxPeers."},{"id":"feasibility-discv5","metadata":{"permalink":"/rlog/feasibility-discv5","source":"@site/rlog/2020-04-27-feasibility-discv5.mdx","title":"Feasibility Study: Discv5","description":"Looking at discv5 and the theoretical numbers behind finding peers.","date":"2020-04-27T12:00:00.000Z","formattedDate":"April 27, 2020","tags":[],"readingTime":5.655,"hasTruncateMarker":true,"authors":[{"name":"Dean","twitter":"DeanEigenmann","github":"decanus","website":"https://dean.eigenmann.me","key":"dean"}],"frontMatter":{"layout":"post","name":"Feasibility Study: Discv5","title":"Feasibility Study: Discv5","date":"2020-04-27T12:00:00.000Z","authors":"dean","published":true,"slug":"feasibility-discv5","categories":"research","discuss":"https://discuss.status.im/t/discv5-feasibility-study/1632"},"prevItem":{"title":"What\'s the Plan for Waku v2?","permalink":"/rlog/waku-v2-plan"},"nextItem":{"title":"What Would a WeChat Replacement Need?","permalink":"/rlog/wechat-replacement-need"}},"content":"Looking at discv5 and the theoretical numbers behind finding peers.\\n\\n\x3c!--truncate--\x3e\\n\\n> Disclaimer: some of the numbers found in this write-up could be inaccurate. They are based on the current understanding of theoretical parts of the protocol itself by the author and are meant to provide a rough overview rather than bindable numbers.\\n\\nThis post serves as a more authoritative overview of the discv5 study, for a discussionary post providing more context make sure to check out the corresponding [discuss post](https://discuss.status.im/t/discv5-feasibility-study/1632). Additionally, if you are unfamiliar with discv5, check out my previous write-up: [\\"From Kademlia to Discv5\\"](https://vac.dev/kademlia-to-discv5).\\n\\n## Motivating Problem\\n\\nThe discovery method currently used by [Status](https://status.im), is made up of various components and grew over time to solve a mix of problems. We want to simplify this while maintaining some of the properties we currently have.\\n\\nNamely, we want to ensure censorship resistance to state-level adversaries. One of the issues Status had which caused us them add to their discovery method was the fact that addresses from providers like AWS and GCP were blocked both in Russia and China. Additionally, one of the main factors required is the ability to function on resource restricted devices.\\n\\nConsidering we are talking about resource restricted devices, let\'s look at the implications and what we need to consider:\\n\\n- **Battery consumption** - constant connections like websockets consume a lot of battery life.\\n- **CPU usage** - certain discovery methods may be CPU incentive, slowing an app down and making it unusable.\\n- **Bandwidth consumption** - a lot of users will be using data plans, the discovery method needs to be efficient in order to accommodate those users without using up significant portions of their data plans.\\n- **Short connection windows** - the discovery algorithm needs to be low latency, that means it needs to return results fast. This is because many users will only have the app open for a short amount of time.\\n- **Not publicly connectable** - There is a good chance that most resource restricted devices are not publicly connectable.\\n\\nFor a node to be able to participate as both a provider, and a consumer in the discovery method. Meaning a node both reads from other nodes\' stored DHTs and hosts the DHT for other nodes to read from, it needs to be publically connectable. This means another node must be able to connect to some public IP of the given node.\\n\\nWith devices that are behind a NAT, this is easier said than done. Especially mobile devices, that when connected to 4G LTE networks are often stuck behind a symmetric NAT, drastically reducing the the succeess rate of NAT traversal. Keeping this in mind, it becomes obvious that most resource restricted devices will be consumers rather than providers due to this technical limitation.\\n\\nIn order to answer our questions, we formulated the problem with a simple method for testing. The \\"needle in a haystack\\" problem was formulated to figure out how easily a specific node can be found within a given network. This issue was fully formulated in [vacp2p/research#15](https://github.com/vacp2p/research/issues/15).\\n\\n## Overview\\n\\nThe main things we wanted to investigate was the overhead on finding a peer. This means we wanted to look at both the bandwidth, latency and effectiveness of this. There are 2 methods which we can use to find a peer:\\n\\n- We can find a peer with a specific ID, using normal lookup methods as documented by Kademlia.\\n- We can find a peer that advertises a capability, this is possible using either capabilities advertised in the ENR or through [topic tables](https://github.com/ethereum/devp2p/blob/master/discv5/discv5-theory.md#topic-advertisement).\\n\\n## Feasbility\\n\\nTo be able to investigate the feasibility of discv5, we used various methods including rough calculations which can be found in the [notebook](https://vac.dev/discv5-notebook/), and a simulation isolated in [vacp2p/research#19](https://github.com/vacp2p/research/pull/19).\\n\\n### CPU & Memory Usage\\n\\nThe experimental discv5 has already been used within Status, however what was noticed was that the CPU and memory usage was rather high. It therefore should be investiaged if this is still the case, and if it is, it should be isolated where this stems from. Additionally it is worth looking at whether or not this is the case with both the go and nim implementation.\\n\\nSee details: [vacp2p/research#31](https://github.com/vacp2p/research/issues/31)\\n\\n### NAT on Cellular Data\\n\\nIf a peer is not publically connectable it can not participate in the DHT both ways. A lot of mobile phones are behind symmetric NATs which UDP hole-punching close to impossible. It should be investigated whether or not mobile phones will be able to participate both ways and if there are good methods for doing hole-punching.\\n\\nSee details: [vacp2p/research#29](https://github.com/vacp2p/research/issues/29)\\n\\n### Topic Tables\\n\\nTopic Tables allow us the ability to efficiently find nodes given a specific topic. However, they are not implemented in the [status-im/nim-eth](https://github.com/status-im/nim-eth/) implementation nor are they fully finalized in the spec. These are important if the network grows past a size where the concentration of specific nodes is relatively low making them hard to find.\\n\\nSee details: [vacp2p/research#26](https://github.com/vacp2p/research/issues/26)\\n\\n### Finding a node\\n\\nIt is important to note, that given a network is relatively small sized, eg 100-500 nodes, then finding a node given a specific address is relatively managable. Additionally, if the concentration of a specific capability in a network is reasonable, then finding a node advertising its capabilities using an ENR rather than the topic table is also managable. A reasonable concentration for example would be 10%, which would give us an 80% chance of getting a node with that capability in the first lookup request. This can be explored more using our [discv5 notebook](https://vac.dev/discv5-notebook/#Needle-in-a-haystack-with-ENR-records-indicating-capabilities).\\n\\n## Results\\n\\nResearch has shown that finding a node in the DHT has a relatively low effect on bandwidth, both inbound and outbound. For example when trying to find a node in a network of 100 nodes, it would take roughly 5668 bytes total. Additionally if we assume 100ms latency per request it would range at \u2248 300ms latency, translating to 3 requests to find a specific node.\\n\\n## General Thoughts\\n\\nOne of the main blockers right now is figuring out what the CPU and memory usage of discv5 is on mobile phones, this is a large blocker as it affects one of the core problems for us. We need to consider whether discv5 is an upgrade as it allows us to simplify our current discovery process or if it is too much of an overhead for resource restricted devices. The topic table feature could largely enhance discovery however it is not yet implemented. Given that CPU and memory isn\'t too high, discv5 could probably be used as the other issues are more \\"features\\" than large scale issues. Implementing it would already reduce the ability for state level adversaries to censor our nodes.\\n\\n## Acknowledgements\\n\\n- Oskar Thoren\\n- Dmitry Shmatko\\n- Kim De Mey\\n- Corey Petty"},{"id":"wechat-replacement-need","metadata":{"permalink":"/rlog/wechat-replacement-need","source":"@site/rlog/2020-04-16-wechat-replacement-need.mdx","title":"What Would a WeChat Replacement Need?","description":"What would a self-sovereign, private, censorship-resistant and open alternative to WeChat look like?","date":"2020-04-16T12:00:00.000Z","formattedDate":"April 16, 2020","tags":[],"readingTime":25.24,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"What Would a WeChat Replacement Need?","title":"What Would a WeChat Replacement Need?","date":"2020-04-16T12:00:00.000Z","authors":"oskarth","published":true,"slug":"wechat-replacement-need","categories":"research","image":"/img/tianstatue.jpg","discuss":"https://forum.vac.dev/t/discussion-what-would-a-wechat-replacement-need/42"},"prevItem":{"title":"Feasibility Study: Discv5","permalink":"/rlog/feasibility-discv5"},"nextItem":{"title":"From Kademlia to Discv5","permalink":"/rlog/kademlia-to-discv5"}},"content":"What would a self-sovereign, private, censorship-resistant and open alternative to WeChat look like?\\n\\n\x3c!--truncate--\x3e\\n\\nWhat would it take to replace WeChat? More specifically, what would a self-sovereign, private, censorship-resistant and open alternative look like? One that allows people to communicate, coordinate and transact freely.\\n\\n## Background\\n\\n### What WeChat provides to the end-user\\n\\nLet\'s first look at some of the things that WeChat providers. It is a lot:\\n\\n- **Messaging:** 1:1 and group chat. Text, as well as voice and video. Post gifs. Share location.\\n- **Group chat:** Limited to 500 people; above 100 people people need to verify with a bank account. Also has group video chat and QR code to join a group.\\n- **Timeline/Moments:** Post comments with attachments and have people like/comment on it.\\n- **Location Discovery:** See WeChat users that are nearby.\\n- **Profile:** Nickname and profile picture; can alias people.\\n- **\\"Broadcast\\" messages:** Send one message to many contacts, up to 200 people (spam limited).\\n- **Contacts:** Max 5000 contacts (people get around it with multiple accounts and sim cards).\\n- **App reach:** Many diferent web apps, extensions, native apps, etc. Scan QR code to access web app from phone.\\n- **Selective posting:** Decide who can view your posts and who can view your comments on other people\'s post.\\n- **Transact:** Send money gifts through red envelopes.\\n- **Transact:** Use WeChat pay to transfer money to friends and businesses; linked account with Alipay that is connected to your bank account.\\n- **Services:** Find taxis and get notifications; book flights, train tickets, hotels etc.\\n- **Mini apps:** API for all kinds of apps that allow you to provide services etc.\\n- **Picture in picture:** allowing you to have a video call while using the app.\\n\\nAnd much more. Not going to through it all in detail, and there are probably many things I don\'t know about WeChat since I\'m not a heavy user living in mainland China.\\n\\n### How WeChat works - a toy model\\n\\nThis is an overly simplistic model of how WeChat works, but it is sufficient for our purposes. This general design applies to most traditional client-server apps today.\\n\\nTo sign up for account you need a phone number or equivalent. To get access to some features you need to verify your identity further, for example with official ID and/or bank account.\\n\\nWhen you signup this creates an entry in the WeChat server, from now on treated as a black box. You authenticate with that box, and thats where you get your messages from. If you go online the app asks that box for messages you have received while you were offline. If you login from a different app your contacts and conversations are synced from that box.\\n\\nThe box gives you an account, it deals with routing to your contacts, it stores messages and attachments and gives access to mini apps that people have uploaded. For transacting money, there is a partnership with a different company that has a different box which talks to your bank account.\\n\\nThis is done in a such a way that they can support a billion users with the features above, no sweat.\\n\\nWhoever controls that box can sees who you are talking with and what the content of those messages are. There is no end to end encryption. If WeChat/Tencent disagrees with you for some reason they can ban you. This means you can\'t interact with the box under that name anymore.\\n\\n## What do we want?\\n\\nWe want something that is self-sovereign, private, censorship-resistant and open that allows individuals and groups of people to communicate and transact freely. To explore what this means in more detail, without getting lost in the weeds, we provide the following list of properties. A lot of these are tied together, and some fall out of the other requirements. Some of them stand in slight opposition to each other.\\n\\n**Self-sovereignity identity**. Exercises authority within your own sphere. If you aren\'t harming anyone, you should be able to have an account and communicate with other people.\\n\\n**Pseudonymity, and ideally total anonymity**. Not having your identity tied to your real name (e.g. through phone number, bank account, ID, etc). This allows people to act more freely without being overly worried about censorship and coercion in the real world. While total anonymity is even more desirable - especially to break multiple hops to a true-name action - real-world constraints sometimes makes this more challenging.\\n\\n**Private and secure communication**. Your communication and who you transact with should be for your eyes only. This includes transactions (transfer of value) as a form of communication.\\n\\n**Censorship-resistance**. Not being able to easily censor individuals on the platform. Both at an individual, group and collective level. Not having single points of failure that allow service to be disrupted.\\n\\n**Decentralization**. Partly falls out of censorship-resistance and other properties. If infrastructure isn\'t decentralized it means there\'s a single point of failure that can be disrupted. This is more of a tool than a goal on its own, but it is an important tool.\\n\\n**Built for mass adoption**. Includes scalabiltiy, UX (latency, reliability, bandwidth consumption, UI etc), and allowing for people to stick around. One way of doing this is to allow users to discover people they want to talk to.\\n\\n**Scalability**. Infrastructure needs to support a lot of users to be a viabile alternative. Like, a billion of them (eventually).\\n\\n**Fundamentals in place to support great user experience**. To be a viable alternative, aside from good UI and distribution, fundamentals such as latency, bandwidth usage, consistency etc must support great UX to be a viable alternative.\\n\\n**Works for resource restricted devices, including smartphones**. Most people will use a smartphone to use this. This means it has to work well on them and similar devices, without becoming a second-class citizen where we ignore properties such as censorship-resistance and privacy. Some concession to reality will be necessary due to additional constraints, which leads us to...\\n\\n**Adaptive nodes**. Nodes will have different capabilities, and perhaps at different times. To maintain a lot of the properties described here it is desirable if as many participants as possible are first-class citizens. If a phone is switching from a limited data plan to a WiFi network or from battery to AC power it can do more useful work, and so on. Likewise for a laptop with a lot of free disk space and spare compute power, etc.\\n\\n**Sustainable**. If there\'s no centralized, top down ad-driven model, this means all the infrastructure has to be sustainable somehow. Since these are individual entitites, this means it has to be paid for. While altruistic modes and similar can be used, this likely requires some form of incentivization scheme for useful services provided in the network. Related: free rider problem.\\n\\n**Spam resistant**. Relates to sustainability, scalability and built for mass adoption. Made more difficult by pseudonymous identity due to whitewashing attacks.\\n\\n**Trust-minimized**. To know that properties are provided for and aren\'t compromised, various ways of minimizing trust requirements are useful. This also related to mass adoption and social cohesion. Examples include: open and audited protocols, open source, reproducible builds, etc. This also relates to how mini apps are provided for, since we may not know their source but want to be able to use them anyway.\\n\\n**Open source**. Related to above, where we must be able to inspect the software to know that it functions as advertised and hasn\'t been compromised, e.g. by uploading private data to a third party.\\n\\nSome of these are graded and a bit subtle, i.e.:\\n\\n- Censorship resistance would ideally be able to absorb Internet shutdowns. This would require an extensive MANET/meshnet infrastructure, which while desirable, requires a lot of challenges to be overcome to be feasible.\\n- Privacy would ideally make all actions (optionally) totally anoymous, though this may incur undue costs on bandwidth and latency, which impacts user experience.\\n- Decentralization, certain topologies, such as DHTs, are efficient and quite decentralized but still have some centralized aspects, which makes it attackable in various ways. Ditto for blockchains compared with bearer instruments which requires some coordinating infrastructure, compared with naturally occuring assets such as precious metals.\\n- \\"Discover people\\" and striving for \\"total anonymity\\" might initially seem incompatible. The idea is to provide for sane defaults, and then allow people to decide how much information they want to disclose. This is the essence of privacy.\\n- Users often want _some_ form of moderation to get a good user experience, which can be seen as a form of censorship. The idea to raise the bar on the basics, the fundamental infrastructure. If individuals or specific communities want certain moderation mechanisms, that is still a compatible requirement.\\n\\n### Counterpoint 1\\n\\nWe could refute the above by saying that the design goals are undesirable. We want a system where people can censor others, and where everyone is tied to their real identity. Or we could say something like, freedom of speech is a general concept, and it doesn\'t apply to Internet companies, even if they provide a vital service. You can survive without it and you should\'ve read the terms of service. This roughly charactericizes the mainstream view.\\n\\nAdditional factor here is the idea that a group of people know more about what\'s good for you then you do, so they are protecting you.\\n\\n### Counterpoint 2\\n\\nWe could agree with all these design goals, but think they are too extreme in terms of their requirements. For example, we could operate as a non profit, take donations and volunteers, and then host the whole infrastructure ourselves. We could say we are in a friendly legislation, so we won\'t be a single point of failure. Since we are working on this and maybe even our designs are open, you can trust us and we\'ll provide service and infrastructure that gives you what you want without having to pay for it or solve all these complex decentralized computation and so on problems. If you don\'t trust us for some reason, you shouldn\'t use us regardless. Also, this is better than status quo. And we are more likely to survive by doing this, either by taking shortcuts or by being less ambituous in terms of scope.\\n\\n## Principal components\\n\\nThere are many ways to skin a cat, but this is one way of breaking down the problem. We have a general direction with the properties listed above, together with some understanding of how WeChat works for the everday user. Now the question is, what infrastructure do we need to support this? How do we achieve the above properties, or at least get closer to them? We want to figure out the necessary building blocks, and one of doing this is to map out likely necessary components.\\n\\n### Background: Ethereum and Web3 stack\\n\\nIt is worth noting that a lot of the required infrastructure has been developed, at least as concepts, in the original Ethereum / Web3 vision. In it there is Ethereum for consensus/compute/transact, storage through Swarm, and communication through Whisper. That said, the main focus has been on the Ethereum blockchain itself, and a lot of things have happened in the last 5y+ with respect to technology around privacy and scalabilty. It is worth revisiting things from a fresh point of view, with the WeChat alternative in mind as a clear use case.\\n\\n### Account - self-sovereign identity and the perils of phone numbers\\n\\nStarting from the most basic: what is an account and how do you get one? With most internet services today, WeChat and almost all popular messaging apps included, you need to signup with some centralized authority. Usually you also have to verify this with some data that ties this account to you as an individual. E.g. by requiring a phone number, which in most jurisdictions [^1] means giving out your real ID. This also means you can be banned from using the service by a somewhat arbitrary process, with no due process.\\n\\nNow, we could argue these app providers can do what they want. And they are right, in a very narrow sense. As apps like WeChat (and Google) become general-purpose platforms, they become more and more ingrained in our everyday lives. They start to provide utilities that we absolutely require to work to go about our day, such as paying for food or transportation. This means we need higher standard than this.\\n\\nJustifications for requiring phone numbers are usually centered around three claims:\\n\\n1. Avoiding spam\\n2. Tying your account to your real name, for various reasons\\n3. Using as a commonly shared identifier as a social network discovery mechanism\\n\\nOf course, many services require more than phone numbers. E.g. email, other forms of personal data such as voice recording, linking a bank account, and so on.\\n\\nIn contrast, a self-sovereign system would allow you to \\"create an account\\" completely on your own. This can easily be done with public key cryptograpy, and it also paves the way for end-to-end encryption to make your messages private.\\n\\nThe main issue with this that you need to get more creative about avoiding spam (e.g. through white washing attacks), and ideally there is some other form of social discovery mechanism.\\n\\nJust having a public key as an account isn\'t enough though. If it goes through a central server, then nothing is stopping that server from arbitrarly blocking requests related to that public key. Of course, this also depends on how transparent such requests are. Fundamentally, lest we rely completely on goodwill, there needs to be multiple actors by which you can use the service. This naturally points to decentralization as a requirement. See counterpoint.\\n\\nEven so, if the system is closed source we don\'t know what it is doing. Perhaps the app communicating is also uploading data to another place, or somehow making it possible to see who is who and act accordingly.\\n\\nYou might notice that just one simple property, self-sovereign identity, leads to a slew of other requirements and properties. You might also notice that WeChat is far from alone in this, even if their identity requirements might be a bit stringent than, say, Telegram. Their control aspects are also a bit more extreme, at least for someone with western sensibilities [^2].\\n\\nMost user facing applications have similar issues, Google Apps/FB/Twitter etc. For popular tools that have this built in, we can look at git - which is truly decentralized and have keypair at the bottom. It is for a very specific technical domain, and even then people rely on Github. Key management is fairly difficult even for technical people, and for normal people even more so. Banks are generally far behind on this tech, relying on arcane procedures and special purpose hardware for 2FA. That\'s another big issue.\\n\\nLet\'s shift gears a bit and talk about some other functional requirements.\\n\\n### Routing - packets from A to B\\n\\nIn order to get a lot of the features WeChat provides, we need the ability to do three things: communicate, store data, and transact with people. We need a bit more than that, but let\'s focus on this for now.\\n\\nTo communicate with people, in the base case, we need to go from one phone to another phone that is separated by a large distance. This requires some form of routing. The most natural platform to build this on is the existing Internet, though not the only one. Most phones are resource restricted, and are only \\"on\\" for brief periods of time. This is needed to preserve battery and bandwidth. Additionally, Internet uses IPs as endpoints, which change as a phones move through space. NAT punching etc isn\'t always perfect either. This means we need a way to get a message from one public key to another, and through some intermediate nodes. We can think of these nodes as a form of service network. Similar to how a power grid works, or phone lines, or collection of ISPs.\\n\\nOne important property here is to ensure we don\'t end up in a situation like the centralized capture scenario above, something we\'ve seen with centralized ISPs [^3] [^4] where they can choose which traffic is good and which is bad. We want to allow the use of different service nodes, just like if a restaurant gives you food poisioning you can go to the one next door and then the first one goes out of business after a while. And the circle of life continues.\\n\\nWe shouldn\'t be naive though, and think that this is something nodes are likely to do for free. They need to be adequately compensated for their services, in some of incentivization scheme. That can either be monetary, or as in the case of Bittorrent, more of a barter situation where you use game theory to coordinate with strangers [^5], and some form of reputation attached to it (for private trackers).\\n\\nThere are many ways of doing routing, and we won\'t go into too much technical detail here. Suffice to say is that you likely want both a structured and unstructured alternative, and that these comes with several trade-offs when it comes to efficiency, metadata protection, ability to incentivize, compatibility with existing topologies, and suitability for mobilephones (mostly offline, bandwidth restricted, not directly connectable). Expect more on this in a future article.\\n\\nSome of these considerations naturally leads us into the storage and transaction components.\\n\\n### Storage - available and persistant for later\\n\\nIf mobile phones are mostly offline, we need some way to store these messages so they can be retrieved when online again. The same goes for various kinds attachments as well, and for when people are switching devices. A user might control their timeline, but in the WeChat case that timeline is stored on Tencent\'s servers, and queried from there as well. This naturally needs to happen by some other service nodes. In the WeChat case, and for most IMs, the way these servers are paid for is through some indirect ad mechanism. The entity controlling these ads and so on is the same one as the one operating the servers for storage. A more direct model with different entities would see these services being compensated for their work.\\n\\nWe also need storage for attachments, mini-apps, as well as a way of understanding the current state of consensus when it comes to the compute/transact module. In the WeChat case, this state is completely handled by the bank institution or one of their partners, such as Alibaba. When it comes to bearer instruments like cash, no state needs to be kept as that\'s a direct exchange in the physical world. This isn\'t directly compatible with transfering value over a distance.\\n\\nAll of this state requires availability and persistance. It should be done in a trust minimized fashion and decentralized, which requires some form of incentivization for keeping data around. If it isn\'t, you are relying on social cohesion which breaks down at very large scales.\\n\\nSince data will be spread out across multiple nodes, you need a way to sync data and transfer it in the network. As well as being able to add and query data from it. All of this requires a routing component.\\n\\nTo make it more censorship resistant it might be better to keep it as a general-purpose store, i.e. individuals don\'t need to know what they storing. Otherwise, you naturally end up in a situation where individual nodes can be pressured to not store certain content.\\n\\n### Messaging - from me to you to all of us (not them)\\n\\nThis builds on top of routing, but it has a slightly different focus. The goal is to allow for individuals and groups to communicate in a private, secure and censorship-resistant manner.\\n\\nIt also needs to provide a decent interface to the end user, in terms of dealing seamlessly with offline messages, providing reliable and timely messaging.\\n\\nIn order to get closer to the ideal of total anonymity, it is useful to be able to hide metadata of who is talking to whom. This applies to both normal communication as well as for transactions. Ideally, no one but the parties involved can see who is taking part in a conversation. This can be achieved through various techniques such as mixnets, anonymous credentials, private information retrieval, and so on. Many of these techniques have a fundamental trade-off with latency and bandwidth, something that is a big concern for mobilephones. Being able to do some form of tuning, in an adaptive node manner, depending on your threat model and current capabilities is useful here.\\n\\nThe baseline here is pseudonymity, and having tools to allow individuals to \\"cut off\\" ties to their real world identity and transactions. People act different in different circles in the real world, and this should be mimicked online as well. Your company, family or government shouldn\'t be able to know what exactly you use your paycheck for, and who you are talking to.\\n\\n### Compute - transact, contract and settle\\n\\nThe most immediate need here is transaction from A to B. Direct exchange. There is also a more indirect need for private lawmaking and contracting.\\n\\nWe talked about routing and storage and how they likely need to be incentivized to work properly. How are they going to be compensated? While this could in theory work via existing banking system and so on, this would be rather heavy. It\'d also very likely require tying your identifier to your legal name, something that goes against what we want to achieve. What we want is something that acts more as right-to-access, similar to the way cash functions in a society [^6]. I pay for a fruit with something that is valuable to you and then I\'m on my way.\\n\\nWhile there might be other candidates, such as pre-paid debit cards and so on, this transaction mode pretty much requires a cryptocurrency component. The alternative is to do it on a reputation basis, which might work for small communities, due to social cohesion, but quickly detoriates for large ones [^7]. Ad hoc models like private Bittorrent trackers are centralized and easy to censor.\\n\\nNow, none of the existing cryptocurrency models are ideal. They also all suffer from lack of widespread use, and it is difficult to get onboarded to them in the first place. Transactions in Bitcoin are slow. Ethereum is faster and has more capabilities, but it still suffers from linking payments over time, which makes the privacy part of this more difficult. Zcash, Monero and similar are interesting, but also require more use. For Zcash, shielded transactions appear to only account for less than 2% of all transactions in 2019 [^8] [^9].\\n\\nAnother dimension is what sets general purpose cryptocurrencies like Ethereum apart. Aside from just paying from A to B, you can encode rules about when something should be paid out and not. This is very useful for doing a form of private lawmaking, contracting, for setting up service agreements with these nodes. If there\'s no trivial recourse as in the meatspace world, where you know someone\'s name and you can sue them, you need a different kind of model.\\n\\nWhat makes something like Zcash interesting is that it works more like digital cash. Instead of leaving a public trail for everyone, where someone can see where you got the initial money from and then trace you across various usage, for Zcash every hop is privacy preserving.\\n\\nTo fulfill the general goals of being censorship resistance and secure, it is also vital that the system being used stays online and can\'t be easily disrupted. That points to disintermediation, as opposed to using gateways and exchanges. This is a case where something like cash, or gold, is more direct, since no one can censor this transaction without being physically present where this direct exchange is taking place. However, like before, this doesn\'t work over distance.\\n\\n### Secure chat - just our business\\n\\nSimilar to the messaging module above. The distinction here is that we assume the network part has already taken place. Here we are interested in keeping the contents of messages private, so that means confidentiality/end-to-end encryption, integrity, authentication, as well as forward secrecy and plausible deniability. This means that even if there\'s some actor that gets some private key material, or confiscated your phone, there is some level of...ephemerality to your conversations. Another issue here in terms of scalable private group chat.\\n\\n### Extensible mini apps\\n\\nThis relates to the compute and storage module above. Essentially we want to provide mini apps as in WeChat, but to do so in a way that is compatible with what we want to achieve more generally. This allows individuals and small businesses to create small tools for various purposes, and coordinate with strangers. E.g. booking a cab or getting an insurance, and so on.\\n\\nThis has a higher dependency on the contracting/general computation aspect. I.e. often it isn\'t only a transaction, but you might want to encode some specific rules here that strangers can abide by without having too high trust requirements. As a simple example: escrows.\\n\\nThis also needs an open API that anyone can use. It should be properly secured, so using one doesn\'t compromise the rest of the system it is operating in. To be censorship resistant it requires the routing and storage component to work properly.\\n\\n## Where are we now?\\n\\nLet\'s look back at some of desirable properties we set out in the beginning and see how close we are to building out the necessary components. Is it realistic at all or just a pipe dream? We\'ll see that there are many building blocks in place, and there\'s reason for hope.\\n\\n**Self-sovereignity identity**. Public key crypto and web of trust like constructs makes this possible.\\n\\n**Pseudonymity, and ideally total anonymity**. Pseudonymity can largely be achieved with public key crypto and open systems that allow for permissionless participation. For transactions, pseudonymity exists in most cryptocurrencies. The challenge is linkage across time, especially when interfacing with other \\"legacy\\" system. There are stronger constructs that are actively being worked on and are promising here, such as mixnets (Nym), mixers (Wasabi Wallet, Tornado.Cash) and zero knowledge proofs (Zcash, Ethereum, Starkware). This area of applied research has exploded over the last few years.\\n\\n**Private and secure communication**. Signal has pioneered a lot of this, following OTR. Double Ratchet, X3DH. E2EE is minimum these days, and properties like PFS and PD are getting better. For metadata protection, you have Tor, with its faults, and more active research on mixnets and private information retrieval, etc.\\n\\n**Censorship-resistance**. This covers a lot of ground across the spectrum. You have technologies like Bittorrent, Bitcoin/Ethereum, Tor obfuscated transports, E2EE by default, partial mesh networks in production, abilit to move/replicate host machines more quickly have all made this more of a reality than it used to be. this easier. Of course, techniques such as deep packet inspection and internet shutdowns have increased.\\n\\n**Decentralization**. Cryptocurrencies, projects like libp2p and IPFS. Need to be mindful here of many projects that claim decentralization but are still vulnerable to single points of failures, such as relying on gateways.\\n\\n**Built for mass adoption**. This one is more subjective. There\'s definitely a lot of work to be done here, both when it comes to fundamental performance, key management and things like social discoverability. Directionally these things are improving and becoming easier for the average person but there is a lot ot be done here.\\n\\n**Scalability**. With projects like Ethereum 2.0 and IPFS more and more resources are a being put into this, both at the consensus/compute layer as well as networking (gossip, scalable Kademlia) layer. Also various layer 2 solutions for transactions.\\n\\n**Fundamentals in place to support great user experience**. Similar to built for mass adoption. As scalability becomes more important, more applied research is being done in the p2p area to improve things like latency, bandwidth.\\n\\n**Works for resource restricted devices, including smartphones**. Work in progress and not enough focus here, generally an after thought. Also have stateless clients etc.\\n\\n**Adaptive nodes**. See above. With subprotocols and capabilities in Ethereum and libp2p, this is getting easier.\\n\\n**Sustainable**. Token economics is a thing. While a lot of it won\'t stay around, there are many more projects working on making themselves dispensable. Being open source, having an engaged community and enabling users run their own infrastructure. Users as stakeholders.\\n\\n**Spam resistant**. Tricky problem if you want to be pseudonymous, but some signs of hope with incentivization mechanisms, zero knowledge based signaling, etc. Together with various forms of rate limiting and better controlling of topology and network amplification. And just generally being battle-tested by real world attacks, such as historical Ethereum DDoS attacks.\\n\\n**Trust minimized**. Bitcoin. Zero knowledge provable computation. Open source. Reproducible builds. Signed binaries. Incentive compatible structures. Independent audits. Still a lot of work, but getting better.\\n\\n**Open source**. Big and only getting bigger. Including mainstream companies.\\n\\n## What\'s next?\\n\\nWe\'ve look at what WeChat provides and what we\'d like an alternative to look like. We\'ve also seen a few principal modules that are necessary to achieve those goals. To achieve all of this is a daunting task, and one might call it overly ambitiuous. We\'ve also seen how far we\'ve come with some of the goals, and how a lot of the pieces are there, in one form or another. Then it is a question of putting them all together in the right mix.\\n\\nThe good news is that a lot of people are working all these building blocks and thinking about these problems. Compared to a few years ago we\'ve come quite far when it comes to p2p infrastructure, privacy, security, scalability, and general developer mass and mindshare. If you want to join us in building some of these building blocks, and assembling them, check out our forum.\\n\\nPS. We are [hiring protocol engineers](https://status.im/our_team/open_positions.html). DS\\n\\n## Acknowledgements\\n\\nCorey, Dean, Jacek.\\n\\n## References\\n\\n[^1]: Mandatory SIM card registration laws: https://privacyinternational.org/long-read/3018/timeline-sim-card-registration-laws\\n[^2]: On WeChat keyword censorship: https://citizenlab.ca/2016/11/wechat-china-censorship-one-app-two-systems/\\n[^3]: Net Neutrality: https://www.eff.org/issues/net-neutrality\\n[^4]: ISP centralization: https://ilsr.org/repealing-net-neutrality-puts-177-million-americans-at-risk/\\n[^5]: Incentives Build Robustness in BitTorrent bittorrent.org/bittorrentecon.pdf\\n[^6]: The Case for Electronic Cash: https://coincenter.org/files/2019-02/the-case-for-electronic-cash-coin-center.pdf\\n[^7]: Money, blockchains, and social scalability: http://unenumerated.blogspot.com/2017/02/money-blockchains-and-social-scalability.html\\n[^8]: Zcash private transactions (partial paywall): https://www.theblockcrypto.com/genesis/48413/an-analysis-of-zcashs-private-transactions\\n[^9]: Shielded transactions usage (stats page 404s): https://z.cash/support/faq/"},{"id":"kademlia-to-discv5","metadata":{"permalink":"/rlog/kademlia-to-discv5","source":"@site/rlog/2020-04-9-kademlia-to-discv5.mdx","title":"From Kademlia to Discv5","description":"A quick history of discovery in peer-to-peer networks, along with a look into discv4 and discv5, detailing what they are, how they work and where they differ.","date":"2020-04-09T16:00:00.000Z","formattedDate":"April 9, 2020","tags":[],"readingTime":8.045,"hasTruncateMarker":true,"authors":[{"name":"Dean","twitter":"DeanEigenmann","github":"decanus","website":"https://dean.eigenmann.me","key":"dean"}],"frontMatter":{"layout":"post","name":"From Kademlia to Discv5","title":"From Kademlia to Discv5","date":"2020-04-09T16:00:00.000Z","authors":"dean","published":true,"slug":"kademlia-to-discv5","categories":"research"},"prevItem":{"title":"What Would a WeChat Replacement Need?","permalink":"/rlog/wechat-replacement-need"},"nextItem":{"title":"Waku Update","permalink":"/rlog/waku-update"}},"content":"A quick history of discovery in peer-to-peer networks, along with a look into discv4 and discv5, detailing what they are, how they work and where they differ.\\n\\n\x3c!--truncate--\x3e\\n\\nIf you\'ve been working on Ethereum or adjacent technologies you\'ve probably heard of [discv4](https://github.com/ethereum/devp2p/blob/master/discv4.md) or [discv5](https://github.com/ethereum/devp2p/blob/master/discv5/discv5.md). But what are they actually? How do they work and what makes them different? To answer these questions, we need to start at the beginning, so this post will assume that there is little knowledge on the subject so the post should be accessible for anyone.\\n\\n## The Beginning\\n\\nLet\'s start right at the beginning: the problem of discovery and organization of nodes in peer-to-peer networks.\\n\\nEarly P2P file sharing technologies, such as Napster, would share information about who holds what file using a single server. A node would connect to the central server and give it a list of the files it owns. Another node would then connect to that central server, find a node that has the file it is looking for and contact that node. This however was a flawed system -- it was vulnerable to attacks and left a single party open to lawsuits.\\n\\nIt became clear that another solution was needed, and after years of research and experimentation, we were given the distributed hash table or DHT.\\n\\n## Distributed Hash Tables\\n\\nIn 2001 4 new protocols for such DHTs were conceived, [Tapestry](https://pdos.csail.mit.edu/~strib/docs/tapestry/tapestry_jsac03.pdf), [Chord](https://pdos.csail.mit.edu/papers/chord:sigcomm01/chord_sigcomm.pdf), [CAN](https://people.eecs.berkeley.edu/~sylvia/papers/cans.pdf) and [Pastry](http://rowstron.azurewebsites.net/PAST/pastry.pdf), all of which made various trade-offs and changes in their core functionality, giving them unique characteristics.\\n\\nBut as said, they\'re all DHTs. So what is a DHT?\\n\\nA distributed hash table (DHT) is essentially a distributed key-value list. Nodes participating in the DHT can easily retrieve the value for a key.\\n\\nIf we have a network with 9 key-value pairs and 3 nodes, ideally each node would store 3 (optimally 6 for redundancy) of those key-value pairs, meaning that if a key-value pair were to be updated, only part of the network would responsible for ensuring that it is. The idea is that any node in the network would know where to find the specific key-value pair it is looking for based on how things are distributed amongst the nodes.\\n\\n## Kademlia\\n\\nSo now that we know what DHTs are, let\'s get to Kademlia, the predecessor of discv4. Kademlia was created by Petar Maymounkov and David Mazi\xe8res in 2002. I will naively say that this is probably one of the most popular and most used DHT protocols. It\'s quite simple in how it works, so let\'s look at it.\\n\\nIn Kademlia, nodes and values are arranged by distance (in a very mathematical definition). This distance is not a geographical one, but rather based on identifiers. It is calculated how far 2 identifiers are from eachother using some distance function.\\n\\nKademlia uses an `XOR` as its distance function. An `XOR` is a function that outputs `true` only when inputs differ. Here is an example with some binary identifiers:\\n\\n```\\nXOR 10011001\\n    00110010\\n    --------\\n    10101011\\n```\\n\\nThe top in decimal numbers means that the distance between `153` and `50` is `171`.\\n\\nThere are several reasons why `XOR` was taken:\\n\\n1.  The distance from one ID to itself will be `0`.\\n2.  Distance is symmetric, A to B is the same as B to A.\\n3.  Follows triangle inequality, if `A`, `B` and `C` are points on a triangle then the distance `A` to `B` is closer or equal to that of `A` to `C` plus the one from `B` to `C`.\\n\\nIn summary, this distance function allows a node to decide what is \\"close\\" to it and make decisions based on that \\"closeness\\".\\n\\nKademlia nodes store a routing table. This table contains multiple lists. Each subsequent list contains nodes which are a little further distanced than the ones included in the previous list. Nodes maintain detailed knowledge about nodes closest to them, and the further away a node is, the less knowledge the node maintains about it.\\n\\nSo let\'s say I want to find a specific node. What I would do is go to any node which I already know and ask them for all their neighbours closest to my target. I repeat this process for the returned neighbours until I find my target.\\n\\nThe same thing happens for values. Values have a certain distance from nodes and their IDs are structured the same way so we can calculate this distance. If I want to find a value, I simply look for the neighbours closest to that value\'s key until I find the one storing said value.\\n\\nFor Kademlia nodes to support these functions, there are several messages with which the protocol communicates.\\n\\n- `PING` - Used to check whether a node is still running.\\n- `STORE` - Stores a value with a given key on a node.\\n- `FINDNODE` - Returns the closest nodes requested to a given ID.\\n- `FINDVALUE` - The same as `FINDNODE`, except if a node stores the specific value it will return it directly.\\n\\n_This is a **very** simplified explanation of Kademlia and skips various important details. For the full description, make sure to check out the [paper](https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf) or a more in-depth [design specification](http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html)_\\n\\n## Discv4\\n\\nNow after that history lesson, we finally get to discv4 (which stands for discovery v4), Ethereum\'s current node discovery protocol. The protocol itself is essentially based off of Kademlia, however it does away with certain aspects of it. For example, it does away with any usage of the value part of the DHT.\\n\\nKademlia is mainly used for the organisation of the network, so we only use the routing table to locate other nodes. Due to the fact that discv4 doesn\'t use the value portion of the DHT at all, we can throw away the `FINDVALUE` and `STORE` commands described by Kademlia.\\n\\nThe lookup method previously described by Kademlia describes how a node gets its peers. A node contacts some node and asks it for the nodes closest to itself. It does so until it can no longer find any new nodes.\\n\\nAdditionally, discv4 adds mutual endpoint verification. This is meant to ensure that a peer calling `FINDNODE` also participates in the discovery protocol.\\n\\nFinally, all discv4 nodes are expected to maintain up-to-date ENR records. These contain information about a node. They can be requested from any node using a discv4-specific packet called `ENRRequest`.\\n\\n_If you want some more details on ENRs, check out one of my posts [\\"Network Addresses in Ethereum\\"](https://dean.eigenmann.me/blog/2020/01/21/network-addresses-in-ethereum/)_\\n\\nDiscv4 comes with its own range of problems however. Let\'s look at a few of them.\\n\\nFirstly, the way discv4 works right now, there is no way to differentiate between node sub-protocols. This means for example that an Ethereum node could add an Ethereum Classic Node, Swarm or Whisper node to its DHT without realizing that it is invalid until more communication has happened. This inability to differentiate sub-protocols makes it harder to find specific nodes, such as Ethereum nodes with light-client support.\\n\\nNext, in order to prevent replay attacks, discv4 uses timestamps. This however can lead to various issues when a host\'s clock is wrong. For more details, see the [\\"Known Issues\\"](https://github.com/ethereum/devp2p/blob/master/discv4.md#known-issues-in-the-current-version) section of the discv4 specification.\\n\\nFinally, we have an issue with the way mutual endpoint verification works. Messages can get dropped and there is no way to tell if both peers have verified eachother. This means that we could consider our peer verified while it does not consider us so making them drop the `FINDNODE` packet.\\n\\n## Discv5\\n\\nFinally, let\'s look at discv5. The next iteration of discv4 and the discovery protocol which will be used by Eth 2.0. It aims at fixing various issues present in discv4.\\n\\nThe first change is the way `FINDNODE` works. In traditional Kademlia as well as in discv5, we pass an identifier. However, in discv5 we instead pass the logarithmic distance, meaning that a `FINDNODE` request gets a response containing all nodes at the specified logarithmic distance from the called node.\\n\\nLogarithmic distance means we first calculate the distance and then run it through our log base 2 function. See:\\n\\n```\\nlog2(A xor B)\\n```\\n\\nAnd the second, more important change, is that discv5 aims at solving one of the biggest issues of discv4: the differentiation of sub-protocols. It does this by adding topic tables. Topic tables are [first in first out](<https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)>) lists that contain nodes which have advertised that they provide a specific service. Nodes get themselves added to this list by registering `ads` on their peers.\\n\\nAs of writing, there is still an issue with this proposal. There is currently no efficient way for a node to place `ads` on multiple peers, since it would require separate requests for every peer which is inefficient in a large-scale network.\\n\\nAdditionally, it is unclear how many peers a node should place these `ads` on and exactly which peers to place them on. For more details, check out the issue [devp2p#136](https://github.com/ethereum/devp2p/issues/136).\\n\\nThere are a bunch more smaller changes to the protocol, but they are less important hence they were ommitted from this summary.\\n\\nNevertheless, discv5 still does not resolve a couple issues present in discv4, such as unreliable endpoint verification. As of writing this post, there is currently no new method in discv5 to improve the endpoint verification process.\\n\\nAs you can see discv5 is still a work in progress and has a few large challenges to overcome. However if it does, it will most likely be a large improvement to a more naive Kademlia implementations.\\n\\n---\\n\\nHopefully this article helped explain what these discovery protocols are and how they work. If you\'re interested in their full specifications you can find them on [github](https://github.com/ethereum/devp2p)."},{"id":"waku-update","metadata":{"permalink":"/rlog/waku-update","source":"@site/rlog/2020-02-14-waku-update.mdx","title":"Waku Update","description":"A research log. What\'s the current state of Waku? How many users does it support? What are the bottlenecks? What\'s next?","date":"2020-02-14T12:00:00.000Z","formattedDate":"February 14, 2020","tags":[],"readingTime":5.63,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"Waku Update","title":"Waku Update","date":"2020-02-14T12:00:00.000Z","authors":"oskarth","published":true,"slug":"waku-update","categories":"research","image":"/img/waku_infrastructure_sky.jpg","discuss":"https://forum.vac.dev/t/waku-update-where-are-we-at/34"},"prevItem":{"title":"From Kademlia to Discv5","permalink":"/rlog/kademlia-to-discv5"},"nextItem":{"title":"DNS Based Discovery","permalink":"/rlog/dns-based-discovery"}},"content":"A research log. What\'s the current state of Waku? How many users does it support? What are the bottlenecks? What\'s next?\\n\\n\x3c!--truncate--\x3e\\n\\nWaku is our fork of Whisper where we address the shortcomings of Whisper in an iterative manner. We\'ve seen a in [previous post](https://vac.dev/fixing-whisper-with-waku) that Whisper doesn\'t scale, and why. In this post we\'ll talk about what the current state of Waku is, how many users it can support, and future plans.\\n\\n## Current state\\n\\n**Specs:**\\n\\nWe released [Waku spec v0.3](https://rfc.vac.dev/spec/6) this week! You can see the full changelog [here](https://rfc.vac.dev/spec/6/#changelog).\\n\\nThe main change from 0.2 is making the handshake more flexible. This enables us to communicate topic interest immediately without ambiguity. We also did the following:\\n\\n- added recommendation for DNS based discovery\\n- added an upgradability and compatibility policy\\n- cut the spec up into several components\\n\\nWe cut the spec up in several components to make Vac as modular as possible. The components right now are:\\n\\n- Waku (main spec), currently in [version 0.3.0](https://rfc.vac.dev/spec/6)\\n- Waku envelope data field, currently in [version 0.1.0](https://rfc.vac.dev/spec/7)\\n- Waku mailserver, currently in [version 0.2.0](https://rfc.vac.dev/spec/8)\\n\\nWe can probably factor these out further as the main spec is getting quite big, but this is good enough for now.\\n\\n**Clients:**\\n\\nThere are currently two clients that implement Waku v0.3, these are [Nimbus (Update: now nim-waku)](https://github.com/status-im/nim-waku) in Nim and [status-go](https://github.com/status-im/status-go) in Go.\\n\\nFor more details on what each client support and don\'t, you can follow the [work in progress checklist](https://github.com/vacp2p/pm/issues/7).\\n\\nWork is currently in progress to integrate it into the [Status core app](https://github.com/status-im/status-react/pull/9949). Waku is expected to be part of their upcoming 1.1 release (see [Status app roadmap (link deprecated)](https://trello.com/b/DkxQd1ww/status-app-roadmap)).\\n\\n**Simulation:**\\n\\nWe have a [simulation](https://github.com/status-im/nim-waku/blob/master/waku/v1/node/quicksim.nim) that verifies - or rather, fails to falsify - our [scalability model](https://vac.dev/fixing-whisper-with-waku). More on the simulation and what it shows below.\\n\\n## How many users does Waku support?\\n\\nThis is our current understanding of how many users a network running Waku can support. Specifically in the context of the Status chat app, since that\'s the most immediate consumer of Waku. It should generalize fairly well to most deployments.\\n\\n**tl;dr (for Status app):**\\n\\n- beta: 100 DAU\\n- v1: 1k DAU\\n- v1.1 (waku only): 10k DAU (up to x10 with deployment hotfixes)\\n- v1.2 (waku+dns): 100k DAU (can optionally be folded into v1.1)\\n\\n_Assuming 10 concurrent users = 100 DAU. Estimate uncertainty increases for each order of magnitude until real-world data is observed._\\n\\nAs far as we know right now, these are the bottlenecks we have:\\n\\n- Immediate bottleneck - Receive bandwidth for end user clients (aka \u2018Fixing Whisper with Waku\u2019)\\n- Very likely bottleneck - Nodes and cluster capacity (aka \u2018DNS based node discovery\u2019)\\n- Conjecture but not unlikely to appear- Full node traffic (aka \u2018the routing / partition problem\u2019)\\n\\nWe\'ve already seen the first bottleneck being discussed in the initial post. Dean wrote a post on [DNS based discovery](https://vac.dev/dns-based-discovery) which explains how we will address the likely second bottleneck. More on the third one in future posts.\\n\\nFor more details on these bottlenecks, see [Scalability estimate: How many users can Waku and the Status app support?](https://discuss.status.im/t/scalability-estimate-how-many-users-can-waku-and-the-status-app-support/1514).\\n\\n## Simulation\\n\\nThe ultimate test is real-world usage. Until then, we have a simulation thanks to Kim De Mey from the Nimbus team!\\n\\n![](/img/waku_simulation.jpeg)\\n\\nWe have two network topologies, Star and full mesh. Both networks have 6 full nodes, one traditional light node with bloom filter, and one Waku light node.\\n\\nOne of the full nodes sends 1 envelope over 1 of the 100 topics that the two light nodes subscribe to. After that, it sends 10000 envelopes over random topics.\\n\\nFor light node, bloom filter is set to almost 10% false positive (bloom filter: n=100, k=3, m=512). It shows the number of valid and invalid envelopes received for the different nodes.\\n\\n**Star network:**\\n\\n| Description     | Peers | Valid | Invalid |\\n| --------------- | ----- | ----- | ------- |\\n| Master node     | 7     | 10001 | 0       |\\n| Full node 1     | 3     | 10001 | 0       |\\n| Full node 2     | 1     | 10001 | 0       |\\n| Full node 3     | 1     | 10001 | 0       |\\n| Full node 4     | 1     | 10001 | 0       |\\n| Full node 5     | 1     | 10001 | 0       |\\n| Light node      | 2     | 815   | 0       |\\n| Waku light node | 2     | 1     | 0       |\\n\\n**Full mesh:**\\n\\n| Description     | Peers | Valid | Invalid |\\n| --------------- | ----- | ----- | ------- |\\n| Full node 0     | 7     | 10001 | 20676   |\\n| Full node 1     | 7     | 10001 | 9554    |\\n| Full node 2     | 5     | 10001 | 23304   |\\n| Full node 3     | 5     | 10001 | 11983   |\\n| Full node 4     | 5     | 10001 | 24425   |\\n| Full node 5     | 5     | 10001 | 23472   |\\n| Light node      | 2     | 803   | 803     |\\n| Waku light node | 2     | 1     | 1       |\\n\\nThings to note:\\n\\n- Whisper light node with ~10% false positive gets ~10% of total traffic\\n- Waku light node gets ~1000x less envelopes than Whisper light node\\n- Full mesh results in a lot more duplicate messages, expect for Waku light node\\n\\nRun the simulation yourself [here](https://github.com/status-im/nim-waku/blob/master/waku/v1/node/quicksim.nim). The parameters are configurable, and it is integrated with Prometheus and Grafana.\\n\\n## Difference between Waku and Whisper\\n\\nSummary of main differences between Waku v0 spec and Whisper v6, as described in [EIP-627](https://eips.ethereum.org/EIPS/eip-627):\\n\\n- Handshake/Status message not compatible with shh/6 nodes; specifying options as association list\\n- Include topic-interest in Status handshake\\n- Upgradability policy\\n- `topic-interest` packet code\\n- RLPx subprotocol is changed from shh/6 to waku/0.\\n- Light node capability is added.\\n- Optional rate limiting is added.\\n- Status packet has following additional parameters: light-node, confirmations-enabled and rate-limits\\n- Mail Server and Mail Client functionality is now part of the specification.\\n- P2P Message packet contains a list of envelopes instead of a single envelope.\\n\\n## Next steps and future plans\\n\\nSeveral challenges remain to make Waku a robust and suitable base\\ncommunication protocol. Here we outline a few challenges that we are addressing and will continue to work on:\\n\\n- scalability of the network\\n- incentived infrastructure and spam-resistance\\n- build with resource restricted devices in mind, including nodes being mostly offline\\n\\nFor the third bottleneck, a likely candidate for fixing this is Kademlia routing. This is similar to what is done in [Swarm\'s](https://www.ethswarm.org/) PSS. We are in the early stages of experimenting with this over libp2p in [nim-libp2p](https://github.com/status-im/nim-libp2p). More on this in a future post!\\n\\n## Acknowledgements\\n\\n_Image from \\"caged sky\\" by mh.xbhd.org is licensed under CC BY 2.0 (https://ccsearch.creativecommons.org/photos/a9168311-78de-4cb7-a6ad-f92be8361d0e)_"},{"id":"dns-based-discovery","metadata":{"permalink":"/rlog/dns-based-discovery","source":"@site/rlog/2020-02-7-dns-based-discovery.mdx","title":"DNS Based Discovery","description":"A look at EIP-1459 and the benefits of DNS based discovery.","date":"2020-02-07T12:00:00.000Z","formattedDate":"February 7, 2020","tags":[],"readingTime":5.635,"hasTruncateMarker":true,"authors":[{"name":"Dean","twitter":"DeanEigenmann","github":"decanus","website":"https://dean.eigenmann.me","key":"dean"}],"frontMatter":{"layout":"post","name":"DNS Based Discovery","title":"DNS Based Discovery","date":"2020-02-07T12:00:00.000Z","authors":"dean","published":true,"slug":"dns-based-discovery","categories":"research"},"prevItem":{"title":"Waku Update","permalink":"/rlog/waku-update"},"nextItem":{"title":"Fixing Whisper with Waku","permalink":"/rlog/fixing-whisper-with-waku"}},"content":"A look at EIP-1459 and the benefits of DNS based discovery.\\n\\n\x3c!--truncate--\x3e\\n\\nDiscovery in p2p networks is the process of how nodes find each other and specific resources they are looking for. Popular discovery protocols, such as [Kademlia](https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf) which utilizes a [distributed hash table](https://en.wikipedia.org/wiki/Distributed_hash_table) or DHT, are highly inefficient for resource restricted devices. These methods use short connection windows, and it is quite battery intensive to keep establishing connections. Additionally, we cannot expect a mobile phone for example to synchronize an entire DHT using cellular data.\\n\\nAnother issue is how we do the initial bootstrapping. In other words, how does a client find its first node to then discover the rest of the network? In most applications, including Status right now, this is done with a [static list of nodes](https://specs.status.im/spec/1#bootstrapping) that a client can connect to.\\n\\nIn summary, we have a static list that provides us with nodes we can connect to which then allows us to discover the rest of the network using something like Kademlia. But what we need is something that can easily be mutated, guarantees a certain amount of security, and is efficient for resource restricted devices. Ideally our solution would also be robust and scalable.\\n\\nHow do we do this?\\n\\n[EIP 1459: Node Discovery via DNS](https://eips.ethereum.org/EIPS/eip-1459), which is one of the strategies we are using for discovering waku nodes. [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459) is a DNS-based discovery protocol that stores [merkle trees](https://en.wikipedia.org/wiki/Merkle_tree) in DNS records which contain connection information for nodes.\\n\\n_Waku is our fork of Whisper. Oskar recently wrote an [entire post](https://vac.dev/fixing-whisper-with-waku) explaining it. In short, Waku is our method of fixing the shortcomings of Whisper in a more iterative fashion. You can find the specification [here](https://rfc.vac.dev/spec/6/)_\\n\\nDNS-based methods for bootstrapping p2p networks are quite popular. Even Bitcoin uses it, but it uses a concept called DNS seeds, which are just DNS servers that are configured to return a list of randomly selected nodes from the network upon being queried. This means that although these seeds are hardcoded in the client, the IP addresses of actual nodes do not have to be.\\n\\n```console\\n> dig dnsseed.bluematt.me +short\\n129.226.73.12\\n107.180.78.111\\n169.255.56.123\\n91.216.149.28\\n85.209.240.91\\n66.232.124.232\\n207.55.53.96\\n86.149.241.168\\n193.219.38.57\\n190.198.210.139\\n74.213.232.234\\n158.181.226.33\\n176.99.2.207\\n202.55.87.45\\n37.205.10.3\\n90.133.4.73\\n176.191.182.3\\n109.207.166.232\\n45.5.117.59\\n178.211.170.2\\n160.16.0.30\\n```\\n\\nThe above displays the result of querying on of these DNS seeds. All the nodes are stored as [`A` records](https://simpledns.plus/help/a-records) for the given domain name. This is quite a simple solution which Bitcoin almost soley relies on since removing the [IRC bootstrapping method in v0.8.2](https://en.bitcoin.it/wiki/Network#IRC).\\n\\nWhat makes this DNS based discovery useful? It allows us to have a mutable list of bootstrap nodes without needing to ship a new version of the client every time a list is mutated. It also allows for a more lightweight method of discovering nodes, something very important for resource restricted devices.\\n\\nAdditionally, DNS provides us with a robust and scalable infrastructure. This is due to its hierarchical architecture. This hierarchical architecture also already makes it distributed such that the failure of one DNS server does not result in us no longer being able to resolve our name.\\n\\nAs with every solution though, there is a trade-off. By storing the list in DNS name an adversary would simply need to censor the DNS records for a specific name. This would prevent any new client trying to join the network from being able to do so.\\n\\nOne thing you notice when looking at [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459) is that it is a lot more technically complex than Bitcoin\'s way of doing this. So if Bitcoin uses this simple method and has proven that it works, why did we need a new method?\\n\\nThere are multiple reasons, but the main one is **security**. In the Bitcoin example, an attacker could create a new list and no one querying would be able to tell. This is however mitigated in [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459) where we can verify the integrity of the entire returned list by storing an entire merkle tree in the DNS records.\\n\\nLet\'s dive into this. Firstly, a client that is using these DNS records for discovery must know the public key corresponding to the private key controlled by the entity creating the list. This is because the entire list is signed using a secp256k1 private key, giving the client the ability to authenticate the list and know that it has not been tampered with by some external party.\\n\\nSo that already makes this a lot safer than the method Bitcoin uses. But how are these lists even stored? As previously stated they are stored using **merkle trees** as follows:\\n\\n- The root of the tree is stored in a [`TXT` record](https://simpledns.plus/help/txt-records), this record contains the tree\'s root hash, a sequence number which is incremented every time the tree is updated and a signature as stated above.\\n\\n  Additionally, there is also a root hash to a second tree called a **link tree**, it contains the information to different lists. This link tree allows us to delegate trust and build a graph of multiple merkle trees stored across multiple DNS names.\\n\\n  The sequence number ensures that an attacker cannot replace a tree with an older version because when a client reads the tree, they should ensure that the sequence number is greater than the last synchronized version.\\n\\n- Using the root hash for the tree, we can find the merkle tree\'s first branch, the branch is also stored in a `TXT` record. The branch record contains all the hashes of the branch\'s leafs.\\n\\n- Once a client starts reading all the leafs, they can find one of two things: either a new branch record leading them further down the tree or an Ethereum Name Records (ENR) which means they now have the address of a node to connect to! To learn more about ethereum node records you can have a look at [EIP-778](https://eips.ethereum.org/EIPS/eip-778), or read a short blog post I wrote explaining them [here](https://dean.eigenmann.me/blog/2020/01/21/network-addresses-in-ethereum/#enr).\\n\\nBelow is the zone file taken from the [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459), displaying how this looks in practice.\\n\\n```\\n; name                        ttl     class type  content\\n@                             60      IN    TXT   enrtree-root:v1 e=JWXYDBPXYWG6FX3GMDIBFA6CJ4 l=C7HRFPF3BLGF3YR4DY5KX3SMBE seq=1 sig=o908WmNp7LibOfPsr4btQwatZJ5URBr2ZAuxvK4UWHlsB9sUOTJQaGAlLPVAhM__XJesCHxLISo94z5Z2a463gA\\nC7HRFPF3BLGF3YR4DY5KX3SMBE    86900   IN    TXT   enrtree://AM5FCQLWIZX2QFPNJAP7VUERCCRNGRHWZG3YYHIUV7BVDQ5FDPRT2@morenodes.example.org\\nJWXYDBPXYWG6FX3GMDIBFA6CJ4    86900   IN    TXT   enrtree-branch:2XS2367YHAXJFGLZHVAWLQD4ZY,H4FHT4B454P6UXFD7JCYQ5PWDY,MHTDO6TMUBRIA2XWG5LUDACK24\\n2XS2367YHAXJFGLZHVAWLQD4ZY    86900   IN    TXT   enr:-HW4QOFzoVLaFJnNhbgMoDXPnOvcdVuj7pDpqRvh6BRDO68aVi5ZcjB3vzQRZH2IcLBGHzo8uUN3snqmgTiE56CH3AMBgmlkgnY0iXNlY3AyNTZrMaECC2_24YYkYHEgdzxlSNKQEnHhuNAbNlMlWJxrJxbAFvA\\nH4FHT4B454P6UXFD7JCYQ5PWDY    86900   IN    TXT   enr:-HW4QAggRauloj2SDLtIHN1XBkvhFZ1vtf1raYQp9TBW2RD5EEawDzbtSmlXUfnaHcvwOizhVYLtr7e6vw7NAf6mTuoCgmlkgnY0iXNlY3AyNTZrMaECjrXI8TLNXU0f8cthpAMxEshUyQlK-AM0PW2wfrnacNI\\nMHTDO6TMUBRIA2XWG5LUDACK24    86900   IN    TXT   enr:-HW4QLAYqmrwllBEnzWWs7I5Ev2IAs7x_dZlbYdRdMUx5EyKHDXp7AV5CkuPGUPdvbv1_Ms1CPfhcGCvSElSosZmyoqAgmlkgnY0iXNlY3AyNTZrMaECriawHKWdDRk2xeZkrOXBQ0dfMFLHY4eENZwdufn1S1o\\n```\\n\\nAll of this has already been introduced into go-ethereum with the pull request [#20094](https://github.com/ethereum/go-ethereum/pull/20094), created by Felix Lange. There\'s a lot of tooling around it that already exists too which is really cool. So if your project is written in Golang and wants to use this, it\'s relatively simple! Additionally, here\'s a proof of concept that shows what this might look like with libp2p on [github](https://github.com/decanus/dns-discovery).\\n\\nI hope this was a helpful explainer into DNS based discovery, and shows [EIP-1459](https://eips.ethereum.org/EIPS/eip-1459)\'s benefits over more traditional DNS-based discovery schemes."},{"id":"fixing-whisper-with-waku","metadata":{"permalink":"/rlog/fixing-whisper-with-waku","source":"@site/rlog/2019-12-03-fixing-whisper-with-waku.mdx","title":"Fixing Whisper with Waku","description":"A research log. Why Whisper doesn\'t scale and how to fix it.","date":"2019-12-03T12:00:00.000Z","formattedDate":"December 3, 2019","tags":[],"readingTime":9.995,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"Fixing Whisper with Waku","title":"Fixing Whisper with Waku","date":"2019-12-03T12:00:00.000Z","authors":"oskarth","published":true,"slug":"fixing-whisper-with-waku","categories":"research","image":"/img/whisper_scalability.png","discuss":"https://forum.vac.dev/t/discussion-fixing-whisper-with-waku/27"},"prevItem":{"title":"DNS Based Discovery","permalink":"/rlog/dns-based-discovery"},"nextItem":{"title":"Feasibility Study: Semaphore rate limiting through zkSNARKs","permalink":"/rlog/feasibility-semaphore-rate-limiting-zksnarks"}},"content":"A research log. Why Whisper doesn\'t scale and how to fix it.\\n\\n\x3c!--truncate--\x3e\\n\\nThis post will introduce Waku. Waku is a fork of Whisper that attempts to\\naddresses some of Whisper\'s shortcomings in an iterative fashion. We will also\\nintroduce a theoretical scaling model for Whisper that shows why it doesn\'t\\nscale, and what can be done about it.\\n\\n## Introduction\\n\\nWhisper is a gossip-based communication protocol or an ephemeral key-value store\\ndepending on which way you look at it. Historically speaking, it is the\\nmessaging pilllar of [Web3](http://gavwood.com/dappsweb3.html), together with\\nEthereum for consensus and Swarm for storage.\\n\\nWhisper, being a somewhat esoteric protocol and with some fundamental issues,\\nhasn\'t seen a lot of usage. However, applications such as Status are using it,\\nand have been making minor ad hoc modifications to it to make it run on mobile\\ndevices.\\n\\nWhat are these fundamental issues? In short:\\n\\n1. scalability, most immediately when it comes to bandwidth usage\\n2. spam-resistance, proof of work is a poor mechanism for heterogeneous nodes\\n3. no incentivized infrastructure, leading to centralized choke points\\n4. lack of formal and unambiguous specification makes it hard to analyze and implement\\n5. running over devp2p, which limits where it can run and how\\n\\nIn this post, we\'ll focus on the first problem, which is scalability through bandwidth usage.\\n\\n## Whisper theoretical scalability model\\n\\n_(Feel free to skip this section if you want to get right to the results)._\\n\\nThere\'s widespread implicit knowledge that Whisper \\"doesn\'t scale\\", but it is less understood exactly why. This theoretical model attempts to encode some characteristics of it. Specifically for use case such as one by Status (see [Status Whisper usage\\nspec](https://specs.status.im/spec/3)).\\n\\n### Caveats\\n\\nFirst, some caveats: this model likely contains bugs, has wrong assumptions, or completely misses certain dimensions. However, it acts as a form of existence proof for unscalability, with clear reasons.\\n\\nIf certain assumptions are wrong, then we can challenge them and reason about them in isolation. It doesn\u2019t mean things will definitely work as the model predicts, and that there aren\u2019t unknown unknowns.\\n\\nThe model also only deals with receiving bandwidth for end nodes, uses mostly static assumptions of averages, and doesn\u2019t deal with spam resistance, privacy guarantees, accounting, intermediate node or network wide failures.\\n\\n### Goals\\n\\n1. Ensure network scales by being user or usage bound, as opposed to bandwidth growing in proportion to network size.\\n2. Staying with in a reasonable bandwidth limit for limited data plans.\\n3. Do the above without materially impacting existing nodes.\\n\\nIt proceeds through various case with clear assumptions behind them, starting from the most naive assumptions. It shows results for 100 users, 10k users and 1m users.\\n\\n### Model\\n\\n```\\nCase 1. Only receiving messages meant for you [naive case]\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A4. Only receiving messages meant for you.\\n\\nFor 100 users, receiving bandwidth is 1000.0KB/day\\nFor 10k users, receiving bandwidth is 1000.0KB/day\\nFor  1m users, receiving bandwidth is 1000.0KB/day\\n\\n------------------------------------------------------------\\n\\nCase 2. Receiving messages for everyone [naive case]\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A5. Received messages for everyone.\\n\\nFor 100 users, receiving bandwidth is   97.7MB/day\\nFor 10k users, receiving bandwidth is    9.5GB/day\\nFor  1m users, receiving bandwidth is  953.7GB/day\\n\\n------------------------------------------------------------\\n\\nCase 3. All private messages go over one discovery topic [naive case]\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A6. Proportion of private messages (static): 0.5\\n- A7. Public messages only received by relevant recipients (static).\\n- A8. All private messages are received by everyone (same topic) (static).\\n\\nFor 100 users, receiving bandwidth is   49.3MB/day\\nFor 10k users, receiving bandwidth is    4.8GB/day\\nFor  1m users, receiving bandwidth is  476.8GB/day\\n\\n------------------------------------------------------------\\n\\nCase 4. All private messages are partitioned into shards [naive case]\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A6. Proportion of private messages (static): 0.5\\n- A7. Public messages only received by relevant recipients (static).\\n- A9. Private messages partitioned across partition shards (static), n=5000\\n\\nFor 100 users, receiving bandwidth is 1000.0KB/day\\nFor 10k users, receiving bandwidth is    1.5MB/day\\nFor  1m users, receiving bandwidth is   98.1MB/day\\n\\n------------------------------------------------------------\\n\\nCase 5. 4 + Bloom filter with false positive rate\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A6. Proportion of private messages (static): 0.5\\n- A7. Public messages only received by relevant recipients (static).\\n- A9. Private messages partitioned across partition shards (static), n=5000\\n- A10. Bloom filter size (m) (static): 512\\n- A11. Bloom filter hash functions (k) (static): 3\\n- A12. Bloom filter elements, i.e. topics, (n) (static): 100\\n- A13. Bloom filter assuming optimal k choice (sensitive to m, n).\\n- A14. Bloom filter false positive proportion of full traffic, p=0.1\\n\\nFor 100 users, receiving bandwidth is   10.7MB/day\\nFor 10k users, receiving bandwidth is  978.0MB/day\\nFor  1m users, receiving bandwidth is   95.5GB/day\\n\\nNOTE: Traffic extremely sensitive to bloom false positives\\nThis completely dominates network traffic at scale.\\nWith p=1% we get 10k users ~100MB/day and 1m users ~10gb/day)\\n\\n------------------------------------------------------------\\n\\nCase 6. Case 5 + Benign duplicate receives\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A6. Proportion of private messages (static): 0.5\\n- A7. Public messages only received by relevant recipients (static).\\n- A9. Private messages partitioned across partition shards (static), n=5000\\n- A10. Bloom filter size (m) (static): 512\\n- A11. Bloom filter hash functions (k) (static): 3\\n- A12. Bloom filter elements, i.e. topics, (n) (static): 100\\n- A13. Bloom filter assuming optimal k choice (sensitive to m, n).\\n- A14. Bloom filter false positive proportion of full traffic, p=0.1\\n- A15. Benign duplicate receives factor (static): 2\\n- A16. No bad envelopes, bad PoW, expired, etc (static).\\n\\nFor 100 users, receiving bandwidth is   21.5MB/day\\nFor 10k users, receiving bandwidth is    1.9GB/day\\nFor  1m users, receiving bandwidth is  190.9GB/day\\n\\n------------------------------------------------------------\\n\\nCase 7. 6 + Mailserver under good conditions; small bloom fp; mostly offline\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A6. Proportion of private messages (static): 0.5\\n- A7. Public messages only received by relevant recipients (static).\\n- A9. Private messages partitioned across partition shards (static), n=5000\\n- A10. Bloom filter size (m) (static): 512\\n- A11. Bloom filter hash functions (k) (static): 3\\n- A12. Bloom filter elements, i.e. topics, (n) (static): 100\\n- A13. Bloom filter assuming optimal k choice (sensitive to m, n).\\n- A14. Bloom filter false positive proportion of full traffic, p=0.1\\n- A15. Benign duplicate receives factor (static): 2\\n- A16. No bad envelopes, bad PoW, expired, etc (static).\\n- A17. User is offline p% of the time (static) p=0.9\\n- A18. No bad request, dup messages for mailservers; overlap perfect (static).\\n- A19. Mailserver requests can change false positive rate to be p=0.01\\n\\nFor 100 users, receiving bandwidth is    3.9MB/day\\nFor 10k users, receiving bandwidth is  284.8MB/day\\nFor  1m users, receiving bandwidth is   27.8GB/day\\n\\n------------------------------------------------------------\\n\\nCase 8. No metadata protection w bloom filter; 1 node connected; static shard\\n\\nAka waku mode.\\n\\nNext step up is to either only use contact code, or shard more aggressively.\\nNote that this requires change of other nodes behavior, not just local node.\\n\\nAssumptions:\\n- A1. Envelope size (static): 1024kb\\n- A2. Envelopes / message (static): 10\\n- A3. Received messages / day (static): 100\\n- A6. Proportion of private messages (static): 0.5\\n- A7. Public messages only received by relevant recipients (static).\\n- A9. Private messages partitioned across partition shards (static), n=5000\\n\\nFor 100 users, receiving bandwidth is 1000.0KB/day\\nFor 10k users, receiving bandwidth is    1.5MB/day\\nFor  1m users, receiving bandwidth is   98.1MB/day\\n\\n------------------------------------------------------------\\n```\\n\\nSee [source](https://github.com/vacp2p/research/tree/master/whisper_scalability)\\nfor more detail on the model and its assumptions.\\n\\n### Takeaways\\n\\n1. Whisper as it currently works doesn\u2019t scale, and we quickly run into unacceptable bandwidth usage.\\n2. There are a few factors of this, but largely it boils down to noisy topics usage and use of bloom filters. Duplicate (e.g. see [Whisper vs PSS](https://our.status.im/whisper-pss-comparison/)) and bad envelopes are also factors, but this depends a bit more on specific deployment configurations.\\n3. Waku mode (case 8) is an additional capability that doesn\u2019t require other nodes to change, for nodes that put a premium on performance.\\n4. The next bottleneck after this is the partitioned topics (app/network specific), which either needs to gracefully (and potentially quickly) grow, or an alternative way of consuming those messages needs to be deviced.\\n\\n![](/img/whisper_scalability.png)\\n\\nThe results are summarized in the graph above. Notice the log-log scale. The\\ncolored backgrounds correspond to the following bandwidth usage:\\n\\n- Blue: <10mb/d (<~300mb/month)\\n- Green: <30mb/d (<~1gb/month)\\n- Yellow: <100mb/d (<~3gb/month)\\n- Red: >100mb/d (>3gb/month)\\n\\nThese ranges are somewhat arbitrary, but are based on [user\\nrequirements](https://github.com/status-im/status-react/issues/9081) for users\\non a limited data plan, with comparable usage for other messaging apps.\\n\\n## Introducing Waku\\n\\n### Motivation for a new protocol\\n\\nApps such as Status will likely use something like Whisper for the forseeable\\nfuture, and we want to enable them to use it with more users on mobile devices\\nwithout bandwidth exploding with minimal changes.\\n\\nAdditionally, there\'s not a clear cut alternative that maps cleanly to the\\ndesired use cases (p2p, multicast, privacy-preserving, open, etc).\\n\\nWe are actively researching, developing and collaborating with more greenfield\\napproaches. It is likely that Waku will either converge to those, or Waku will\\nlay the groundwork (clear specs, common issues/components) necessary to make\\nswitching to another protocol easier. In this project we want to emphasize\\niterative work with results on the order of weeks.\\n\\n### Briefly on Waku mode\\n\\n- Doesn\u2019t impact existing clients, it\u2019s just a separate node and capability.\\n- Other nodes can still use Whisper as is, like a full node.\\n- Sacrifices metadata protection and incurs higher connectivity/availability requirements for scalbility\\n\\n**Requirements:**\\n\\n- Exposes API to get messages from a set of list of topics (no bloom filter)\\n- Way of being identified as a Waku node (e.g. through version string)\\n- Option to statically encode this node in app, e.g. similar to custom bootnodes/mailserver\\n- Only node that needs to be connected to, possibly as Whisper relay / mailserver hybrid\\n\\n**Provides:**\\n\\n- likely provides scalability of up to 10k users and beyond\\n- with some enhancements to partition topic logic, can possibly scale up to 1m users (app/network specific)\\n\\n**Caveats:**\\n\\n- hasn\u2019t been tested in a large-scale simulation\\n- other network and intermediate node bottlenecks might become apparent (e.g. full bloom filter and private cluster capacity; can likely be dealt with in isolation using known techniques, e.g. load balancing) (deployment specific)\\n\\n### Progress so far\\n\\nIn short, we have a [Waku version 0 spec up](https://rfc.vac.dev/spec/5) as well as a [PoC](https://github.com/status-im/nim-eth/pull/120) for backwards compatibility. In the coming weeks, we are going to solidify the specs, get a more fully featured PoC for [Waku mode](https://github.com/status-im/nim-eth/pull/114). See [rough roadmap](https://github.com/vacp2p/pm/issues/5), project board [link deprecated] and progress thread on the [Vac forum](https://forum.vac.dev/t/waku-project-and-progress/24).\\n\\nThe spec has been rewrittten for clarity, with ABNF grammar and less ambiguous language. The spec also incorporates several previously [ad hoc implemented features](https://rfc.vac.dev/spec/6/#additional-capabilities), such as light nodes and mailserver/client support. This has already caught a few incompatibilities between the `geth` (Go), `status/whisper` (Go) and `nim-eth` (Nim) versions, specifically around light node usage and the handshake.\\n\\nIf you are interested in this effort, please check out [our forum](https://forum.vac.dev/) for questions, comments and proposals. We already have some discussion for better [spam protection](https://forum.vac.dev/t/stake-priority-based-queuing/26) (see [previous post](https://vac.dev/feasibility-semaphore-rate-limiting-zksnarks) for a more complex but privacy-preserving proposal), something that is likely going to be addressed in future versions of Waku, along with many other fixes and enhancement."},{"id":"feasibility-semaphore-rate-limiting-zksnarks","metadata":{"permalink":"/rlog/feasibility-semaphore-rate-limiting-zksnarks","source":"@site/rlog/2019-11-08-feasibility-semaphore-rate-limiting-zksnarks.mdx","title":"Feasibility Study: Semaphore rate limiting through zkSNARKs","description":"A research log. Zero knowledge signaling as a rate limiting mechanism to prevent spam in p2p networks.","date":"2019-11-08T12:00:00.000Z","formattedDate":"November 8, 2019","tags":[],"readingTime":7.54,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"Feasibility Study: Semaphore rate limiting through zkSNARKs","title":"Feasibility Study: Semaphore rate limiting through zkSNARKs","date":"2019-11-08T12:00:00.000Z","authors":"oskarth","published":true,"slug":"feasibility-semaphore-rate-limiting-zksnarks","categories":"research","image":"/img/peacock-signaling.jpg","discuss":"https://forum.vac.dev/t/discussion-feasibility-study-semaphore-rate-limiting-through-zksnarks/21","toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"Fixing Whisper with Waku","permalink":"/rlog/fixing-whisper-with-waku"},"nextItem":{"title":"P2P Data Sync with a Remote Log","permalink":"/rlog/remote-log"}},"content":"A research log. Zero knowledge signaling as a rate limiting mechanism to prevent spam in p2p networks.\\n\\n\x3c!--truncate--\x3e\\n\\n**tldr: Moon math promising for solving spam in Whisper, but to get there we need to invest more in performance work and technical upskilling.**\\n\\n## Motivating problem\\n\\nIn open p2p networks for messaging, one big problem is spam-resistance. Existing solutions, such as Whisper\'s proof of work, are insufficient, especially for heterogeneous nodes. Other reputation-based approaches might not be desirable, due to issues around arbitrary exclusion and privacy.\\n\\nOne possible solution is to use a right-to-access staking-based method, where a node is only able to send a message, signal, at a certain rate, and otherwise they can be slashed. One problem with this is in terms of privacy-preservation, where we specifically don\'t want a user to be tied to a specific payment or unique fingerprint.\\n\\n### Related problems\\n\\nIn addition to above, there are a lot of related problems that share similarities in terms of their structure and proposed solution.\\n\\n- Private transactions ([Zcash](https://z.cash/), [AZTEC](https://www.aztecprotocol.com/))\\n- Private voting ([Semaphore](https://github.com/kobigurk/semaphore))\\n- Private group membership (Semaphore)\\n- Layer 2 scaling, poss layer 1 ([ZK Rollup](https://ethresear.ch/t/on-chain-scaling-to-potentially-500-tx-sec-through-mass-tx-validation/3477); StarkWare/Eth2-3)\\n\\n## Overview\\n\\n## Basic terminology\\n\\nA _zero-knowledge proof_ allows a _prover_ to show a _verifier_ that they know something, without revealing what that something is. This means you can do trust-minimized computation that is also privacy preserving. As a basic example, instead of showing your ID when going to a bar you simply give them a proof that you are over 18, without showing the doorman your id.\\n\\n_zkSNARKs_ is a form of zero-knowledge proofs. There are many types of zero-knowledge proofs, and the field is evolving rapidly. They come with various trade-offs in terms of things such as: trusted setup, cryptographic assumptions, proof/verification key size, proof/verification time, proof size, etc. See section below for more.\\n\\n_Semaphore_ is a framework/library/construct on top of zkSNARks. It allows for zero-knowledge signaling, specifically on top of Ethereum. This means an approved user can broadcast some arbitrary string without revealing their identity, given some specific constraints. An approved user is someone who has been added to a certain merkle tree. See [current Github home](https://github.com/kobigurk/semaphore) for more.\\n\\n_Circom_ is a DSL for writing arithmetic circuits that can be used in zkSNARKs, similar to how you might write a NAND gate. See [Github](https://github.com/iden3/circom) for more.\\n\\n## Basic flow\\n\\nWe start with a private voting example, and then extend it to the slashable rate limiting example.\\n\\n1. A user registers an identity (arbitrary keypair), along with a small fee, to a smart contract. This adds them to a merkle tree and allows them to prove that they are member of that group, without revealing who they are.\\n\\n2. When a user wants to send a message, they compute a zero-knowledge proof. This ensures certain invariants, have some _public outputs_, and can be verified by anyone (including a smart contract).\\n3. Any node can verify the proof, including smart contracts on chain (as of Byzantinum HF). Additionally, a node can have rules for the public output. In the case of voting, one such rule is that a specific output hash has to be equal to some predefined value, such as \\"2020-01-01 vote on Foo Bar for president\\".\\n4. Because of how the proof is constructed, and the rules around output values, this ensures that: a user is part of the approved set of voters and that a user can only vote once.\\n5. As a consequence of above, we have a system where registered users can only vote once, no one can see who voted for what, and this can all be proven and verified.\\n\\n### Rate limiting example\\n\\nIn the case of rate limiting, we do want nodes to send multiple messages. This changes step 3-5 above somewhat.\\n\\n_NOTE: It is a bit more involved than this, and if we precompute proofs the flow might look a bit different. But the general idea is the same_.\\n\\n1. Instead of having a rule that you can only vote once, we have a rule that you can only send a message per epoch. Epoch here can be every second, as defined by UTC date time +-20s.\\n2. Additionally, if a users sends more than one message per epoch, one of the public outputs is a random share of a private key. Using Shamir\'s Secret Sharing (similar to a multisig) and 2/3 key share as an example threshold: in the normal case only 1/3 private keys is revealed, which is insufficient to have access. In the case where two messages are sent in an epoch, probabilistically 2/3 shares is sufficient to have access to the key (unless you get the same random share of the key).\\n3. This means any untrusted user who detects a spamming user, can use it to access their private key corresponding to funds in the contract, and thus slash them.\\n\\n4. As a consequence of above, we have a system where registered users can only messages X times per epoch, and no one can see who is sending what messages. Additionally, if a user is violating the above rate limit, they can be punished and any user can profit from it.\\n\\n### Briefly on scope of \'approved users\'\\n\\nIn the case of an application like Status, this construct can either be a global StatusNetwork group, or one per chat, or network, etc. It can be applied both at the network and user level. There are no specific limitations on where or who deploys this, and it is thus more of a UX consideration.\\n\\n## Technical details\\n\\nFor a fairly self-contained set of examples above, see exploration in [Vac research repo](https://github.com/vacp2p/research/blob/master/zksnarks/semaphore/src/hello.js). Note that the Shamir secret sharing is not inside the SNARK, but out-of-band for now.\\n\\nThe [current version](https://github.com/kobigurk/semaphore) of Semaphore is using NodeJS and [Circom](https://github.com/iden3/circom) from Iden3 for Snarks.\\n\\nFor more on rate limiting idea, see [ethresearch post](https://ethresear.ch/t/semaphore-rln-rate-limiting-nullifier-for-spam-prevention-in-anonymous-p2p-setting/5009/).\\n\\n## Feasibility\\n\\nThe above repo was used to exercise the basic paths and to gain intution of feasibility. Based on it and related reading we outline a few blockers and things that require further study.\\n\\n### Technical feasibility\\n\\n#### Proof time\\n\\nProve time for Semaphore (<https://github.com/kobigurk/semaphore>) zKSNARKs using circom, groth and snarkjs is currently way too long. It takes on the order of ~10m to generate a proof. With Websnark, it is likely to take 30s, which might still be too long. We should experiment with native code on mobile here.\\n\\nSee [details](https://github.com/vacp2p/research/issues/7).\\n\\n#### Proving key size\\n\\nProver key size is ~110mb for Semaphore. Assuming this is embedded on mobile device, it bloats the APK a lot. Current APK size is ~30mb and even that might be high for people with limited bandwidth.\\n\\nSee [details](https://github.com/vacp2p/research/issues/8).\\n\\n#### Trusted setup\\n\\nUsing zkSNARKs a trusted setup is required to generate prover and verifier keys. As part of this setup, a toxic parameter lambda is generated. If a party gets access to this lambda, they can prove anything. This means people using zKSNARKs usually have an elaborate MPC ceremony to ensure this parameter doesn\'t get discovered.\\n\\nSee [details](https://github.com/vacp2p/research/issues/9).\\n\\n#### Shamir logic in SNARK\\n\\nFor [Semaphore RLN](https://ethresear.ch/t/semaphore-rln-rate-limiting-nullifier-for-spam-prevention-in-anonymous-p2p-setting/5009) we need to embed the Shamir logic inside the SNARK in order to do slashing for spam. Currently the [implementation](https://github.com/vacp2p/research/blob/master/zksnarks/semaphore/src/hello.js#L450) is trusted and very hacky.\\n\\nSee [details](https://github.com/vacp2p/research/issues/10).\\n\\n#### End to end integation\\n\\n[Currently](https://github.com/vacp2p/research/blob/master/zksnarks/semaphore/src/hello.js) is standalone and doesn\'t touch multiple users, deployed contract with merkle tree and verification, actual transactions, a mocked network, add/remove members, etc. There are bound to be edge cases and unknown unknowns here.\\n\\nSee [details](https://github.com/vacp2p/research/issues/11).\\n\\n#### Licensing issues\\n\\nCurrently Circom [uses a GPL license](https://github.com/iden3/circom/blob/master/COPYING), which can get tricky when it comes to the App Store etc.\\n\\nSee [details](https://github.com/vacp2p/research/issues/12).\\n\\n#### Alternative ZKPs?\\n\\nSome of the isolated blockers for zKSNARKs ([#7](https://github.com/vacp2p/research/issues/7), [#8](https://github.com/vacp2p/research/issues/8), [#9](https://github.com/vacp2p/research/issues/9)) might be mitigated by the use of other ZKP technology. However, they likely have their own issues.\\n\\nSee [details](https://github.com/vacp2p/research/issues/13).\\n\\n### Social feasibility\\n\\n#### Technical skill\\n\\nzkSNARKs and related technologies are quite new. To learn how they work and get an intuition for them requires individuals to dedicate a lot of time to studying them. This means we must make getting competence in these technologies if we wish to use them to our advantage.\\n\\n#### Time and resources\\n\\nIn order for this and related projects (such as private transaction) to get anywhere, it must be made an explicit area of focus for an extend period of time.\\n\\n## General thoughts\\n\\nSimilar to Whisper, and in line with moving towards protocol and infrastructure, we need to upskill and invest resources into this. This doesn\'t mean developing all of the technologies ourselves, but gaining enough competence to leverage and extend existing solutions by the growing ZKP community.\\n\\nFor example, this might also include leveraging largely ready made solutions such as AZTEC for private transaction; more fundamental research into ZK rollup and similar; using Semaphore for private group membership and private voting; Nim based wrapper aronud Bellman, etc.\\n\\n## Acknowledgement\\n\\nThanks to Barry Whitehat for patient explanation and pointers. Thanks to WJ for helping with runtime issues.\\n\\n_Peacock header image from [Tonos](<https://en.wikipedia.org/wiki/File:Flickr_-_lo.tangelini_-_Tonos_(1).jpg>).\\\\_"},{"id":"remote-log","metadata":{"permalink":"/rlog/remote-log","source":"@site/rlog/2019-10-04-remote-log.mdx","title":"P2P Data Sync with a Remote Log","description":"A research log. Asynchronous P2P messaging? Remote logs to the rescue!","date":"2019-10-04T12:00:00.000Z","formattedDate":"October 4, 2019","tags":[],"readingTime":4.515,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"P2P Data Sync with a Remote Log","title":"P2P Data Sync with a Remote Log","date":"2019-10-04T12:00:00.000Z","authors":"oskarth","published":true,"slug":"remote-log","categories":"research","summary":null,"image":"/img/remote-log.png"},"prevItem":{"title":"Feasibility Study: Semaphore rate limiting through zkSNARKs","permalink":"/rlog/feasibility-semaphore-rate-limiting-zksnarks"},"nextItem":{"title":"Vac - A Rough Overview","permalink":"/rlog/vac-overview"}},"content":"A research log. Asynchronous P2P messaging? Remote logs to the rescue!\\n\\n\x3c!--truncate--\x3e\\n\\nA big problem when doing end-to-end data sync between mobile nodes is that most devices are offline most of the time. With a naive approach, you quickly run into issues of \'ping-pong\' behavior, where messages have to be constantly retransmitted. We saw some basic calculations of what this bandwidth multiplier looks like in a [previous post](https://vac.dev/p2p-data-sync-for-mobile).\\n\\nWhile you could do some background processing, this is really battery-draining, and on iOS these capabilities are limited. A better approach instead is to loosen the constraint that two nodes need to be online at the same time. How do we do this? There are two main approaches, one is the _store and forward model_, and the other is a _remote log_.\\n\\nIn the _store and forward_ model, we use an intermediate node that forward messages on behalf of the recipient. In the _remote log_ model, you instead replicate the data onto some decentralized storage, and have a mutable reference to the latest state, similar to DNS. While both work, the latter is somewhat more elegant and \\"pure\\", as it has less strict requirements of an individual node\'s uptime. Both act as a highly-available cache to smoothen over non-overlapping connection windows between endpoints.\\n\\nIn this post we are going to describe how such a remote log schema could work. Specifically, how it enhances p2p data sync and takes care of the [following requirements](https://vac.dev/p2p-data-sync-for-mobile):\\n\\n> 3. MUST allow for mobile-friendly usage. By mobile-friendly we mean devices\\n>    that are resource restricted, mostly-offline and often changing network.\\n\\n> 4. MAY use helper services in order to be more mobile-friendly. Examples of\\n>    helper services are decentralized file storage solutions such as IPFS and\\n>    Swarm. These help with availability and latency of data for mostly-offline\\n>    devices.\\n\\n## Remote log\\n\\nA remote log is a replication of a local log. This means a node can read data from a node that is offline.\\n\\nThe spec is in an early draft stage and can be found [here](https://github.com/vacp2p/specs/pull/16). A very basic [spike](<https://en.wikipedia.org/wiki/Spike_(software_development)>) / proof-of-concept can be found [here](https://github.com/vacp2p/research/tree/master/remote_log).\\n\\n### Definitions\\n\\n| Term       | Definition                                                                |\\n| ---------- | ------------------------------------------------------------------------- |\\n| CAS        | Content-addressed storage. Stores data that can be addressed by its hash. |\\n| NS         | Name system. Associates mutable data to a name.                           |\\n| Remote log | Replication of a local log at a different location.                       |\\n\\n### Roles\\n\\nThere are four fundamental roles:\\n\\n1. Alice\\n2. Bob\\n3. Name system (NS)\\n4. Content-addressed storage (CAS)\\n\\nThe _remote log_ is the data format of what is stored in the name system.\\n\\n\\"Bob\\" can represent anything from 0 to N participants. Unlike Alice, Bob only needs read-only access to NS and CAS.\\n\\n### Flow\\n\\n![Figure 1: Remote log data synchronization.](/img/remote-log.png)\\n\\n### Data format\\n\\nThe remote log lets receiving nodes know what data they are missing. Depending on the specific requirements and capabilities of the nodes and name system, the information can be referred to differently. We distinguish between three rough modes:\\n\\n1. Fully replicated log\\n2. Normal sized page with CAS mapping\\n3. \\"Linked list\\" mode - minimally sized page with CAS mapping\\n\\nA remote log is simply a mapping from message identifiers to their corresponding address in a CAS:\\n\\n| Message Identifier (H1) | CAS Hash (H2) |\\n| ----------------------- | ------------- |\\n| H1_3                    | H2_3          |\\n| H1_2                    | H2_2          |\\n| H1_1                    | H2_1          |\\n|                         |               |\\n| _address to next page_  |\\n\\nThe numbers here corresponds to messages. Optionally, the content itself can be included, just like it normally would be sent over the wire. This bypasses the need for a dedicated CAS and additional round-trips, with a trade-off in bandwidth usage.\\n\\n| Message Identifier (H1) | Content |\\n| ----------------------- | ------- |\\n| H1_3                    | C3      |\\n| H1_2                    | C2      |\\n| H1_1                    | C1      |\\n|                         |         |\\n| _address to next page_  |\\n\\nBoth patterns can be used in parallel, e,g. by storing the last `k` messages directly and use CAS pointers for the rest. Together with the `next_page` page semantics, this gives users flexibility in terms of bandwidth and latency/indirection, all the way from a simple linked list to a fully replicated log. The latter is useful for things like backups on durable storage.\\n\\n### Interaction with MVDS\\n\\n[vac.mvds.Message](https://rfc.vac.dev/spec/2/#payloads) payloads are the only payloads that MUST be uploaded. Other messages types MAY be uploaded, depending on the implementation.\\n\\n## Future work\\n\\nThe spec is still in an early draft stage, so it is expected to change. Same with the proof of concept. More work is needed on getting a fully featured proof of concept with specific CAS and NAS instances. E.g. Swarm and Swarm Feeds, or IPFS and IPNS, or something else.\\n\\nFor data sync in general:\\n\\n- Make consistency guarantees more explicit for app developers with support for sequence numbers and DAGs, as well as the ability to send non-synced messages. E.g. ephemeral typing notifications, linear/sequential history and casual consistency/DAG history\\n- Better semantics and scalability for multi-user sync contexts, e.g. CRDTs and joining multiple logs together\\n- Better usability in terms of application layer usage (data sync clients) and supporting more transports\\n\\n---\\n\\nPS1. Thanks everyone who submitted great [logo proposals](https://explorer.bounties.network/bounty/3389) for Vac!\\n\\nPPS2. Next week on October 10th decanus and I will be presenting Vac at [Devcon](https://devcon.org/agenda), come say hi :)"},{"id":"vac-overview","metadata":{"permalink":"/rlog/vac-overview","source":"@site/rlog/2019-08-02-vac-overview.mdx","title":"Vac - A Rough Overview","description":"Vac is a modular peer-to-peer messaging stack, with a focus on secure messaging. Overview of terms, stack and open problems.","date":"2019-08-02T12:00:00.000Z","formattedDate":"August 2, 2019","tags":[],"readingTime":5.535,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"layout":"post","name":"Vac - A Rough Overview","title":"Vac - A Rough Overview","date":"2019-08-02T12:00:00.000Z","authors":"oskarth","published":true,"slug":"vac-overview","categories":"research"},"prevItem":{"title":"P2P Data Sync with a Remote Log","permalink":"/rlog/remote-log"},"nextItem":{"title":"P2P Data Sync for Mobile","permalink":"/rlog/p2p-data-sync-for-mobile"}},"content":"Vac is a modular peer-to-peer messaging stack, with a focus on secure messaging. Overview of terms, stack and open problems.\\n\\n\x3c!--truncate--\x3e\\n\\nVac is a **modular peer-to-peer messaging stack, with a focus on secure messaging**. What does that mean? Let\'s unpack it a bit.\\n\\n## Basic terms\\n\\n_messaging stack_. While the initial focus is on [data sync](https://vac.dev/p2p-data-sync-for-mobile), we are concerned with all layers in the stack. That means all the way from underlying transports, p2p overlays and routing, to initial trust establishment and semantics for things like group chat. The ultimate goal is to give application developers the tools they need to provide secure messaging for their users, so they can focus on their domain expertise.\\n\\n_modular_. Unlike many other secure messaging applications, our goal is not to have a tightly coupled set of protocols, nor is it to reinvent the wheel. Instead, we aim to provide options at each layer in the stack, and build on the shoulders of giants, putting a premimum on interoperability. It\'s similar in philosophy to projects such as [libp2p](https://libp2p.io/) or [Substrate](https://www.parity.io/substrate/) in that regard. Each choice comes with different trade-offs, and these look different for different applications.\\n\\n_peer-to-peer_. The protocols we work on are pure p2p, and aim to minimize centralization. This too is in opposition to many initiatives in the secure messaging space.\\n\\n_messaging_. By messaging we mean messaging in a generalized sense. This includes both human to human communication, as well machine to machine communication. By messaging we also mean something more fundamental than text messages, we also include things like transactions (state channels, etc) under this moniker.\\n\\n_secure messaging_. Outside of traditional notions of secure messaging, such as ensuring end to end encryption, forward secrecy, avoiding MITM-attacks, etc, we are also concerned with two other forms of secure messaging. We call these _private messaging_ and _censorship-resistance_. Private messaging means viewing privacy as a security property, with all that entails. Censorship resistance ties into being p2p, but also in terms of allowing for transports and overlays that can\'t easily be censored by port blocking, traffic analysis, and similar.\\n\\n_V\u0101c_. Is a Vedic goddess of speech. It also hints at being a vaccine.\\n\\n## Protocol stack\\n\\nWhat does this stack look like? We take inspiration from [core](https://tools.ietf.org/html/rfc793) [internet architecture](https://www.ietf.org/rfc/rfc1122.txt), existing [survey work](https://css.csail.mit.edu/6.858/2020/readings/secure-messaging.pdf) and other [efforts](https://code.briarproject.org/briar/briar/wikis/A-Quick-Overview-of-the-Protocol-Stack) that have been done to decompose the problem into orthogonal pieces. Each layer provides their own set of properties and only interact with the layers it is adjacent to. Note that this is a rough sketch.\\n\\n| Layer / Protocol    | Purpose                           | Examples             |\\n| ------------------- | --------------------------------- | -------------------- |\\n| Application layer   | End user semantics                | 1:1 chat, group chat |\\n| Data Sync           | Data consistency                  | MVDS, BSP            |\\n| Secure Transport    | Confidentiality, PFS, etc         | Double Ratchet, MLS  |\\n| Transport Privacy   | Transport and metadata protection | Whisper, Tor, Mixnet |\\n| P2P Overlay         | Overlay routing, NAT traversal    | devp2p, libp2p       |\\n|                     |                                   |\\n| Trust Establishment | Establishing end-to-end trust     | TOFU, web of trust   |\\n\\nAs an example, end user semantics such as group chat or moderation capabilities can largely work regardless of specific choices further down the stack. Similarly, using a mesh network or Tor doesn\'t impact the use of Double Ratchet at the Secure Transport layer.\\n\\nData Sync plays a similar role to what TCP does at the transport layer in a traditional Internet architecture, and for some applications something more like UDP is likely to be desirable.\\n\\nIn terms of specific properties and trade-offs at each layer, we\'ll go deeper down into them as we study them. For now, this is best treated as a rough sketch or mental map.\\n\\n## Problems and rough priorities\\n\\nWith all the pieces involved, this is quite an undertaking. Luckily, a lot of pieces are already in place and can be either incorporated as-is or iterated on. In terms of medium and long term, here\'s a rough sketch of priorities and open problems.\\n\\n1. **Better data sync.** While the current [MVDS](https://rfc.vac.dev/spec/2/) works, it is lacking in a few areas:\\n\\n- Lack of remote log for mostly-offline offline devices\\n- Better scalability for multi-user chat contexts\\n- Better usability in terms of application layer usage and supporting more transports\\n\\n2. **Better transport layer support.** Currently MVDS runs primarily over Whisper, which has a few issues:\\n\\n- scalability, being able to run with many nodes\\n- spam-resistance, proof of work is a poor mechanism for heterogeneous devices\\n- no incentivized infrastructure, leading to centralized choke points\\n\\nIn addition to these most immediate concerns, there are other open problems. Some of these are overlapping with the above.\\n\\n3. **Adaptive nodes.** Better support for resource restricted devices and nodes of varying capabilities. Light connection strategy for resources and guarantees. Security games to outsource processing with guarantees.\\n\\n4. **Incentivized and spam-resistant messaging.** Reasons to run infrastructure and not relying on altruistic nodes. For spam resistance, in p2p multicast spam is a big attack vector due to amplification. There are a few interesting directions here, such as EigenTrust, proof of burn with micropayments, and leveraging zero-knowledge proofs.\\n\\n5. **Strong privacy guarantees at transport privacy layer**. More rigorous privacy guarantees and explicit trade-offs for metadata protection. Includes Mixnet.\\n6. **Censorship-resistant and robust P2P overlay**. NAT traversal; running in the browser; mesh networks; pluggable transports for traffic obfuscation.\\n\\n7. **Scalable and decentralized secure conversational security.** Strong security guarantees such as forward secrecy, post compromise security, for large group chats. Includes projects such MLS and extending Double Ratchet.\\n\\n8. **Better trust establishment and key handling**. Avoiding MITM attacks while still enabling a good user experience. Protecting against ghost users in group chat and providing better ways to do key handling.\\n\\nThere is also a set of more general problems, that touch multiple layers:\\n\\n9. **Ensuring modularity and interoperability**. Providing interfaces that allow for existing and new protocols to be at each layer of the stack.\\n\\n10. **Better specifications**. Machine-readable and formally verified specifications. More rigorous analysis of exact guarantees and behaviors. Exposing work in such a way that it can be analyzed by academics.\\n\\n11. **Better simulations**. Providing infrastructure and tooling to be able to test protocols in adverse environments and at scale.\\n\\n12. **Enabling excellent user experience**. A big reason for the lack of widespread adoption of secure messaging is the fact that more centralized, insecure methods provide a better user experience. Given that incentives can align better for users interested in secure messaging, providing an even better user experience should be doable.\\n\\n---\\n\\nWe got some work to do. Come help us if you want. See you in the next update!"},{"id":"p2p-data-sync-for-mobile","metadata":{"permalink":"/rlog/p2p-data-sync-for-mobile","source":"@site/rlog/2019-07-19-p2p-data-sync-for-mobile.mdx","title":"P2P Data Sync for Mobile","description":"A research log. Reliable and decentralized, pick two.","date":"2019-07-19T12:00:00.000Z","formattedDate":"July 19, 2019","tags":[],"readingTime":11.01,"hasTruncateMarker":true,"authors":[{"name":"Oskar","twitter":"oskarth","github":"oskarth","key":"oskarth"}],"frontMatter":{"title":"P2P Data Sync for Mobile","date":"2019-07-19T12:00:00.000Z","authors":"oskarth","published":true,"slug":"p2p-data-sync-for-mobile","categories":"research","image":"/img/mvds_interactive.png","toc_min_heading_level":2,"toc_max_heading_level":5},"prevItem":{"title":"Vac - A Rough Overview","permalink":"/rlog/vac-overview"}},"content":"A research log. Reliable and decentralized, pick two.\\n\\n\x3c!--truncate--\x3e\\n\\nTogether with decanus, I\'ve been working on the problem of data sync lately.\\n\\nIn building p2p messaging systems, one problem you quickly come across is the problem of reliably transmitting data. If there\'s no central server with high availability guarantees, you can\'t meaningfully guarantee that data has been transmitted. One way of solving this problem is through a synchronization protocol.\\n\\nThere are many synchronization protocols out there and I won\'t go into detail of how they differ with our approach here. Some common examples are Git and Bittorrent, but there are also projects like IPFS, Swarm, Dispersy, Matrix, Briar, SSB, etc.\\n\\n## Problem motivation\\n\\nWhy do we want to do p2p sync for mobilephones in the first place? There are three components to that question. One is on the value of decentralization and peer-to-peer, the second is on why we\'d want to reliably sync data at all, and finally why mobilephones and other resource restricted devices.\\n\\n### Why p2p?\\n\\nFor decentralization and p2p, there are both technical and social/philosophical reasons. Technically, having a user-run network means it can scale with the number of users. Data locality is also improved if you query data that\'s close to you, similar to distributed CDNs. The throughput is also improved if there are more places to get data from.\\n\\nSocially and philosophically, there are several ways to think about it. Open and decentralized networks also relate to the idea of open standards, i.e. compare the longevity of AOL with IRC or Bittorrent. One is run by a company and is shut down as soon as it stops being profitable, the others live on. Additionally increasingly control of data and infrastructure is becoming a liability. By having a network with no one in control, everyone is. It\'s ultimately a form of democratization, more similar to organic social structures pre Big Internet companies. This leads to properties such as censorship resistance and coercion resistance, where we limit the impact a 3rd party might have a voluntary interaction between individuals or a group of people. Examples of this are plentiful in the world of Facebook, Youtube, Twitter and WeChat.\\n\\n### Why reliably sync data?\\n\\nAt risk of stating the obvious, reliably syncing data is a requirement for many problem domains. You don\'t get this by default in a p2p world, as it is unreliable with nodes permissionslessly join and leave the network. In some cases you can get away with only ephemeral data, but usually you want some kind of guarantees. This is a must for reliable group chat experience, for example, where messages are expected to arrive in a timely fashion and in some reasonable order. The same is true for messages there represent financial transactions, and so on.\\n\\n### Why mobilephones?\\n\\nMost devices people use daily are mobile phones. It\'s important to provide the same or at least similar guarantees to more traditional p2p nodes that might run on a desktop computer or computer. The alternative is to rely on gateways, which shares many of the drawbacks of centralized control and prone to censorship, control and surveillence.\\n\\nMore generally, resource restricted devices can differ in their capabilities. One example is smartphones, but others are: desktop, routers, Raspberry PIs, POS systems, and so on. The number and diversity of devices are exploding, and it\'s useful to be able to leverage this for various types of infrastructure. The alternative is to centralize on big cloud providers, which also lends itself to lack of democratization and censorship, etc.\\n\\n## Minimal Requirements\\n\\nFor requirements or design goals for a solution, here\'s what we came up with.\\n\\n1. MUST sync data reliably between devices. By reliably we mean having the ability to deal with messages being out of order, dropped, duplicated, or delayed.\\n\\n2. MUST NOT rely on any centralized services for reliability. By centralized services we mean any single point of failure that isn\u2019t one of the endpoint devices.\\n\\n3. MUST allow for mobile-friendly usage. By mobile-friendly we mean devices that are resource restricted, mostly-offline and often changing network.\\n\\n4. MAY use helper services in order to be more mobile-friendly. Examples of helper services are decentralized file storage solutions such as IPFS and Swarm. These help with availability and latency of data for mostly-offline devices.\\n\\n5. MUST have the ability to provide casual consistency. By casual consistency we mean the commonly accepted definition in distributed systems literature. This means messages that are casually related can achieve a partial ordering.\\n\\n6. MUST support ephemeral messages that don\u2019t need replication. That is, allow for messages that don\u2019t need to be reliabily transmitted but still needs to be transmitted between devices.\\n\\n7. MUST allow for privacy-preserving messages and extreme data loss. By privacy-preserving we mean things such as exploding messages (self-destructing messages). By extreme data loss we mean the ability for two trusted devices to recover from a, deliberate or accidental, removal of data.\\n\\n8. MUST be agnostic to whatever transport it is running on. It should not rely on specific semantics of the transport it is running on, nor be tightly coupled with it. This means a transport can be swapped out without loss of reliability between devices.\\n\\n## MVDS - a minimium viable version\\n\\nThe first minimum viable version is in an alpha stage, and it has a [specification](https://rfc.vac.dev/spec/2), [implementation](https://github.com/vacp2p/mvds) and we have deployed it in a [console client](https://github.com/status-im/status-console-client) for end to end functionality. It\'s heavily inspired by [Bramble Sync Protocol](https://code.briarproject.org/briar/briar-spec/blob/master/protocols/BSP.md).\\n\\nThe spec is fairly minimal. You have nodes that exchange records over some secure transport. These records are of different types, such as `OFFER`, `MESSAGE`, `REQUEST`, and `ACK`. A peer keep tracks of the state of message for each node it is interacting with. There\'s also logic for message retransmission with exponential delay. The positive ACK and retransmission model is quite similar to how TCP is designed.\\n\\nThere are two different modes of syncing, interactive and batch mode. See sequence diagrams below.\\n\\nInteractive mode:\\n![Interactive mode](/img/mvds_interactive.png)\\n\\nBatch mode:\\n![Batch mode](/img/mvds_batch.png)\\n\\nWhich mode should you choose? It\'s a tradeoff of latency and bandwidth. If you want to minimize latency, batch mode is better. If you care about preserving bandwidth interactive mode is better. The choice is up to each node.\\n\\n### Basic simulation\\n\\nInitial ad hoc bandwidth and latency testing shows some issues with a naive approach. Running with the [default simulation settings](https://github.com/vacp2p/mvds/):\\n\\n- communicating nodes: 2\\n- nodes using interactive mode: 2\\n- interval between messages: 5s\\n- time node is offine: 90%\\n- nodes each node is sharing with: 2\\n\\nwe notice a [huge overhead](https://notes.status.im/7QYa4b6bTH2wMk3HfAaU0w#). More specifically, we see a ~5 minute latency overhead and a bandwidth multiplier of x100-1000, i.e. 2-3 orders of magnitude just for receiving a message with interactive mode, without acks.\\n\\nNow, that seems terrible. A moment of reflection will reveal why that is. If each node is offline uniformly 90% of the time, that means that each record will be lost 90% of the time. Since interactive mode requires offer, request, payload (and then ack), that\'s three links just for Bob to receive the actual message.\\n\\nEach failed attempt implies another retransmission. That means we have `(1/0.1)^3 = 1000` expected overhead to receive a message in interactive mode. The latency follows naturally from that, with the retransmission logic.\\n\\n### Mostly-offline devices\\n\\nThe problem above hints at the requirements 3 and 4 above. While we did get reliable syncing (requirement 1), it came at a big cost.\\n\\nThere are a few ways of getting around this issue. One is having a _store and forward_ model, where some intermediary node picks up (encrypted) messages and forwards them to the recipient. This is what we have in production right now at Status.\\n\\nAnother, arguably more pure and robust, way is having a _remote log_, where the actual data is spread over some decentralized storage layer, and you have a mutable reference to find the latest messages, similar to DNS.\\n\\nWhat they both have in common is that they act as a sort of highly-available cache to smooth over the non-overlapping connection windows between two endpoints. Neither of them are _required_ to get reliable data transmission.\\n\\n### Basic calculations for bandwidth multiplier\\n\\nWhile we do want better simulations, and this is a work in progress, we can also look at the above scenarios using some basic calculations. This allows us to build a better intuition and reason about the problem without having to write code. Let\'s start with some assumptions:\\n\\n- two nodes exchanging a single message in batch mode\\n- 10% uniformly random uptime for each node\\n- in HA cache case, 100% uptime of a piece of infrastructure C\\n- retransmission every epoch (with constant or exponential backoff)\\n- only looking at average (p50) case\\n\\n#### First case, no helper services\\n\\nA sends a message to B, and B acks it.\\n\\n```\\nA message -> B (10% chance of arrival)\\nA   <- ack   B (10% chance of arrival)\\n```\\n\\nWith a constant backoff, A will send messages at epoch `1, 2, 3, ...`. With exponential backoff and a multiplier of 2, this would be `1, 2, 4, 8, ...`. Let\'s assume constant backoff for now, as this is what will influence the success rate and thus the bandwidth multiplier.\\n\\nThere\'s a difference between _time to receive_ and _time to stop sending_. Assuming each send attempt is independent, it takes on average 10 epochs for A\'s message to arrive with B. Furthermore:\\n\\n1. A will send messages until it receives an ACK.\\n2. B will send ACK if it receives a message.\\n\\nTo get an average of one ack through, A needs to send 100 messages, and B send on average 10 acks. That\'s a multiplier of roughly a 100. That\'s roughly what we saw with the simulation above for receiving a message in interactive mode.\\n\\n#### Second case, high-availability caching layer\\n\\nLet\'s introduce a helper node or piece of infrastructure, C. Whenever A or B sends a message, it also sends it to C. Whenever A or B comes online, it queries for messages with C.\\n\\n```\\nA message    -> B (10% chance of arrival)\\nA message    -> C (100% chance of arrival)\\nB <- req/res -> C (100% chance of arrival)\\nA   <- ack      B (10% chance of arrival)\\nC   <- ack      B (100% chance of arrival)\\nA <- req/res -> C (100% chance of arrival)\\n```\\n\\nWhat\'s the probability that A\'s messages will arrive at B? Directly, it\'s still 10%. But we can assume it\'s 100% that C picks up the message. (Giving C a 90% chance success rate doesn\'t materially change the numbers).\\n\\nB will pick up A\'s message from C after an average of 10 epochs. Then B will send ack to A, which will also be picked up by C 100% of the time. Once A comes online again, it\'ll query C and receive B\'s ack.\\n\\nAssuming we use exponential backoff with a multiplier of 2, A will send a message directly to B at epoch `1, 2, 4, 8` (assuming it is online). At this point, epoch `10`, B will be online in the average case. These direct sends will likely fail, but B will pick the message up from C and send one ack, both directly to A and to be picked up by C. Once A comes online, it\'ll query C and receive the ack from B, which means it won\'t do any more retransmits.\\n\\nHow many messages have been sent? Not counting interactions with C, A sends 4 (at most) and B 1. Depending on if the interaction with C is direct or indirect (i.e. multicast), the factor for interaction with C will be ~2. This means the total bandwidth multiplier is likely to be `<10`, which is a lot more acceptable.\\n\\nSince the syncing semantics are end-to-end, this is without relying on the reliablity of C.\\n\\n#### Caveat\\n\\nNote that both of these are probabilistic argument. They are also based on heuristics. More formal analysis would be desirable, as well as better simulations to experimentally verify them. In fact, the calculations could very well be wrong!\\n\\n## Future work\\n\\nThere are many enhancements that can be made and are desirable. Let\'s outline a few.\\n\\n1. Data sync clients. Examples of actual usage of data sync, with more interesting domain semantics. This also includes usage of sequence numbers and DAGs to know what content is missing and ought to be synced.\\n\\n2. Remote log. As alluded to above, this is necessary. It needs a more clear specification and solid proof of concepts.\\n\\n3. More efficient ways of syncing with large number of nodes. When the number of nodes goes up, the algorithmic complexity doesn\'t look great. This also touches on things such as ambient content discovery.\\n\\n4. More robust simulations and real-world deployments. Exisiting simulation is ad hoc, and there are many improvements that can be made to gain more confidence and identify issues. Additionally, better formal analysis.\\n\\n5. Example usage over multiple transports. Including things like sneakernet and meshnets. The described protocol is designed to work over unstructured, structured and private p2p networks. In some cases it can leverage differences in topology, such as multicast, or direct connections."}]}')}}]);